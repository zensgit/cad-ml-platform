# CAD ML Platform - 6å¤©å¼€å‘è®¡åˆ’å®æ–½æ¸…å•

**è®¡åˆ’å‘¨æœŸ**: 6ä¸ªå·¥ä½œæ—¥
**å¼€å§‹æ—¥æœŸ**: 2025-11-24
**ç­–ç•¥**: ç¨³å®šæ€§ä¼˜å…ˆ â†’ å¯è§‚æµ‹æ€§ â†’ å®‰å…¨ â†’ åŠŸèƒ½æ‰©å±•

---

## ğŸ“‹ å‡†å¤‡å·¥ä½œï¼ˆDay 0 - å¼€å§‹å‰ï¼‰

### âœ… ç¯å¢ƒå‡†å¤‡
- [ ] åˆ›å»º `config/feature_flags.py` é…ç½®æ–‡ä»¶
- [ ] å»ºç«‹ `scripts/daily_checkpoint.sh` æ£€æŸ¥ç‚¹è„šæœ¬
- [ ] åˆ›å»º `scripts/track_progress.sh` è¿›åº¦è·Ÿè¸ªè„šæœ¬
- [ ] å‡†å¤‡ v4 å‡ ä½•ç®—æ³•æµ‹è¯•æ•°æ®é›†
- [ ] é…ç½® CI é¢„æ£€æŸ¥é’©å­
- [ ] è®¾ç½®ä¼˜å…ˆçº§æ ‡ç­¾ç³»ç»Ÿ (P0/P1/P2)
- [ ] å»ºç«‹æ€§èƒ½åŸºçº¿å¿«ç…§

### éªŒæ”¶æ ‡å‡†
- æ‰€æœ‰å‡†å¤‡è„šæœ¬å¯æ‰§è¡Œ
- æµ‹è¯•æ•°æ®é›†å°±ä½
- åŸºçº¿æ€§èƒ½æ•°æ®è®°å½•å®Œæˆ

---

## Day 1: Phase A - ç¨³å®šæ€§ä¸è¡¥æµ‹ï¼ˆè°ƒæ•´ç‰ˆï¼‰

### ğŸŒ… AM Session (4h) - Phase A-1

#### ä»»åŠ¡ 1.1: Rediså®•æœºå­¤å„¿æ¸…ç†æµ‹è¯•
- [ ] å®ç° `tests/unit/test_orphan_cleanup_redis_down.py`
  - æ¨¡æ‹Ÿ Redis è¿æ¥å¤±è´¥
  - éªŒè¯å­¤å„¿æ¸…ç†é™çº§é€»è¾‘
  - æ£€æŸ¥ `vector_orphan_total` æŒ‡æ ‡
- [ ] æ‰©å±• `/api/v1/maintenance/orphans/cleanup` é”™è¯¯å¤„ç†
  - è¿”å›ç»“æ„åŒ–é”™è¯¯ `SERVICE_UNAVAILABLE`
  - æ·»åŠ  fallback æç¤ºä¿¡æ¯

**éªŒæ”¶**:
- 3ä¸ªæµ‹è¯•ç”¨ä¾‹é€šè¿‡ï¼ˆè¿æ¥å¤±è´¥/è¶…æ—¶/éƒ¨åˆ†å¤±è´¥ï¼‰
- æŒ‡æ ‡æ­£ç¡®é€’å¢
- é”™è¯¯å“åº”ç¬¦åˆ `build_error` æ ¼å¼

#### ä»»åŠ¡ 1.2: Faissæ‰¹é‡ç›¸ä¼¼åº¦é™çº§æµ‹è¯•
- [ ] åˆ›å»º `tests/unit/test_faiss_degraded_batch.py`
  - Faiss ä¸å¯ç”¨æ—¶æ‰¹é‡æŸ¥è¯¢é™çº§åˆ°å†…å­˜
  - éªŒè¯ `vector_query_backend_total{backend="memory_fallback"}`
  - æ£€æŸ¥å“åº”åŒ…å« `fallback=true` æ ‡è®°
- [ ] æ›´æ–° `src/api/v1/vectors.py` batch_similarity
  - å¢åŠ  fallback æ ‡è®°å­—æ®µ
  - è®°å½•é™çº§æŒ‡æ ‡

**éªŒæ”¶**:
- 4ä¸ªæµ‹è¯•ç”¨ä¾‹é€šè¿‡ï¼ˆFaissä¸å¯ç”¨/åˆå§‹åŒ–å¤±è´¥/æŸ¥è¯¢å¼‚å¸¸/æ··åˆåœºæ™¯ï¼‰
- é™çº§æ ‡è®°æ­£ç¡®è¿”å›
- æ€§èƒ½æ— æ˜æ˜¾åŠ£åŒ–ï¼ˆ< 10%ï¼‰

#### ä»»åŠ¡ 1.3: ç»´æŠ¤ç«¯ç‚¹é”™è¯¯ç»“æ„åŒ–
- [ ] å®¡æŸ¥æ‰€æœ‰ `/api/v1/maintenance/*` ç«¯ç‚¹
- [ ] ç»Ÿä¸€é”™è¯¯å“åº”æ ¼å¼ï¼ˆä½¿ç”¨ `build_error`ï¼‰
- [ ] æ·»åŠ ä¸Šä¸‹æ–‡å­—æ®µï¼ˆoperation/resource_id/suggestionï¼‰

**éªŒæ”¶**:
- æ‰€æœ‰ç»´æŠ¤ç«¯ç‚¹é”™è¯¯æ ¼å¼ä¸€è‡´
- å•æµ‹è¦†ç›–é”™è¯¯è·¯å¾„

---

### ğŸŒ† PM Session (4h) - Phase A-2

#### ä»»åŠ¡ 1.4: æ¨¡å‹å›æ»šå¥åº·æµ‹è¯•
- [ ] æ‰©å±• `src/api/v1/health.py` çš„ `/health/model` ç«¯ç‚¹
  - å¢åŠ  `rollback_level: int` å­—æ®µï¼ˆ0/1/2ï¼‰
  - å¢åŠ  `last_error: str | None` å­—æ®µ
  - å¢åŠ  `rollback_reason: str | None` å­—æ®µ
- [ ] åˆ›å»º `tests/unit/test_model_rollback_health.py`
  - æ¨¡æ‹Ÿå®‰å…¨å¤±è´¥è§¦å‘å›æ»š
  - éªŒè¯ health ç«¯ç‚¹è¿”å› rollback ä¿¡æ¯
  - æ£€æŸ¥ `model_health_checks_total{status="rollback"}` æŒ‡æ ‡

**éªŒæ”¶**:
- 6ä¸ªæµ‹è¯•ç”¨ä¾‹é€šè¿‡ï¼ˆæ— å›æ»š/level1/level2/è¿ç»­å¤±è´¥/æ¢å¤åæ¸…é™¤ï¼‰
- Health å“åº”åŒ…å«å®Œæ•´å›æ»šä¿¡æ¯
- æŒ‡æ ‡æ­£ç¡®åˆ†ç±» ok/absent/error/rollback

#### ä»»åŠ¡ 1.5: åç«¯é‡è½½å¤±è´¥æµ‹è¯•ï¼ˆéƒ¨åˆ†ï¼‰
- [ ] åˆ›å»º `tests/unit/test_backend_reload_failures.py`
  - æ— æ•ˆåç«¯åç§°
  - ç¼ºå°‘æˆæƒå¤´
  - åç«¯åˆå§‹åŒ–å¤±è´¥
- [ ] æ›´æ–° `vector_store_reload_total` æŒ‡æ ‡
  - å¢åŠ  `reason` æ ‡ç­¾ï¼ˆinvalid_backend/auth_failed/init_errorï¼‰

**éªŒæ”¶**:
- 3ä¸ªæ ¸å¿ƒæµ‹è¯•ç”¨ä¾‹å®Œæˆ
- é”™è¯¯å“åº”ç»“æ„åŒ–
- æŒ‡æ ‡æ ‡ç­¾é½å…¨

---

## Day 2: Phase Aå®Œæˆ + Phase Bå¼€å§‹

### ğŸŒ… AM Session (4h) - Phase Aæ”¶å°¾

#### ä»»åŠ¡ 2.1: å®Œæˆåç«¯é‡è½½å¤±è´¥æµ‹è¯•
- [ ] è¡¥å…… `tests/unit/test_backend_reload_failures.py`
  - å¹¶å‘é‡è½½å†²çª
  - é…ç½®æ–‡ä»¶ç¼ºå¤±
  - æƒé™ä¸è¶³åœºæ™¯

**éªŒæ”¶**:
- åç«¯é‡è½½æµ‹è¯•å¥—ä»¶å®Œæ•´ï¼ˆ6-8ä¸ªç”¨ä¾‹ï¼‰
- è¦†ç›–ç‡ â‰¥ 90%

#### ä»»åŠ¡ 2.2: é™çº§è¿ç§»é“¾ç»Ÿè®¡æµ‹è¯•
- [ ] åˆ›å»º `tests/unit/test_migrate_downgrade_chain.py`
  - æ¨¡æ‹Ÿ v4â†’v3â†’v2â†’v1 é™çº§é“¾
  - éªŒè¯ `vector_migrate_total{status="downgraded"}` è®¡æ•°
  - æ£€æŸ¥ç»´åº¦é€’å‡ç»Ÿè®¡

**éªŒæ”¶**:
- é™çº§é“¾è·¯æ¸…æ™°å¯è¿½è¸ª
- ç»Ÿè®¡æŒ‡æ ‡ç²¾ç¡®

#### ä»»åŠ¡ 2.3: æ‰¹é‡ç›¸ä¼¼åº¦ç©ºç»“æœæ‹’ç»è®¡æ•°
- [ ] æ‰©å±• `src/api/v1/vectors.py` batch_similarity
  - æ£€æµ‹æ‰€æœ‰IDæ— ç»“æœæƒ…å†µ
  - è®°å½• `analysis_rejections_total{reason="batch_empty_results"}`
- [ ] æ·»åŠ æµ‹è¯•ç”¨ä¾‹

**éªŒæ”¶**:
- ç©ºç»“æœåœºæ™¯æŒ‡æ ‡æ­£ç¡®é€’å¢
- ä¸å½±å“æ­£å¸¸æŸ¥è¯¢

---

### ğŸŒ† PM Session (4h) - Phase B-1

#### ä»»åŠ¡ 2.4: è‡ªé€‚åº”ç¼“å­˜è°ƒä¼˜ç«¯ç‚¹
- [ ] åˆ›å»º `src/api/v1/features.py` æ–°ç«¯ç‚¹ `/api/v1/features/cache/tuning`
  - è¾“å…¥æ¨¡å‹ï¼š`CacheTuningRequest` (hit_rate/capacity/ttl/window_hours)
  - è¾“å‡ºæ¨¡å‹ï¼š`CacheTuningRecommendation`
    - `recommended_capacity: int`
    - `recommended_ttl: int`
    - `confidence: float`
    - `reasoning: List[str]`
    - `experimental: bool = True`
- [ ] å®ç°è°ƒä¼˜ç®—æ³•
  ```python
  if hit_rate < 0.4:
      # å‘½ä¸­ç‡è¿‡ä½ï¼Œå®¹é‡ä¸è¶³
      capacity *= 1.5
      reasoning.append("Low hit rate suggests insufficient capacity")
  elif 0.4 <= hit_rate < 0.7:
      # ä¸­ç­‰å‘½ä¸­ç‡ï¼Œè°ƒæ•´TTL
      ttl = adjust_ttl_based_on_access_pattern()
      reasoning.append("Moderate hit rate, optimize TTL")
  elif hit_rate > 0.85:
      # å‘½ä¸­ç‡è¿‡é«˜ï¼Œå¯èƒ½è¿‡åº¦ç¼“å­˜
      capacity *= 0.8
      reasoning.append("High hit rate, capacity can be reduced")
  ```
- [ ] æ·»åŠ æŒ‡æ ‡ `feature_cache_tuning_requests_total{status}`
- [ ] åˆ›å»º `tests/unit/test_cache_tuning.py`

**éªŒæ”¶**:
- ç«¯ç‚¹è¿”å›åˆç†å»ºè®®
- è¾¹ç•Œcaseæµ‹è¯•è¦†ç›–ï¼ˆ0.35/0.39/0.40/0.70/0.85/0.90ï¼‰
- å¯è§£é‡Šæ€§å¼ºï¼ˆreasoningæ¸…æ™°ï¼‰

#### ä»»åŠ¡ 2.5: è¿ç§»ç»´åº¦å·®å¼‚ç›´æ–¹å›¾
- [ ] æ·»åŠ æŒ‡æ ‡ `vector_migrate_dimension_delta`
  ```python
  vector_migrate_dimension_delta = Histogram(
      "vector_migrate_dimension_delta",
      "Dimension difference during migration (positive = expansion, negative = reduction)",
      buckets=[-50, -20, -10, -5, 0, 5, 10, 20, 50, 100],
  )
  ```
- [ ] åœ¨ `src/core/similarity.py` æˆ–è¿ç§»é€»è¾‘ä¸­è®°å½•
- [ ] å¯¼å‡ºåˆ° `__all__`

**éªŒæ”¶**:
- æŒ‡æ ‡åœ¨ `/metrics` å¯è§
- è®°å½•ç»´åº¦å˜åŒ–åˆ†å¸ƒ

---

## Day 3: Phase B + Phase C-1

### ğŸŒ… AM Session (4h) - Phase B-2

#### ä»»åŠ¡ 3.1: Grafana Dashboardæ¡†æ¶ï¼ˆ70%ï¼‰
- [ ] åˆ›å»º `config/grafana/dashboard_main.json`
  - é¢æ¿1: åˆ†æè¯·æ±‚æ€»è§ˆï¼ˆæˆåŠŸç‡/QPSï¼‰
  - é¢æ¿2: æ‰¹é‡ç›¸ä¼¼åº¦å»¶è¿Ÿï¼ˆp50/p95/p99ï¼‰
  - é¢æ¿3: ç‰¹å¾ç¼“å­˜å‘½ä¸­ç‡
  - é¢æ¿4: æ¨¡å‹å¥åº·çŠ¶æ€
  - é¢æ¿5: å‘é‡å­˜å‚¨ç»Ÿè®¡
  - é¢æ¿6: é”™è¯¯åˆ†å¸ƒï¼ˆæŒ‰stageï¼‰
- [ ] ä½¿ç”¨ç°æœ‰æŒ‡æ ‡ï¼Œä¸ä¾èµ–Day 3-4æ–°å¢æŒ‡æ ‡

**éªŒæ”¶**:
- Dashboardå¯å¯¼å…¥Grafana
- é¢æ¿æ•°æ®æ­£ç¡®å±•ç¤º
- æ—¶é—´èŒƒå›´é€‰æ‹©å™¨å·¥ä½œæ­£å¸¸

#### ä»»åŠ¡ 3.2: Prometheuså½•åˆ¶è§„åˆ™åŸºç¡€ç‰ˆ
- [ ] åˆ›å»º `config/prometheus/recording_rules.yml`
  ```yaml
  groups:
    - name: cad_analysis_aggregations
      interval: 30s
      rules:
        - record: cad:analysis_requests:rate5m
          expr: rate(analysis_requests_total[5m])

        - record: cad:analysis_success_rate:5m
          expr: |
            rate(analysis_requests_total{status="success"}[5m])
            /
            rate(analysis_requests_total[5m])

        - record: cad:feature_cache_hit_rate:1h
          expr: |
            sum(rate(feature_cache_hits_total[1h]))
            /
            (sum(rate(feature_cache_hits_total[1h])) + sum(rate(feature_cache_miss_total[1h])))
  ```
- [ ] è¿è¡Œ `promtool check rules config/prometheus/recording_rules.yml`

**éªŒæ”¶**:
- promtooléªŒè¯é€šè¿‡
- è§„åˆ™è¯­æ³•æ­£ç¡®

---

### ğŸŒ† PM Session (4h) - Phase C-1

#### ä»»åŠ¡ 3.3: Pickle Opcode Auditæ¨¡å¼
- [ ] æ‰©å±• `src/ml/classifier.py` reload_model
  - å¢åŠ  `MODEL_OPCODE_MODE` ç¯å¢ƒå˜é‡æ”¯æŒ
    - `audit`: æ‰«æä½†ä¸é˜»æ–­ï¼Œè®°å½•æ—¥å¿—
    - `blocklist`: å½“å‰è¡Œä¸ºï¼Œé˜»æ–­å±é™©opcode
    - `whitelist`: ä»…å…è®¸å®‰å…¨opcodeï¼ˆé¢„ç•™ï¼‰
  - å®ç° opcode æ‰«æé€»è¾‘
    ```python
    import pickletools

    def scan_pickle_opcodes(file_path: Path) -> Dict[str, Any]:
        """æ‰«æpickleæ–‡ä»¶ä¸­çš„opcode"""
        opcodes = []
        with file_path.open("rb") as f:
            for opcode, arg, pos in pickletools.genops(f):
                opcodes.append(opcode.name)

        dangerous = ["GLOBAL", "INST", "BUILD", "REDUCE"]
        found_dangerous = [op for op in opcodes if op in dangerous]

        return {
            "opcodes": opcodes,
            "dangerous": found_dangerous,
            "safe": len(found_dangerous) == 0
        }
    ```
  - åœ¨ audit æ¨¡å¼è®°å½•ä½†ç»§ç»­åŠ è½½
  - åœ¨ blocklist æ¨¡å¼æ‹’ç»å¹¶è¿”å› `opcode_blocked`
- [ ] æ·»åŠ æŒ‡æ ‡
  ```python
  model_opcode_mode = Gauge(
      "model_opcode_mode",
      "Current opcode validation mode (0=audit, 1=blocklist, 2=whitelist)"
  )
  ```
- [ ] æ›´æ–° `model_security_fail_total{reason="opcode_blocked"}`

**éªŒæ”¶**:
- Auditæ¨¡å¼è®°å½•ä½†ä¸é˜»æ–­
- Blocklistæ¨¡å¼æ­£ç¡®æ‹’ç»
- æ—¥å¿—åŒ…å«å…·ä½“opcodeä¿¡æ¯

#### ä»»åŠ¡ 3.4: å®‰å…¨æµç¨‹å›¾æ–‡æ¡£
- [ ] åˆ›å»º `docs/SECURITY_MODEL_LOADING.md`
  - æ¨¡å‹åŠ è½½å®‰å…¨æµç¨‹å›¾ï¼ˆMermaidï¼‰
  - ä¸‰ç§æ¨¡å¼å¯¹æ¯”è¡¨æ ¼
  - å¿«é€Ÿæ’é”™æŒ‡å—ï¼ˆhash mismatch / opcode blocked / magic invalidï¼‰
- [ ] æ›´æ–° README å®‰å…¨ç« èŠ‚

**éªŒæ”¶**:
- æµç¨‹å›¾æ¸…æ™°æ˜“æ‡‚
- æ’é”™æŒ‡å—å¯æ“ä½œ

#### ä»»åŠ¡ 3.5: v4å‡ ä½•ç®—æ³•é¢„ç ”
- [ ] å‡†å¤‡æµ‹è¯•æ•°æ®é›†
  - ç©ºå®ä½“CADæ–‡ä»¶
  - å•å®ä½“ç®€å•å‡ ä½•
  - å¤šå®ä½“å¤æ‚å‡ ä½•ï¼ˆé«˜å¤šæ ·æ€§ï¼‰
- [ ] è°ƒç ”å‡ ä½•ç»†åˆ†ç®—æ³•
  - é€‰æ‹©åº“ï¼šOCC/trimesh/å…¶ä»–
  - è¯„ä¼°æ€§èƒ½å½±å“

**éªŒæ”¶**:
- æµ‹è¯•æ•°æ®é›†å°±ç»ª
- ç®—æ³•é€‰å‹æ–‡æ¡£

---

## Day 4: Phase C-2 + Phase D-1

### ğŸŒ… AM Session (4h) - Phase C-2 + Phase DåŸºç¡€

#### ä»»åŠ¡ 4.1: æ¥å£æ ¡éªŒæ‰©å±•
- [ ] æ‰©å±• `src/ml/classifier.py` reload_model
  - æ£€æŸ¥æ¨¡å‹å¯¹è±¡å±æ€§æ•°é‡ï¼ˆé˜²æ­¢large attribute graphï¼‰
  - æ£€æŸ¥ `__reduce__` ç­‰é­”æœ¯æ–¹æ³•
  - éªŒè¯predictæ–¹æ³•ç­¾å
- [ ] æ·»åŠ æŒ‡æ ‡
  ```python
  model_interface_validation_fail_total = Counter(
      "model_interface_validation_fail_total",
      "Model interface validation failures",
      ["reason"],  # large_graph|suspicious_method|invalid_signature
  )
  ```
- [ ] åˆ›å»ºæµ‹è¯• `tests/unit/test_model_interface_validation.py`

**éªŒæ”¶**:
- å¤§å¯¹è±¡å›¾è¢«æ‹’ç»
- å¯ç–‘æ–¹æ³•è¢«æ ‡è®°
- æŒ‡æ ‡æ­£ç¡®è®°å½•

#### ä»»åŠ¡ 4.2: å›æ»šå±‚çº§3å®ç°
- [ ] æ‰©å±•æ¨¡å‹å¿«ç…§ç³»ç»Ÿ
  ```python
  # å·²æœ‰: _MODEL_PREV, _MODEL_PREV2
  # æ–°å¢: _MODEL_PREV3
  _MODEL_PREV3: Dict[str, Any] | None = None
  _MODEL_PREV3_HASH: str | None = None
  _MODEL_PREV3_VERSION: str | None = None
  _MODEL_PREV3_PATH: Path | None = None
  ```
- [ ] æ›´æ–°å›æ»šé€»è¾‘æ”¯æŒ3çº§
- [ ] åˆ›å»ºæµ‹è¯• `tests/unit/test_model_rollback_level3.py`
  - æ¨¡æ‹Ÿ4æ¬¡åŠ è½½ï¼Œ3æ¬¡å¤±è´¥
  - éªŒè¯å±‚çº§æ¨è¿›/å›é€€

**éªŒæ”¶**:
- 3çº§å›æ»šé€»è¾‘æ­£ç¡®
- å¿«ç…§é“¾å®Œæ•´
- æµ‹è¯•è¦†ç›–æ‰€æœ‰å±‚çº§

#### ä»»åŠ¡ 4.3: v4 surface_count åŸºç¡€ç‰ˆæœ¬
- [ ] åœ¨ `src/core/feature_extractor.py` å®ç°
  ```python
  def extract_surface_count_v4(doc: CadDocument, mode: str = "simple") -> int:
      """æå–è¡¨é¢æ•°é‡

      Args:
          doc: CADæ–‡æ¡£å¯¹è±¡
          mode: simple | advancedï¼ˆå‡ ä½•ç»†åˆ†ï¼‰
      """
      if mode == "simple":
          # åŸºäºå®ä½“æ•°é‡ä¼°ç®—
          return len(doc.entities) * 6  # å‡è®¾æ¯å®ä½“6é¢ï¼ˆç«‹æ–¹ä½“ï¼‰
      else:
          # TODO: å®ç°é«˜çº§å‡ ä½•ç»†åˆ†
          raise NotImplementedError("Advanced surface counting not ready")
  ```
- [ ] æ·»åŠ å•æµ‹ `tests/unit/test_v4_surface_count.py`
  - ç©ºå®ä½“ â†’ 0
  - å•ç«‹æ–¹ä½“ â†’ 6
  - å¤æ‚æ¨¡å‹ï¼ˆå·²çŸ¥é¢æ•°ï¼‰

**éªŒæ”¶**:
- Simpleæ¨¡å¼å·¥ä½œæ­£å¸¸
- å•æµ‹é€šè¿‡
- æ€§èƒ½å¯æ¥å—

---

### ğŸŒ† PM Session (4h) - Phase D-1

#### ä»»åŠ¡ 4.4: v4 shape_entropy å¹³æ»‘å¤„ç†
- [ ] å®ç°Laplaceå¹³æ»‘
  ```python
  def calculate_shape_entropy_v4(entities: List[Entity], smoothing: float = 1.0) -> float:
      """è®¡ç®—å½¢çŠ¶ç†µï¼ˆå¸¦å¹³æ»‘ï¼‰

      Args:
          entities: å®ä½“åˆ—è¡¨
          smoothing: Laplaceå¹³æ»‘å‚æ•°ï¼ˆé»˜è®¤1.0ï¼‰
      """
      from collections import Counter
      import math

      if not entities:
          return 0.0

      type_counts = Counter(e.type for e in entities)
      total = sum(type_counts.values())
      vocab_size = len(type_counts)

      # Laplaceå¹³æ»‘
      entropy = 0.0
      for count in type_counts.values():
          p = (count + smoothing) / (total + smoothing * vocab_size)
          entropy -= p * math.log2(p)

      # å½’ä¸€åŒ–åˆ°[0, 1]
      max_entropy = math.log2(vocab_size) if vocab_size > 1 else 1.0
      return entropy / max_entropy
  ```
- [ ] æ·»åŠ å•æµ‹éªŒè¯
  - å•ä¸€ç±»å‹ â†’ 0.0ï¼ˆå®Œå…¨ç¡®å®šï¼‰
  - å‡åŒ€åˆ†å¸ƒ â†’ æ¥è¿‘1.0ï¼ˆæœ€å¤§ä¸ç¡®å®šæ€§ï¼‰
  - è¾¹ç•Œcaseï¼ˆç©ºåˆ—è¡¨/å•å…ƒç´ ï¼‰

**éªŒæ”¶**:
- ç†µå€¼ âˆˆ [0, 1]
- å¹³æ»‘é¿å…NaN
- å•æµ‹è¾¹ç•Œcaseé€šè¿‡

#### ä»»åŠ¡ 4.5: v4æ€§èƒ½å¯¹æ¯”æµ‹è¯•
- [ ] åˆ›å»º `tests/performance/test_v4_performance.py`
  ```python
  @pytest.mark.slow
  def test_v4_extraction_overhead():
      """æµ‹è¯•v4ç‰¹å¾æå–æ€§èƒ½å¼€é”€"""
      # å‡†å¤‡æµ‹è¯•æ•°æ®
      test_files = load_test_cad_files(count=20)

      # æµ‹è¯•v3
      v3_times = []
      for f in test_files:
          start = time.time()
          extract_features_v3(f)
          v3_times.append(time.time() - start)

      # æµ‹è¯•v4
      v4_times = []
      for f in test_files:
          start = time.time()
          extract_features_v4(f)
          v4_times.append(time.time() - start)

      v3_p95 = np.percentile(v3_times, 95)
      v4_p95 = np.percentile(v4_times, 95)
      overhead = (v4_p95 - v3_p95) / v3_p95

      assert overhead < 0.05, f"v4 overhead {overhead:.1%} exceeds 5% limit"
  ```
- [ ] è®°å½•åŸºçº¿æ•°æ®

**éªŒæ”¶**:
- v4 æå–è€—æ—¶ â‰¤ v3 * 1.05
- å¦‚è¶…è¿‡5%ï¼Œé™çº§åˆ°simpleæ¨¡å¼

---

## Day 5: Phase D-2 + Phase E-1

### ğŸŒ… AM Session (4h) - Phase D-2

#### ä»»åŠ¡ 5.1: è¿ç§»å·¥å…·previewç«¯ç‚¹
- [ ] æ‰©å±• `src/api/v1/vectors.py` æˆ–æ–°å»º `src/api/v1/migrate.py`
  ```python
  @router.get("/migrate/preview")  # å·²æ›´æ–°: é¢„è§ˆè¿ç§»æ”¹ä¸ºGETå¹¶æŒ‚è½½åœ¨ /api/v1/vectors/migrate/preview
  async def migrate_preview(
      from_version: str,
      to_version: str,
      sample_ids: List[str] = Query(default=[], max_length=10)
  ):
      """é¢„è§ˆè¿ç§»å½±å“

      Returns:
          - dimension_change: int (delta)
          - affected_vectors: int
          - top_dimension_changes: List[Tuple[slot_idx, old_val, new_val]]
          - estimated_time: float (seconds)
      """
  ```
- [ ] å®ç°é¢„è§ˆé€»è¾‘ï¼ˆä¸å®é™…è¿ç§»ï¼‰
- [ ] æ·»åŠ æµ‹è¯•

**éªŒæ”¶**:
- é¢„è§ˆä¸ä¿®æ”¹æ•°æ®
- ç»´åº¦å˜åŒ–ç»Ÿè®¡æ­£ç¡®
- å“åº”æ—¶é—´ < 2s

#### ä»»åŠ¡ 5.2: è¿ç§»è¶‹åŠ¿ç«¯ç‚¹
- [ ] å®ç° `/vectors/migrate/trends`
  ```python
  @router.get("/vectors/migrate/trends")
  async def migrate_trends(window_hours: int = 24):
      """è·å–è¿ç§»è¶‹åŠ¿

      Returns:
          - total_migrations: int
          - success_rate: float
          - v4_adoption_rate: float
          - avg_dimension_delta: float
          - hourly_breakdown: List[dict]
      """
  ```
- [ ] ä»æŒ‡æ ‡æŸ¥è¯¢å†å²æ•°æ®
- [ ] æ·»åŠ æµ‹è¯•

**éªŒæ”¶**:
- è¶‹åŠ¿æ•°æ®å‡†ç¡®
- å¯ç”¨äºDashboardé›†æˆ

#### ä»»åŠ¡ 5.3: Dashboardè¡¥å……Day 3-4æ–°æŒ‡æ ‡
- [ ] æ›´æ–° `config/grafana/dashboard_main.json`
  - é¢æ¿7: v4ç‰¹å¾æå–å»¶è¿Ÿå¯¹æ¯”ï¼ˆv3 vs v4ï¼‰
  - é¢æ¿8: è¿ç§»ç»´åº¦å·®å¼‚ç›´æ–¹å›¾
  - é¢æ¿9: æ¨¡å‹å®‰å…¨å¤±è´¥åˆ†å¸ƒï¼ˆæŒ‰reasonï¼‰
  - é¢æ¿10: ç¼“å­˜è°ƒä¼˜å»ºè®®å†å²
  - é¢æ¿11: Opcodeæ¨¡å¼å½“å‰å€¼
  - é¢æ¿12: æ¼‚ç§»åˆ·æ–°è§¦å‘é¥¼å›¾
- [ ] éªŒè¯æ‰€æœ‰é¢æ¿æ•°æ®æº

**éªŒæ”¶**:
- Dashboardå®Œæ•´åº¦100%
- æ‰€æœ‰é¢æ¿æ­£å¸¸å±•ç¤º

---

### ğŸŒ† PM Session (4h) - Phase E-1

#### ä»»åŠ¡ 5.4: Prometheus Ruleså®Œæ•´ç‰ˆ
- [ ] åˆ›å»º `config/prometheus/alert_rules.yml`
  ```yaml
  groups:
    - name: cad_analysis_alerts
      rules:
        - alert: FeatureExtractionV4SlowDown
          expr: |
            histogram_quantile(0.95,
              rate(feature_extraction_latency_seconds_bucket{version="v4"}[5m])
            ) >
            histogram_quantile(0.95,
              rate(feature_extraction_latency_seconds_bucket{version="v3"}[5m])
            ) * 1.5
          for: 10m
          labels:
            severity: warning
          annotations:
            summary: "v4 feature extraction significantly slower than v3"

        - alert: ModelOpcodeBlocked
          expr: increase(model_security_fail_total{reason="opcode_blocked"}[5m]) > 0
          for: 1m
          labels:
            severity: critical
          annotations:
            summary: "Dangerous pickle opcode detected and blocked"

        - alert: CacheHitRateLow
          expr: cad:feature_cache_hit_rate:1h < 0.35
          for: 30m
          labels:
            severity: warning
          annotations:
            summary: "Feature cache hit rate below 35% for 30 minutes"
  ```
- [ ] è¿è¡Œ `promtool check rules` éªŒè¯

**éªŒæ”¶**:
- æ‰€æœ‰å‘Šè­¦è§„åˆ™è¯­æ³•æ­£ç¡®
- é˜ˆå€¼åˆç†
- å‘Šè­¦åˆ†çº§æ˜ç¡®ï¼ˆcritical/warning/infoï¼‰

#### ä»»åŠ¡ 5.5: æ–‡æ¡£å…¨é¢æ›´æ–°
- [ ] æ›´æ–° `README.md`
  - æ–°å¢ç«¯ç‚¹æ–‡æ¡£ï¼ˆcache/tuning, migrate/preview, migrate/trendsï¼‰
  - ç¯å¢ƒå˜é‡è¡¨æ ¼æ–°å¢ï¼ˆMODEL_OPCODE_MODE, FEATURE_V4_*ï¼‰
  - æŒ‡æ ‡ç´¢å¼•æ›´æ–°ï¼ˆæ–°å¢8ä¸ªæŒ‡æ ‡ï¼‰
- [ ] åˆ›å»º `docs/ERROR_SCHEMA.md`
  ```markdown
  # ç»Ÿä¸€é”™è¯¯å“åº”Schema

  | Field | Type | Description |
  |-------|------|-------------|
  | code | str | é”™è¯¯ä»£ç ï¼ˆå¤§å†™ä¸‹åˆ’çº¿ï¼‰ |
  | stage | str | å‘ç”Ÿé˜¶æ®µ |
  | message | str | äººç±»å¯è¯»æè¿° |
  | context | dict | ä¸Šä¸‹æ–‡ä¿¡æ¯ |

  ## å¸¸è§Stage
  - `routing`: è·¯ç”±å±‚
  - `batch_similarity`: æ‰¹é‡ç›¸ä¼¼åº¦
  - `vector_migrate`: å‘é‡è¿ç§»
  - `feature_slots`: ç‰¹å¾æ§½ä½
  - `model_reload`: æ¨¡å‹é‡è½½
  - `security`: å®‰å…¨éªŒè¯
  - `drift`: æ¼‚ç§»æ£€æµ‹
  ```
- [ ] åˆ›å»º `docs/METRICS_INDEX.md`
  - æ‰€æœ‰æŒ‡æ ‡åˆ—è¡¨
  - PromQLæŸ¥è¯¢ç¤ºä¾‹
  - å¯è§†åŒ–å»ºè®®
- [ ] æ›´æ–° `CHANGELOG.md`

**éªŒæ”¶**:
- æ–‡æ¡£æ— æ­»é“¾
- ä»£ç ç¤ºä¾‹å¯æ‰§è¡Œ
- æ¸²æŸ“æ— æ ¼å¼é”™è¯¯

---

## Day 6: Phase E-2 + Phase F

### ğŸŒ… AM Session (4h) - Phase E-2

#### ä»»åŠ¡ 6.1: Prometheus Ruleså›å½’éªŒè¯
- [ ] è¿è¡Œå®Œæ•´éªŒè¯
  ```bash
  promtool check rules config/prometheus/recording_rules.yml
  promtool check rules config/prometheus/alert_rules.yml
  ```
- [ ] ä¿®å¤ä»»ä½•è¯­æ³•é”™è¯¯
- [ ] éªŒè¯æŒ‡æ ‡ä¾èµ–å­˜åœ¨

**éªŒæ”¶**:
- æ‰€æœ‰è§„åˆ™éªŒè¯é€šè¿‡
- æ— missing metricè­¦å‘Š

#### ä»»åŠ¡ 6.2: CIé¢„æ£€æŸ¥è„šæœ¬
- [ ] åˆ›å»º `scripts/check_metrics_consistency.py`
  ```python
  #!/usr/bin/env python3
  """éªŒè¯metricså®šä¹‰ä¸__all__å¯¼å‡ºä¸€è‡´æ€§"""
  import ast
  import re
  from pathlib import Path

  def extract_metric_definitions(file_path: Path):
      """æå–Counter/Histogram/Gaugeå®šä¹‰"""
      with open(file_path) as f:
          content = f.read()

      # æ­£åˆ™åŒ¹é… metric_name = Counter(...) ç­‰
      pattern = r'(\w+)\s*=\s*(Counter|Histogram|Gauge)\('
      return [m.group(1) for m in re.finditer(pattern, content)]

  def extract_all_exports(file_path: Path):
      """æå–__all__åˆ—è¡¨"""
      with open(file_path) as f:
          tree = ast.parse(f.read())

      for node in ast.walk(tree):
          if isinstance(node, ast.Assign):
              for target in node.targets:
                  if isinstance(target, ast.Name) and target.id == '__all__':
                      return [elt.s for elt in node.value.elts]
      return []

  def main():
      metrics_file = Path("src/utils/analysis_metrics.py")

      defined = set(extract_metric_definitions(metrics_file))
      exported = set(extract_all_exports(metrics_file))

      missing = defined - exported
      extra = exported - defined

      if missing:
          print(f"âŒ Metrics defined but not exported: {missing}")
          return 1
      if extra:
          print(f"âš ï¸  Metrics exported but not defined: {extra}")

      print(f"âœ… All {len(defined)} metrics consistent")
      return 0

  if __name__ == "__main__":
      exit(main())
  ```
- [ ] æ·»åŠ åˆ° `.github/workflows/` æˆ– Makefile

**éªŒæ”¶**:
- è„šæœ¬æ£€æµ‹åˆ°ä¸ä¸€è‡´æ—¶é€€å‡ºç é0
- CIé›†æˆå®Œæˆ

#### ä»»åŠ¡ 6.3: æ€§èƒ½åŸºçº¿æµ‹è¯•
- [ ] è¿è¡Œ `scripts/performance_baseline.py`
  ```bash
  # æµ‹è¯•åœºæ™¯
  - å•æ–‡ä»¶åˆ†æ (å°/ä¸­/å¤§)
  - æ‰¹é‡ç›¸ä¼¼åº¦ (5/20/50 IDs)
  - ç‰¹å¾è¿ç§» (v3â†’v4, 100 vectors)
  - æ¨¡å‹åŠ è½½ (å†·å¯åŠ¨/çƒ­é‡è½½)
  ```
- [ ] è®°å½•p50/p95/p99å»¶è¿Ÿ
- [ ] ä¸Day 0åŸºçº¿å¯¹æ¯”

**éªŒæ”¶**:
- æ€§èƒ½æ— å›é€€ (< 5%)
- ç”Ÿæˆæ€§èƒ½æŠ¥å‘Šè¡¨æ ¼

---

### ğŸŒ† PM Session (4h) - Phase F

#### ä»»åŠ¡ 6.4: å›å½’æµ‹è¯•å¥—ä»¶
- [ ] åˆ›å»º `tests/regression/test_stateless_execution.py`
  ```python
  @pytest.mark.parametrize("order", [
      list(range(30)),
      list(range(30))[::-1],
      random.sample(range(30), 30)
  ])
  def test_critical_path_random_order(order):
      """éšæœºé¡ºåºæ‰§è¡Œå…³é”®æµ‹è¯•ï¼ŒéªŒè¯æ— çŠ¶æ€è€¦åˆ"""
      tests = load_critical_tests()  # 30ä¸ªæ ¸å¿ƒæµ‹è¯•
      for i in order:
          run_test_isolated(tests[i])
  ```
- [ ] è¿è¡Œ3æ¬¡éªŒè¯æ— é¡ºåºä¾èµ–

**éªŒæ”¶**:
- éšæœºé¡ºåºæµ‹è¯•å…¨éƒ¨é€šè¿‡
- æ— çŠ¶æ€æ³„æ¼

#### ä»»åŠ¡ 6.5: ç¼“å†²ä¸å»¶åä»»åŠ¡è¯„ä¼°
- [ ] è¯„ä¼°æ—¶é—´ä½™é‡
- [ ] å¦‚æœ‰ä½™é‡ï¼Œå®ç°å¯é€‰ä»»åŠ¡ï¼š
  - [ ] Drift baseline å¯¼å‡º/å¯¼å…¥ç«¯ç‚¹
    ```python
    @router.post("/drift/baseline/export")
    async def export_baseline():
        """å¯¼å‡ºå½“å‰baselineå¿«ç…§"""

    @router.post("/drift/baseline/import")
    async def import_baseline(data: BaselineSnapshot):
        """å¯¼å…¥baselineå¿«ç…§"""
    ```
  - [ ] Vector backend reload å®‰å…¨token
    ```python
    @router.post("/vectors/backend/reload")
    async def reload_backend(
        backend: str,
        token: str = Header(None, alias="X-Admin-Token")
    ):
        """é‡è½½å‘é‡åç«¯ï¼ˆéœ€è¦ç®¡ç†å‘˜tokenï¼‰"""
        if token != os.getenv("ADMIN_TOKEN"):
            raise HTTPException(403, "Invalid admin token")
    ```

**éªŒæ”¶**:
- å¦‚å®ç°ï¼Œæµ‹è¯•è¦†ç›–é½å…¨
- å¦‚æœªå®ç°ï¼Œè®°å½•åˆ°ä¸‹ä¸ªè¿­ä»£

#### ä»»åŠ¡ 6.6: æœ€ç»ˆéªŒè¯ä¸æ–‡æ¡£
- [ ] è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶
  ```bash
  pytest -v --cov=src --cov-report=html
  ```
- [ ] ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
- [ ] æ›´æ–° `IMPLEMENTATION_RESULTS.md`ï¼ˆå¼€å‘æˆæœæ–‡æ¡£ï¼‰
- [ ] Gitæäº¤æ•´ç†

**éªŒæ”¶**:
- æµ‹è¯•é€šè¿‡ç‡ 100%
- è¦†ç›–ç‡ â‰¥ 85%
- æˆæœæ–‡æ¡£å®Œæ•´

---

## ğŸ“Š æ¯æ—¥æ£€æŸ¥ç‚¹

æ¯å¤©ä¸‹åˆ4ç‚¹æ‰§è¡Œï¼š
```bash
./scripts/daily_checkpoint.sh
```

è¾“å‡ºå†…å®¹ï¼š
- [ ] å½“æ—¥ä»»åŠ¡å®Œæˆç‡
- [ ] æµ‹è¯•é€šè¿‡æ•°/å¤±è´¥æ•°
- [ ] ä»£ç è¦†ç›–ç‡å˜åŒ–
- [ ] æ–°å¢æŒ‡æ ‡æ•°é‡
- [ ] æ€§èƒ½å¯¹æ¯”ï¼ˆå¦‚é€‚ç”¨ï¼‰
- [ ] é˜»å¡é—®é¢˜åˆ—è¡¨

---

## ğŸ¯ ä¼˜å…ˆçº§æ ‡ç­¾

**P0 (å¿…é¡»å®Œæˆ)**:
- æ‰€æœ‰Phase Aæµ‹è¯•
- å®‰å…¨å¢å¼ºæ ¸å¿ƒåŠŸèƒ½ (Opcode audit/blocklist)
- v4åŸºç¡€ç‰ˆæœ¬ (simpleæ¨¡å¼)
- æ ¸å¿ƒæ–‡æ¡£æ›´æ–° (README/ERROR_SCHEMA)

**P1 (å¼ºçƒˆå»ºè®®)**:
- Dashboardå®Œæ•´ç‰ˆ
- ç¼“å­˜è°ƒä¼˜ç«¯ç‚¹
- Prometheus ruleså®Œæ•´ç‰ˆ
- æ€§èƒ½åŸºçº¿æµ‹è¯•

**P2 (æ—¶é—´å…è®¸)**:
- v4 advancedæ¨¡å¼
- Drift export/import
- è‡ªåŠ¨TTLè°ƒæ•´PoC
- Backend reloadå®‰å…¨token

---

## ğŸš¨ é£é™©ç¼“è§£

### å¦‚Day 4 v4å®ç°å»¶æœŸ
- **é™çº§æ–¹æ¡ˆ**: v4ä»…å®ç°entropyä¼˜åŒ–ï¼Œsurface_countæ ‡è®°experimental
- **å¼€å…³æ§åˆ¶**: `FEATURE_V4_SURFACE_ALGORITHM=simple`

### å¦‚å®‰å…¨ç™½åå•è¿‡ä¸¥
- **å›é€€ç­–ç•¥**: `MODEL_OPCODE_MODE=audit` æ¨¡å¼è¿è¡Œ1-2å¤©è§‚å¯Ÿ
- **è®°å½•æœºåˆ¶**: æ‰€æœ‰é˜»æ–­æ ·æœ¬æ—¥å¿—åˆ° `logs/opcode_blocks.json`

### å¦‚æµ‹è¯•è¦†ç›–ç‡ä¸è¾¾æ ‡
- **æœ€å°é˜ˆå€¼**: P0åŠŸèƒ½ â‰¥90%, P1åŠŸèƒ½ â‰¥80%, P2åŠŸèƒ½ â‰¥70%
- **è±å…æœºåˆ¶**: æ€§èƒ½æµ‹è¯•ã€é›†æˆæµ‹è¯•å¯æ ‡è®° `@pytest.mark.slow` ä¸è®¡å…¥è¦†ç›–ç‡

---

## âœ… æœ€ç»ˆäº¤ä»˜ç‰©æ¸…å•

- [ ] æ›´æ–°ä»£ç æ¨¡å—ï¼ˆ~15ä¸ªæ–‡ä»¶ï¼‰
- [ ] æ–°å¢æµ‹è¯•å¥—ä»¶ï¼ˆ~12ä¸ªæ–‡ä»¶ï¼‰
- [ ] å®Œæ•´READMEæ›´æ–°
- [ ] CHANGELOG.mdæ–°ç‰ˆæœ¬æ®µ
- [ ] ERROR_SCHEMA.mdæ–‡æ¡£
- [ ] METRICS_INDEX.mdæ–‡æ¡£
- [ ] SECURITY_MODEL_LOADING.mdæ–‡æ¡£
- [ ] Dashboard JSON (config/grafana/)
- [ ] Prometheus rules (config/prometheus/)
- [ ] æµ‹è¯•è¦†ç›–ç‡æŠ¥å‘Š (htmlcov/)
- [ ] æ€§èƒ½åŸºçº¿æŠ¥å‘Š (reports/performance_baseline.md)
- [ ] å›å½’éªŒè¯è®°å½• (reports/regression_validation.md)
- [ ] **å¼€å‘æˆæœæ€»ç»“** (`IMPLEMENTATION_RESULTS.md`)

---

**Last Updated**: 2025-11-24
**Status**: Ready to start
**Estimated Completion**: 6 working days
