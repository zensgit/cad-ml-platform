#!/usr/bin/env python3
"""
é”™è¯¯ç ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨
Error Code Lifecycle Manager - ç®¡ç†é”™è¯¯ç çš„å®Œæ•´ç”Ÿå‘½å‘¨æœŸ
"""

import os
import sys
import json
import subprocess
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
from pathlib import Path
from collections import defaultdict
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from scripts.error_code_scanner import ErrorCodeScanner, ErrorCode

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class CleanupPlan:
    """æ¸…ç†è®¡åˆ’"""
    def __init__(self):
        self.immediate_removal = []  # ç«‹å³åˆ é™¤
        self.deprecation = []        # æ ‡è®°å¼ƒç”¨
        self.consolidation = []      # åˆå¹¶é‡å¤
        self.monitoring = []         # ç»§ç»­ç›‘æ§
        self.migration_guide = {}    # è¿ç§»æŒ‡å—


class ErrorCodeLifecycleManager:
    """é”™è¯¯ç ç”Ÿå‘½å‘¨æœŸç®¡ç†"""

    def __init__(self, config_file: Optional[str] = None):
        """
        åˆå§‹åŒ–ç®¡ç†å™¨

        Args:
            config_file: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config = self._load_config(config_file)
        self.scanner = ErrorCodeScanner()
        self.history_file = Path('data/error_code_history.json')
        self.history = self._load_history()

    def _load_config(self, config_file: Optional[str]) -> Dict:
        """åŠ è½½é…ç½®"""
        default_config = {
            'thresholds': {
                'unused_days': 60,           # æœªä½¿ç”¨å¤©æ•°é˜ˆå€¼
                'rare_usage_count': 10,       # ç¨€æœ‰ä½¿ç”¨æ¬¡æ•°é˜ˆå€¼
                'deprecation_days': 30,       # å¼ƒç”¨ä¿ç•™å¤©æ•°
                'min_usage_for_active': 100   # æ´»è·ƒä½¿ç”¨çš„æœ€ä½æ¬¡æ•°
            },
            'policies': {
                'auto_remove_unused': True,   # è‡ªåŠ¨åˆ é™¤æœªä½¿ç”¨
                'auto_deprecate_rare': True,  # è‡ªåŠ¨å¼ƒç”¨ç¨€æœ‰
                'merge_duplicates': True,     # åˆå¹¶é‡å¤
                'require_migration_doc': True # éœ€è¦è¿ç§»æ–‡æ¡£
            },
            'exclusions': {
                'protected_codes': [],        # å—ä¿æŠ¤çš„é”™è¯¯ç ï¼ˆä¸èƒ½åˆ é™¤ï¼‰
                'ignore_patterns': []         # å¿½ç•¥çš„æ¨¡å¼
            }
        }

        if config_file and Path(config_file).exists():
            with open(config_file, 'r') as f:
                user_config = json.load(f)
                # æ·±åº¦åˆå¹¶é…ç½®
                self._merge_config(default_config, user_config)

        return default_config

    def _merge_config(self, base: dict, override: dict):
        """æ·±åº¦åˆå¹¶é…ç½®"""
        for key, value in override.items():
            if key in base and isinstance(base[key], dict) and isinstance(value, dict):
                self._merge_config(base[key], value)
            else:
                base[key] = value

    def _load_history(self) -> Dict:
        """åŠ è½½å†å²è®°å½•"""
        if self.history_file.exists():
            with open(self.history_file, 'r') as f:
                return json.load(f)
        return {
            'scans': [],
            'cleanups': [],
            'error_code_lifecycle': {}
        }

    def _save_history(self):
        """ä¿å­˜å†å²è®°å½•"""
        self.history_file.parent.mkdir(exist_ok=True)
        with open(self.history_file, 'w') as f:
            json.dump(self.history, f, indent=2, default=str)

    def analyze_lifecycle(self) -> Dict[str, Any]:
        """
        åˆ†æé”™è¯¯ç ç”Ÿå‘½å‘¨æœŸ

        Returns:
            ç”Ÿå‘½å‘¨æœŸåˆ†æç»“æœ
        """
        logger.info("å¼€å§‹åˆ†æé”™è¯¯ç ç”Ÿå‘½å‘¨æœŸ...")

        # æ‰§è¡Œæ‰«æ
        scan_results = self.scanner.scan_all()

        # è®°å½•æ‰«æå†å²
        self.history['scans'].append({
            'timestamp': datetime.now().isoformat(),
            'summary': scan_results['summary']
        })

        # åˆ†æç”Ÿå‘½å‘¨æœŸçŠ¶æ€
        lifecycle_analysis = self._analyze_lifecycle_status(scan_results)

        # ç”Ÿæˆæ¸…ç†è®¡åˆ’
        cleanup_plan = self.generate_cleanup_plan(scan_results, lifecycle_analysis)

        # ä¿å­˜å†å²
        self._save_history()

        return {
            'scan_results': scan_results,
            'lifecycle_analysis': lifecycle_analysis,
            'cleanup_plan': cleanup_plan
        }

    def _analyze_lifecycle_status(self, scan_results: Dict) -> Dict[str, Any]:
        """åˆ†æç”Ÿå‘½å‘¨æœŸçŠ¶æ€"""
        classification = scan_results['classification']
        definitions = scan_results['definitions']
        log_stats = scan_results['log_stats']

        lifecycle_status = {
            'healthy': [],      # å¥åº·çš„
            'at_risk': [],      # æœ‰é£é™©çš„
            'unhealthy': [],    # ä¸å¥åº·çš„
            'critical': []      # ä¸¥é‡é—®é¢˜çš„
        }

        # åˆ†ææ¯ä¸ªé”™è¯¯ç çš„å¥åº·çŠ¶æ€
        for code, error_code in definitions.items():
            status = error_code.status
            usage_count = log_stats.get(code, 0)

            # æ›´æ–°ç”Ÿå‘½å‘¨æœŸå†å²
            if code not in self.history['error_code_lifecycle']:
                self.history['error_code_lifecycle'][code] = {
                    'first_seen': datetime.now().isoformat(),
                    'last_seen': None,
                    'usage_history': []
                }

            lifecycle_record = self.history['error_code_lifecycle'][code]
            lifecycle_record['usage_history'].append({
                'date': datetime.now().isoformat(),
                'count': usage_count,
                'status': status
            })

            # åˆ¤æ–­å¥åº·çŠ¶æ€
            if status == 'ACTIVE' and usage_count > self.config['thresholds']['min_usage_for_active']:
                lifecycle_status['healthy'].append(code)
            elif status == 'RARE' or usage_count < self.config['thresholds']['rare_usage_count']:
                lifecycle_status['at_risk'].append(code)
            elif status in ['UNUSED', 'ZOMBIE']:
                lifecycle_status['unhealthy'].append(code)
            elif status in ['DEPRECATED', 'DUPLICATE', 'ORPHAN']:
                lifecycle_status['critical'].append(code)

            # æ›´æ–°æœ€åä½¿ç”¨æ—¶é—´
            if usage_count > 0:
                lifecycle_record['last_seen'] = datetime.now().isoformat()

        return lifecycle_status

    def generate_cleanup_plan(
        self,
        scan_results: Dict,
        lifecycle_analysis: Dict
    ) -> CleanupPlan:
        """
        ç”Ÿæˆæ¸…ç†è®¡åˆ’

        Args:
            scan_results: æ‰«æç»“æœ
            lifecycle_analysis: ç”Ÿå‘½å‘¨æœŸåˆ†æ

        Returns:
            æ¸…ç†è®¡åˆ’
        """
        plan = CleanupPlan()
        classification = scan_results['classification']
        definitions = scan_results['definitions']
        duplicates = scan_results['duplicates']

        # 1. å¤„ç†æœªä½¿ç”¨çš„é”™è¯¯ç 
        for code in classification['UNUSED']:
            if self._is_protected(code):
                plan.monitoring.append(code)
                continue

            # æ£€æŸ¥æœªä½¿ç”¨å¤©æ•°
            lifecycle_record = self.history['error_code_lifecycle'].get(code, {})
            first_seen = lifecycle_record.get('first_seen')
            last_seen = lifecycle_record.get('last_seen')

            if first_seen:
                first_seen_date = datetime.fromisoformat(first_seen)
                days_since_first = (datetime.now() - first_seen_date).days

                if days_since_first > self.config['thresholds']['unused_days']:
                    plan.immediate_removal.append(code)
                elif days_since_first > self.config['thresholds']['deprecation_days']:
                    plan.deprecation.append(code)
                else:
                    plan.monitoring.append(code)
            else:
                # æ–°å‘ç°çš„æœªä½¿ç”¨ç ï¼Œå…ˆç›‘æ§
                plan.monitoring.append(code)

        # 2. å¤„ç†åƒµå°¸é”™è¯¯ç ï¼ˆæ›¾ç»ä½¿ç”¨è¿‡ä½†ç°åœ¨æ²¡äº†ï¼‰
        for code in classification['ZOMBIE']:
            if not self._is_protected(code):
                plan.immediate_removal.append(code)

        # 3. å¤„ç†ç¨€æœ‰ä½¿ç”¨çš„é”™è¯¯ç 
        for code in classification['RARE']:
            if not self._is_protected(code) and self.config['policies']['auto_deprecate_rare']:
                plan.deprecation.append(code)
            else:
                plan.monitoring.append(code)

        # 4. å¤„ç†é‡å¤å®šä¹‰
        if self.config['policies']['merge_duplicates']:
            for code in duplicates:
                plan.consolidation.append({
                    'code': code,
                    'locations': duplicates[code]
                })

        # 5. ç”Ÿæˆè¿ç§»æŒ‡å—
        if self.config['policies']['require_migration_doc']:
            plan.migration_guide = self._generate_migration_guide(plan)

        return plan

    def _is_protected(self, code: str) -> bool:
        """æ£€æŸ¥é”™è¯¯ç æ˜¯å¦å—ä¿æŠ¤"""
        # æ£€æŸ¥æ˜¯å¦åœ¨ä¿æŠ¤åˆ—è¡¨ä¸­
        if code in self.config['exclusions']['protected_codes']:
            return True

        # æ£€æŸ¥æ˜¯å¦åŒ¹é…å¿½ç•¥æ¨¡å¼
        for pattern in self.config['exclusions']['ignore_patterns']:
            if pattern in code:
                return True

        return False

    def _generate_migration_guide(self, plan: CleanupPlan) -> Dict[str, Any]:
        """ç”Ÿæˆè¿ç§»æŒ‡å—"""
        guide = {
            'deprecation_timeline': {},
            'replacement_mapping': {},
            'migration_steps': []
        }

        # å¼ƒç”¨æ—¶é—´çº¿
        deprecation_date = datetime.now()
        removal_date = deprecation_date + timedelta(days=self.config['thresholds']['deprecation_days'])

        for code in plan.deprecation:
            guide['deprecation_timeline'][code] = {
                'deprecated_date': deprecation_date.isoformat(),
                'removal_date': removal_date.isoformat(),
                'grace_period_days': self.config['thresholds']['deprecation_days']
            }

        # æ›¿ä»£æ˜ å°„ï¼ˆè¿™é‡Œéœ€è¦æ™ºèƒ½åˆ†ææˆ–äººå·¥æŒ‡å®šï¼‰
        # æš‚æ—¶ä½¿ç”¨ç®€å•è§„åˆ™
        for code in plan.deprecation:
            # æŸ¥æ‰¾ç›¸ä¼¼çš„æ´»è·ƒé”™è¯¯ç ä½œä¸ºæ›¿ä»£
            # å®é™…å®ç°ä¸­åº”è¯¥æœ‰æ›´æ™ºèƒ½çš„æ˜ å°„é€»è¾‘
            guide['replacement_mapping'][code] = self._find_replacement(code)

        # è¿ç§»æ­¥éª¤
        guide['migration_steps'] = [
            "1. æ›´æ–°ä»£ç ä¸­çš„é”™è¯¯ç å¼•ç”¨",
            "2. æ›´æ–°æ–‡æ¡£å’ŒAPIè¯´æ˜",
            "3. é€šçŸ¥å®¢æˆ·ç«¯å›¢é˜Ÿ",
            "4. è®¾ç½®ç›‘æ§å‘Šè­¦",
            "5. åœ¨å®½é™æœŸååˆ é™¤æ—§é”™è¯¯ç "
        ]

        return guide

    def _find_replacement(self, code: str) -> Optional[str]:
        """æŸ¥æ‰¾æ›¿ä»£é”™è¯¯ç """
        # è¿™é‡Œåº”è¯¥æœ‰æ›´æ™ºèƒ½çš„é€»è¾‘
        # æ¯”å¦‚åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦æˆ–åŠŸèƒ½ç›¸ä¼¼åº¦
        # ç°åœ¨è¿”å›é€šç”¨æ›¿ä»£
        if 'NOT_FOUND' in code:
            return 'ERROR_NOT_FOUND'
        elif 'AUTH' in code:
            return 'ERROR_UNAUTHORIZED'
        elif 'INVALID' in code:
            return 'ERROR_INVALID_INPUT'
        else:
            return 'ERROR_GENERAL'

    def apply_cleanup_plan(self, plan: CleanupPlan, dry_run: bool = True) -> Dict[str, Any]:
        """
        åº”ç”¨æ¸…ç†è®¡åˆ’

        Args:
            plan: æ¸…ç†è®¡åˆ’
            dry_run: æ˜¯å¦ä¸ºæ¼”ç»ƒæ¨¡å¼

        Returns:
            åº”ç”¨ç»“æœ
        """
        results = {
            'removed': [],
            'deprecated': [],
            'consolidated': [],
            'errors': []
        }

        if dry_run:
            logger.info("æ¼”ç»ƒæ¨¡å¼ï¼šä¸ä¼šå®é™…ä¿®æ”¹æ–‡ä»¶")

        # 1. åˆ é™¤æœªä½¿ç”¨çš„é”™è¯¯ç 
        for code in plan.immediate_removal:
            try:
                if not dry_run:
                    self._remove_error_code(code)
                results['removed'].append(code)
                logger.info(f"{'[DRY RUN] ' if dry_run else ''}åˆ é™¤é”™è¯¯ç : {code}")
            except Exception as e:
                results['errors'].append(f"åˆ é™¤ {code} å¤±è´¥: {e}")

        # 2. æ ‡è®°å¼ƒç”¨
        for code in plan.deprecation:
            try:
                if not dry_run:
                    self._deprecate_error_code(code)
                results['deprecated'].append(code)
                logger.info(f"{'[DRY RUN] ' if dry_run else ''}å¼ƒç”¨é”™è¯¯ç : {code}")
            except Exception as e:
                results['errors'].append(f"å¼ƒç”¨ {code} å¤±è´¥: {e}")

        # 3. åˆå¹¶é‡å¤
        for item in plan.consolidation:
            try:
                if not dry_run:
                    self._consolidate_error_code(item['code'], item['locations'])
                results['consolidated'].append(item['code'])
                logger.info(f"{'[DRY RUN] ' if dry_run else ''}åˆå¹¶é”™è¯¯ç : {item['code']}")
            except Exception as e:
                results['errors'].append(f"åˆå¹¶ {item['code']} å¤±è´¥: {e}")

        # 4. è®°å½•æ¸…ç†å†å²
        if not dry_run:
            self.history['cleanups'].append({
                'timestamp': datetime.now().isoformat(),
                'removed': results['removed'],
                'deprecated': results['deprecated'],
                'consolidated': results['consolidated']
            })
            self._save_history()

        return results

    def _remove_error_code(self, code: str):
        """åˆ é™¤é”™è¯¯ç ï¼ˆå®é™…å®ç°ï¼‰"""
        # è¿™é‡Œåº”è¯¥å®ç°å®é™…çš„ä»£ç åˆ é™¤é€»è¾‘
        # åŒ…æ‹¬ï¼š
        # 1. ä»å®šä¹‰æ–‡ä»¶ä¸­åˆ é™¤
        # 2. æ›´æ–°å¼•ç”¨
        # 3. æ›´æ–°æ–‡æ¡£
        pass

    def _deprecate_error_code(self, code: str):
        """æ ‡è®°é”™è¯¯ç ä¸ºå¼ƒç”¨"""
        # è¿™é‡Œåº”è¯¥å®ç°å®é™…çš„å¼ƒç”¨æ ‡è®°é€»è¾‘
        # åŒ…æ‹¬ï¼š
        # 1. æ·»åŠ  @deprecated æ³¨é‡Š
        # 2. æ›´æ–°æ–‡æ¡£
        # 3. æ·»åŠ è­¦å‘Šæ—¥å¿—
        pass

    def _consolidate_error_code(self, code: str, locations: List[Dict]):
        """åˆå¹¶é‡å¤çš„é”™è¯¯ç å®šä¹‰"""
        # è¿™é‡Œåº”è¯¥å®ç°å®é™…çš„åˆå¹¶é€»è¾‘
        # åŒ…æ‹¬ï¼š
        # 1. ä¿ç•™ä¸€ä¸ªå®šä¹‰
        # 2. åˆ é™¤å…¶ä»–é‡å¤å®šä¹‰
        # 3. æ›´æ–°æ‰€æœ‰å¼•ç”¨
        pass

    def generate_cleanup_report(self, plan: CleanupPlan) -> str:
        """
        ç”Ÿæˆæ¸…ç†æŠ¥å‘Š

        Args:
            plan: æ¸…ç†è®¡åˆ’

        Returns:
            Markdownæ ¼å¼æŠ¥å‘Š
        """
        report = f"""# é”™è¯¯ç æ¸…ç†è®¡åˆ’

**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ“‹ æ¸…ç†æ¦‚è¦

- **ç«‹å³åˆ é™¤**: {len(plan.immediate_removal)} ä¸ª
- **æ ‡è®°å¼ƒç”¨**: {len(plan.deprecation)} ä¸ª
- **åˆå¹¶é‡å¤**: {len(plan.consolidation)} ä¸ª
- **ç»§ç»­ç›‘æ§**: {len(plan.monitoring)} ä¸ª

## ğŸ—‘ï¸ ç«‹å³åˆ é™¤åˆ—è¡¨

ä»¥ä¸‹é”™è¯¯ç è¶…è¿‡ {self.config['thresholds']['unused_days']} å¤©æœªä½¿ç”¨ï¼Œå»ºè®®ç«‹å³åˆ é™¤ï¼š

"""
        if plan.immediate_removal:
            for code in plan.immediate_removal[:50]:  # æœ€å¤šæ˜¾ç¤º50ä¸ª
                report += f"- `{code}`\n"
            if len(plan.immediate_removal) > 50:
                report += f"- ... è¿˜æœ‰ {len(plan.immediate_removal) - 50} ä¸ª\n"
        else:
            report += "- æ— \n"

        report += f"""
## âš ï¸ æ ‡è®°å¼ƒç”¨åˆ—è¡¨

ä»¥ä¸‹é”™è¯¯ç ä½¿ç”¨ç‡æä½ï¼ˆ< {self.config['thresholds']['rare_usage_count']} æ¬¡/æœˆï¼‰ï¼Œå»ºè®®æ ‡è®°ä¸ºå¼ƒç”¨ï¼š

"""
        if plan.deprecation:
            for code in plan.deprecation[:30]:
                replacement = plan.migration_guide.get('replacement_mapping', {}).get(code, 'å¾…å®š')
                report += f"- `{code}` â†’ `{replacement}`\n"
            if len(plan.deprecation) > 30:
                report += f"- ... è¿˜æœ‰ {len(plan.deprecation) - 30} ä¸ª\n"
        else:
            report += "- æ— \n"

        report += """
## ğŸ”„ åˆå¹¶é‡å¤åˆ—è¡¨

ä»¥ä¸‹é”™è¯¯ç å­˜åœ¨é‡å¤å®šä¹‰ï¼Œéœ€è¦åˆå¹¶ï¼š

"""
        if plan.consolidation:
            for item in plan.consolidation:
                report += f"\n**`{item['code']}`**:\n"
                for loc in item['locations'][:5]:
                    report += f"  - {loc['file']}:{loc['line']}\n"
        else:
            report += "- æ— \n"

        report += """
## ğŸ“ˆ å½±å“è¯„ä¼°

"""
        total_affected = len(plan.immediate_removal) + len(plan.deprecation) + len(plan.consolidation)
        report += f"""- **å—å½±å“é”™è¯¯ç æ€»æ•°**: {total_affected}
- **ä»£ç ä½“ç§¯å‡å°‘**: çº¦ {total_affected * 50} å­—èŠ‚
- **ç»´æŠ¤æˆæœ¬é™ä½**: çº¦ {total_affected * 10} åˆ†é’Ÿ/æœˆ
- **é”™è¯¯ç æ¸…æ™°åº¦æå‡**: {(total_affected / 200 * 100):.1f}%

## ğŸ“ è¿ç§»æŒ‡å—

### æ—¶é—´çº¿
"""
        if plan.migration_guide and plan.migration_guide.get('deprecation_timeline'):
            sample = list(plan.migration_guide['deprecation_timeline'].values())[0] if plan.migration_guide['deprecation_timeline'] else {}
            if sample:
                report += f"""- **å¼ƒç”¨æ—¥æœŸ**: {sample.get('deprecated_date', '').split('T')[0]}
- **åˆ é™¤æ—¥æœŸ**: {sample.get('removal_date', '').split('T')[0]}
- **å®½é™æœŸ**: {sample.get('grace_period_days', 30)} å¤©
"""

        report += """
### è¿ç§»æ­¥éª¤
"""
        if plan.migration_guide and plan.migration_guide.get('migration_steps'):
            for step in plan.migration_guide['migration_steps']:
                report += f"{step}\n"

        report += """
## âœ… ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. **å®¡æ ¸æ¸…ç†è®¡åˆ’** - ç¡®è®¤åˆ é™¤å’Œå¼ƒç”¨åˆ—è¡¨
2. **é€šçŸ¥ç›¸å…³å›¢é˜Ÿ** - ç‰¹åˆ«æ˜¯å®¢æˆ·ç«¯å›¢é˜Ÿ
3. **æ‰§è¡Œæ¸…ç†** - è¿è¡Œ `--apply` å‚æ•°åº”ç”¨è®¡åˆ’
4. **ç›‘æ§å½±å“** - è§‚å¯Ÿæ—¥å¿—ä¸­çš„å¼‚å¸¸
5. **æ›´æ–°æ–‡æ¡£** - åŒæ­¥æ›´æ–°é”™è¯¯ç æ–‡æ¡£

## âš ï¸ æ³¨æ„äº‹é¡¹

- åˆ é™¤æ“ä½œä¸å¯é€†ï¼Œè¯·å…ˆå¤‡ä»½
- å»ºè®®å…ˆåœ¨å¼€å‘ç¯å¢ƒæµ‹è¯•
- ä¿ç•™è‡³å°‘ä¸€å‘¨çš„å›æ»šçª—å£
- ç¡®ä¿å®¢æˆ·ç«¯å·²åŒæ­¥æ›´æ–°

---
*æ­¤æŠ¥å‘Šç”±é”™è¯¯ç ç”Ÿå‘½å‘¨æœŸç®¡ç†ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ*
"""

        return report


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description='é”™è¯¯ç ç”Ÿå‘½å‘¨æœŸç®¡ç†')
    parser.add_argument('--config', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--analyze', action='store_true', help='åˆ†æç”Ÿå‘½å‘¨æœŸ')
    parser.add_argument('--plan', action='store_true', help='ç”Ÿæˆæ¸…ç†è®¡åˆ’')
    parser.add_argument('--apply', action='store_true', help='åº”ç”¨æ¸…ç†è®¡åˆ’')
    parser.add_argument('--dry-run', action='store_true', help='æ¼”ç»ƒæ¨¡å¼')
    parser.add_argument('--output', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--format', choices=['json', 'markdown'], default='markdown',
                       help='è¾“å‡ºæ ¼å¼')

    args = parser.parse_args()

    # åˆ›å»ºç®¡ç†å™¨
    manager = ErrorCodeLifecycleManager(config_file=args.config)

    if args.analyze or args.plan:
        # åˆ†æç”Ÿå‘½å‘¨æœŸ
        results = manager.analyze_lifecycle()
        plan = results['cleanup_plan']

        if args.format == 'json':
            output = json.dumps({
                'summary': results['scan_results']['summary'],
                'lifecycle_analysis': results['lifecycle_analysis'],
                'cleanup_plan': {
                    'immediate_removal': plan.immediate_removal,
                    'deprecation': plan.deprecation,
                    'consolidation': plan.consolidation,
                    'monitoring': plan.monitoring
                }
            }, indent=2)
        else:
            output = manager.generate_cleanup_report(plan)

        # è¾“å‡ºç»“æœ
        if args.output:
            with open(args.output, 'w') as f:
                f.write(output)
            print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜åˆ°: {args.output}")
        else:
            print(output)

        # å¦‚æœéœ€è¦åº”ç”¨è®¡åˆ’
        if args.apply:
            print("\nå¼€å§‹åº”ç”¨æ¸…ç†è®¡åˆ’...\n")
            apply_results = manager.apply_cleanup_plan(plan, dry_run=args.dry_run)
            print(f"âœ… å·²åˆ é™¤: {len(apply_results['removed'])} ä¸ª")
            print(f"âš ï¸ å·²å¼ƒç”¨: {len(apply_results['deprecated'])} ä¸ª")
            print(f"ğŸ”„ å·²åˆå¹¶: {len(apply_results['consolidated'])} ä¸ª")
            if apply_results['errors']:
                print(f"âŒ é”™è¯¯: {len(apply_results['errors'])} ä¸ª")
                for error in apply_results['errors']:
                    print(f"  - {error}")

    else:
        parser.print_help()


if __name__ == '__main__':
    main()