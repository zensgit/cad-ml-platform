#!/usr/bin/env python3
"""
Recording Rules Versioning System
å½•åˆ¶è§„åˆ™ç‰ˆæœ¬åŒ–ç³»ç»Ÿ - ç®¡ç†å’Œè·Ÿè¸ª Prometheus recording rules çš„å˜æ›´å†å²

Features:
- ç‰ˆæœ¬æ§åˆ¶å’Œå†å²è·Ÿè¸ª
- è‡ªåŠ¨å¤‡ä»½å’Œå›æ»š
- è§„åˆ™éªŒè¯å’Œè¯­æ³•æ£€æŸ¥
- å˜æ›´å®¡è®¡æ—¥å¿—
- è§„åˆ™å¯¹æ¯”å’Œå·®å¼‚åˆ†æ
"""

import argparse
import hashlib
import json
import os
import shutil
import sys
import yaml
from dataclasses import dataclass, field
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Any, Optional, Set
from enum import Enum
import subprocess
import difflib


class ChangeType(Enum):
    """å˜æ›´ç±»å‹"""
    ADD = "add"
    MODIFY = "modify"
    DELETE = "delete"
    RENAME = "rename"


@dataclass
class RuleChange:
    """è§„åˆ™å˜æ›´è®°å½•"""
    rule_name: str
    change_type: ChangeType
    old_value: Optional[Dict[str, Any]] = None
    new_value: Optional[Dict[str, Any]] = None
    timestamp: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    author: str = ""
    message: str = ""
    impact: List[str] = field(default_factory=list)


@dataclass
class RuleVersion:
    """è§„åˆ™ç‰ˆæœ¬ä¿¡æ¯"""
    version_id: str
    version_number: str
    timestamp: datetime
    author: str
    message: str
    file_hash: str
    changes: List[RuleChange] = field(default_factory=list)
    parent_version: Optional[str] = None
    tags: List[str] = field(default_factory=list)


class RecordingRulesVersionManager:
    """å½•åˆ¶è§„åˆ™ç‰ˆæœ¬ç®¡ç†å™¨"""

    def __init__(self, rules_dir: str = "prometheus/rules",
                 version_dir: str = ".rules-versions"):
        """åˆå§‹åŒ–ç‰ˆæœ¬ç®¡ç†å™¨"""
        self.rules_dir = Path(rules_dir)
        self.version_dir = Path(version_dir)
        self.version_dir.mkdir(exist_ok=True)

        # åˆ›å»ºå¿…è¦çš„å­ç›®å½•
        self.versions_path = self.version_dir / "versions"
        self.backups_path = self.version_dir / "backups"
        self.metadata_path = self.version_dir / "metadata.json"

        self.versions_path.mkdir(exist_ok=True)
        self.backups_path.mkdir(exist_ok=True)

        self.metadata = self._load_metadata()

    def _load_metadata(self) -> Dict[str, Any]:
        """åŠ è½½ç‰ˆæœ¬å…ƒæ•°æ®"""
        if self.metadata_path.exists():
            with open(self.metadata_path, 'r') as f:
                return json.load(f)
        return {
            "current_version": None,
            "versions": [],
            "last_check": None
        }

    def _save_metadata(self):
        """ä¿å­˜ç‰ˆæœ¬å…ƒæ•°æ®"""
        with open(self.metadata_path, 'w') as f:
            json.dump(self.metadata, f, indent=2, default=str)

    def _calculate_file_hash(self, file_path: Path) -> str:
        """è®¡ç®—æ–‡ä»¶å“ˆå¸Œå€¼"""
        sha256_hash = hashlib.sha256()
        with open(file_path, "rb") as f:
            for byte_block in iter(lambda: f.read(4096), b""):
                sha256_hash.update(byte_block)
        return sha256_hash.hexdigest()

    def _load_rules(self, file_path: Path) -> Dict[str, Any]:
        """åŠ è½½è§„åˆ™æ–‡ä»¶"""
        with open(file_path, 'r') as f:
            return yaml.safe_load(f)

    def _save_rules(self, rules: Dict[str, Any], file_path: Path):
        """ä¿å­˜è§„åˆ™æ–‡ä»¶"""
        with open(file_path, 'w') as f:
            yaml.dump(rules, f, default_flow_style=False, sort_keys=False)

    def _validate_rules(self, rules_file: Path) -> tuple[bool, List[str]]:
        """éªŒè¯è§„åˆ™è¯­æ³•

        Returns:
            (is_valid, errors)
        """
        errors = []

        try:
            # åŠ è½½å¹¶éªŒè¯ YAML æ ¼å¼
            rules = self._load_rules(rules_file)

            if not isinstance(rules, dict):
                errors.append("Rules must be a dictionary")
                return False, errors

            # éªŒè¯å¿…éœ€çš„å­—æ®µ
            if 'groups' not in rules:
                errors.append("Missing 'groups' field")
                return False, errors

            # éªŒè¯æ¯ä¸ªè§„åˆ™ç»„
            for group_idx, group in enumerate(rules.get('groups', [])):
                if 'name' not in group:
                    errors.append(f"Group {group_idx}: missing 'name' field")

                if 'rules' not in group:
                    errors.append(f"Group {group_idx}: missing 'rules' field")
                    continue

                # éªŒè¯æ¯æ¡è§„åˆ™
                for rule_idx, rule in enumerate(group.get('rules', [])):
                    if 'record' not in rule and 'alert' not in rule:
                        errors.append(
                            f"Group '{group.get('name', group_idx)}', "
                            f"Rule {rule_idx}: must have 'record' or 'alert'"
                        )

                    if 'expr' not in rule:
                        errors.append(
                            f"Group '{group.get('name', group_idx)}', "
                            f"Rule {rule_idx}: missing 'expr' field"
                        )

            # å¦‚æœæœ‰ promtoolï¼Œä½¿ç”¨å®ƒè¿›è¡Œé¢å¤–éªŒè¯
            if shutil.which('promtool'):
                result = subprocess.run(
                    ['promtool', 'check', 'rules', str(rules_file)],
                    capture_output=True,
                    text=True
                )
                if result.returncode != 0:
                    errors.append(f"promtool validation failed: {result.stderr}")

        except yaml.YAMLError as e:
            errors.append(f"YAML parse error: {e}")
        except Exception as e:
            errors.append(f"Validation error: {e}")

        return len(errors) == 0, errors

    def _detect_changes(self, old_rules: Dict[str, Any],
                       new_rules: Dict[str, Any]) -> List[RuleChange]:
        """æ£€æµ‹è§„åˆ™å˜æ›´"""
        changes = []

        old_groups = {g['name']: g for g in old_rules.get('groups', [])}
        new_groups = {g['name']: g for g in new_rules.get('groups', [])}

        # æ£€æµ‹åˆ é™¤çš„ç»„
        for name in old_groups:
            if name not in new_groups:
                changes.append(RuleChange(
                    rule_name=f"group:{name}",
                    change_type=ChangeType.DELETE,
                    old_value=old_groups[name]
                ))

        # æ£€æµ‹æ–°å¢çš„ç»„
        for name in new_groups:
            if name not in old_groups:
                changes.append(RuleChange(
                    rule_name=f"group:{name}",
                    change_type=ChangeType.ADD,
                    new_value=new_groups[name]
                ))

        # æ£€æµ‹ä¿®æ”¹çš„ç»„
        for name in old_groups:
            if name in new_groups:
                old_group = old_groups[name]
                new_group = new_groups[name]

                # æ¯”è¾ƒè§„åˆ™
                old_rules_map = {}
                new_rules_map = {}

                for rule in old_group.get('rules', []):
                    key = rule.get('record') or rule.get('alert')
                    if key:
                        old_rules_map[key] = rule

                for rule in new_group.get('rules', []):
                    key = rule.get('record') or rule.get('alert')
                    if key:
                        new_rules_map[key] = rule

                # æ£€æµ‹è§„åˆ™å˜åŒ–
                for rule_name in old_rules_map:
                    if rule_name not in new_rules_map:
                        changes.append(RuleChange(
                            rule_name=f"{name}:{rule_name}",
                            change_type=ChangeType.DELETE,
                            old_value=old_rules_map[rule_name]
                        ))

                for rule_name in new_rules_map:
                    if rule_name not in old_rules_map:
                        changes.append(RuleChange(
                            rule_name=f"{name}:{rule_name}",
                            change_type=ChangeType.ADD,
                            new_value=new_rules_map[rule_name]
                        ))
                    elif old_rules_map[rule_name] != new_rules_map[rule_name]:
                        changes.append(RuleChange(
                            rule_name=f"{name}:{rule_name}",
                            change_type=ChangeType.MODIFY,
                            old_value=old_rules_map[rule_name],
                            new_value=new_rules_map[rule_name]
                        ))

        return changes

    def _analyze_impact(self, changes: List[RuleChange]) -> Dict[str, List[str]]:
        """åˆ†æå˜æ›´å½±å“"""
        impact = {
            "dashboards": [],
            "alerts": [],
            "downstream_rules": [],
            "queries": []
        }

        for change in changes:
            # åˆ†æå¯¹ä»ªè¡¨æ¿çš„å½±å“
            if change.change_type in [ChangeType.DELETE, ChangeType.MODIFY]:
                if ":" in change.rule_name:
                    metric_name = change.rule_name.split(":")[-1]
                    impact["dashboards"].append(
                        f"Dashboard using metric '{metric_name}' may be affected"
                    )

            # åˆ†æå¯¹å‘Šè­¦çš„å½±å“
            if change.rule_name.startswith("alert:") or \
               (change.old_value and 'alert' in change.old_value):
                impact["alerts"].append(
                    f"Alert '{change.rule_name}' {change.change_type.value}"
                )

            # åˆ†æå¯¹ä¸‹æ¸¸è§„åˆ™çš„å½±å“
            if change.change_type == ChangeType.MODIFY:
                if change.old_value and 'expr' in change.old_value:
                    old_expr = change.old_value['expr']
                    if 'record' in change.old_value:
                        record_name = change.old_value['record']
                        impact["downstream_rules"].append(
                            f"Rules using '{record_name}' may need review"
                        )

        return impact

    def create_version(self, author: str = "", message: str = "") -> Optional[str]:
        """åˆ›å»ºæ–°ç‰ˆæœ¬

        Returns:
            ç‰ˆæœ¬ ID æˆ– Noneï¼ˆå¦‚æœæ²¡æœ‰å˜åŒ–ï¼‰
        """
        version_id = datetime.now().strftime("%Y%m%d_%H%M%S")

        # æ”¶é›†æ‰€æœ‰è§„åˆ™æ–‡ä»¶
        rule_files = list(self.rules_dir.glob("*.yml")) + \
                    list(self.rules_dir.glob("*.yaml"))

        if not rule_files:
            print("No rule files found")
            return None

        # åˆ›å»ºç‰ˆæœ¬ç›®å½•
        version_path = self.versions_path / version_id
        version_path.mkdir(exist_ok=True)

        all_changes = []

        for rule_file in rule_files:
            # éªŒè¯è§„åˆ™
            is_valid, errors = self._validate_rules(rule_file)
            if not is_valid:
                print(f"Validation failed for {rule_file.name}:")
                for error in errors:
                    print(f"  - {error}")
                # æ¸…ç†å¹¶è¿”å›
                shutil.rmtree(version_path)
                return None

            # å¤åˆ¶æ–‡ä»¶åˆ°ç‰ˆæœ¬ç›®å½•
            dest_file = version_path / rule_file.name
            shutil.copy2(rule_file, dest_file)

            # æ£€æµ‹å˜åŒ–
            if self.metadata["current_version"]:
                old_version_path = self.versions_path / self.metadata["current_version"]
                old_file = old_version_path / rule_file.name

                if old_file.exists():
                    old_rules = self._load_rules(old_file)
                    new_rules = self._load_rules(rule_file)
                    changes = self._detect_changes(old_rules, new_rules)
                    all_changes.extend(changes)

        if not all_changes and self.metadata["current_version"]:
            # æ²¡æœ‰å˜åŒ–ï¼Œä¸åˆ›å»ºæ–°ç‰ˆæœ¬
            shutil.rmtree(version_path)
            print("No changes detected")
            return None

        # åˆ›å»ºç‰ˆæœ¬ä¿¡æ¯
        version_info = RuleVersion(
            version_id=version_id,
            version_number=f"v{len(self.metadata['versions']) + 1}",
            timestamp=datetime.now(timezone.utc),
            author=author or os.getenv('USER', 'unknown'),
            message=message or "Manual version",
            file_hash=self._calculate_file_hash(rule_files[0]),
            changes=all_changes,
            parent_version=self.metadata["current_version"]
        )

        # ä¿å­˜ç‰ˆæœ¬ä¿¡æ¯
        version_info_path = version_path / "version_info.json"
        with open(version_info_path, 'w') as f:
            json.dump({
                "version_id": version_info.version_id,
                "version_number": version_info.version_number,
                "timestamp": version_info.timestamp.isoformat(),
                "author": version_info.author,
                "message": version_info.message,
                "file_hash": version_info.file_hash,
                "changes": [
                    {
                        "rule_name": c.rule_name,
                        "change_type": c.change_type.value,
                        "timestamp": c.timestamp.isoformat()
                    }
                    for c in version_info.changes
                ],
                "parent_version": version_info.parent_version
            }, f, indent=2)

        # æ›´æ–°å…ƒæ•°æ®
        self.metadata["current_version"] = version_id
        self.metadata["versions"].append(version_id)
        self.metadata["last_check"] = datetime.now(timezone.utc).isoformat()
        self._save_metadata()

        print(f"Created version {version_info.version_number} ({version_id})")
        return version_id

    def list_versions(self) -> List[Dict[str, Any]]:
        """åˆ—å‡ºæ‰€æœ‰ç‰ˆæœ¬"""
        versions = []

        for version_id in self.metadata["versions"]:
            version_path = self.versions_path / version_id
            info_path = version_path / "version_info.json"

            if info_path.exists():
                with open(info_path, 'r') as f:
                    info = json.load(f)
                    versions.append(info)

        return sorted(versions, key=lambda x: x['timestamp'], reverse=True)

    def rollback(self, version_id: str, backup: bool = True) -> bool:
        """å›æ»šåˆ°æŒ‡å®šç‰ˆæœ¬

        Args:
            version_id: ç‰ˆæœ¬ ID
            backup: æ˜¯å¦å¤‡ä»½å½“å‰ç‰ˆæœ¬

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        version_path = self.versions_path / version_id

        if not version_path.exists():
            print(f"Version {version_id} not found")
            return False

        # å¤‡ä»½å½“å‰ç‰ˆæœ¬
        if backup:
            backup_id = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_path = self.backups_path / backup_id
            backup_path.mkdir(exist_ok=True)

            for rule_file in self.rules_dir.glob("*.y*ml"):
                shutil.copy2(rule_file, backup_path / rule_file.name)

            print(f"Current rules backed up to {backup_id}")

        # æ¢å¤ç‰ˆæœ¬æ–‡ä»¶
        for rule_file in version_path.glob("*.y*ml"):
            dest_file = self.rules_dir / rule_file.name
            shutil.copy2(rule_file, dest_file)

        # æ›´æ–°å…ƒæ•°æ®
        self.metadata["current_version"] = version_id
        self._save_metadata()

        print(f"Rolled back to version {version_id}")
        return True

    def diff(self, version1: str, version2: str = None) -> str:
        """æ¯”è¾ƒä¸¤ä¸ªç‰ˆæœ¬çš„å·®å¼‚

        Args:
            version1: ç¬¬ä¸€ä¸ªç‰ˆæœ¬ ID
            version2: ç¬¬äºŒä¸ªç‰ˆæœ¬ IDï¼ˆé»˜è®¤ä¸ºå½“å‰ç‰ˆæœ¬ï¼‰

        Returns:
            å·®å¼‚æŠ¥å‘Š
        """
        if version2 is None:
            version2 = self.metadata["current_version"]

        if not version2:
            return "No current version to compare"

        v1_path = self.versions_path / version1
        v2_path = self.versions_path / version2

        if not v1_path.exists():
            return f"Version {version1} not found"
        if not v2_path.exists():
            return f"Version {version2} not found"

        diff_output = []
        diff_output.append(f"Comparing {version1} -> {version2}\n")
        diff_output.append("=" * 50 + "\n")

        # æ¯”è¾ƒæ¯ä¸ªæ–‡ä»¶
        all_files = set()
        all_files.update(f.name for f in v1_path.glob("*.y*ml"))
        all_files.update(f.name for f in v2_path.glob("*.y*ml"))

        for file_name in sorted(all_files):
            if file_name == "version_info.json":
                continue

            file1 = v1_path / file_name
            file2 = v2_path / file_name

            if not file1.exists():
                diff_output.append(f"\n+ NEW FILE: {file_name}\n")
                continue

            if not file2.exists():
                diff_output.append(f"\n- DELETED FILE: {file_name}\n")
                continue

            # æ¯”è¾ƒæ–‡ä»¶å†…å®¹
            with open(file1, 'r') as f:
                lines1 = f.readlines()
            with open(file2, 'r') as f:
                lines2 = f.readlines()

            diff = difflib.unified_diff(
                lines1, lines2,
                fromfile=f"{version1}/{file_name}",
                tofile=f"{version2}/{file_name}",
                lineterm=''
            )

            diff_lines = list(diff)
            if diff_lines:
                diff_output.append(f"\nğŸ“ {file_name}:\n")
                diff_output.extend(diff_lines)

        return "".join(diff_output)

    def auto_commit(self, check_interval: int = 3600) -> bool:
        """è‡ªåŠ¨æäº¤å˜æ›´ï¼ˆå¦‚æœæœ‰ï¼‰

        Args:
            check_interval: æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰

        Returns:
            æ˜¯å¦åˆ›å»ºäº†æ–°ç‰ˆæœ¬
        """
        last_check = self.metadata.get("last_check")

        if last_check:
            last_check_time = datetime.fromisoformat(last_check)
            time_since_check = (datetime.now(timezone.utc) - last_check_time).seconds

            if time_since_check < check_interval:
                print(f"Last check was {time_since_check}s ago, skipping")
                return False

        # æ£€æŸ¥å˜åŒ–å¹¶è‡ªåŠ¨æäº¤
        version_id = self.create_version(
            author="auto-commit",
            message="Automatic version checkpoint"
        )

        return version_id is not None

    def export_version(self, version_id: str, output_dir: str) -> bool:
        """å¯¼å‡ºç‰ˆæœ¬åˆ°æŒ‡å®šç›®å½•

        Args:
            version_id: ç‰ˆæœ¬ ID
            output_dir: è¾“å‡ºç›®å½•

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        version_path = self.versions_path / version_id

        if not version_path.exists():
            print(f"Version {version_id} not found")
            return False

        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        # å¤åˆ¶è§„åˆ™æ–‡ä»¶
        for rule_file in version_path.glob("*.y*ml"):
            shutil.copy2(rule_file, output_path / rule_file.name)

        # å¤åˆ¶ç‰ˆæœ¬ä¿¡æ¯
        info_file = version_path / "version_info.json"
        if info_file.exists():
            shutil.copy2(info_file, output_path / "version_info.json")

        print(f"Exported version {version_id} to {output_dir}")
        return True

    def generate_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆç‰ˆæœ¬ç®¡ç†æŠ¥å‘Š"""
        versions = self.list_versions()

        report = {
            "total_versions": len(versions),
            "current_version": self.metadata.get("current_version"),
            "last_check": self.metadata.get("last_check"),
            "versions": [],
            "statistics": {
                "total_changes": 0,
                "adds": 0,
                "modifies": 0,
                "deletes": 0
            },
            "recent_activity": []
        }

        # ç»Ÿè®¡å˜åŒ–
        for version in versions[:10]:  # æœ€è¿‘10ä¸ªç‰ˆæœ¬
            changes = version.get("changes", [])

            version_summary = {
                "version_id": version["version_id"],
                "version_number": version["version_number"],
                "timestamp": version["timestamp"],
                "author": version["author"],
                "message": version["message"],
                "change_count": len(changes)
            }

            report["versions"].append(version_summary)

            # ç»Ÿè®¡å˜åŒ–ç±»å‹
            for change in changes:
                change_type = change.get("change_type", "")
                report["statistics"]["total_changes"] += 1

                if change_type == "add":
                    report["statistics"]["adds"] += 1
                elif change_type == "modify":
                    report["statistics"]["modifies"] += 1
                elif change_type == "delete":
                    report["statistics"]["deletes"] += 1

        # æœ€è¿‘æ´»åŠ¨
        if versions:
            recent = versions[0]
            report["recent_activity"] = {
                "last_version": recent["version_id"],
                "last_author": recent["author"],
                "last_message": recent["message"],
                "last_timestamp": recent["timestamp"]
            }

        return report


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="Recording Rules Version Management System"
    )

    subparsers = parser.add_subparsers(dest="command", help="Commands")

    # init å‘½ä»¤
    init_parser = subparsers.add_parser("init", help="Initialize versioning")
    init_parser.add_argument("--rules-dir", default="prometheus/rules",
                            help="Rules directory")

    # commit å‘½ä»¤
    commit_parser = subparsers.add_parser("commit", help="Create new version")
    commit_parser.add_argument("-m", "--message", required=True,
                              help="Version message")
    commit_parser.add_argument("-a", "--author", help="Author name")

    # list å‘½ä»¤
    list_parser = subparsers.add_parser("list", help="List versions")
    list_parser.add_argument("-n", "--number", type=int, default=10,
                            help="Number of versions to show")

    # rollback å‘½ä»¤
    rollback_parser = subparsers.add_parser("rollback", help="Rollback to version")
    rollback_parser.add_argument("version", help="Version ID")
    rollback_parser.add_argument("--no-backup", action="store_true",
                                help="Don't backup current version")

    # diff å‘½ä»¤
    diff_parser = subparsers.add_parser("diff", help="Compare versions")
    diff_parser.add_argument("version1", help="First version")
    diff_parser.add_argument("version2", nargs="?", help="Second version (default: current)")

    # export å‘½ä»¤
    export_parser = subparsers.add_parser("export", help="Export version")
    export_parser.add_argument("version", help="Version ID")
    export_parser.add_argument("-o", "--output", required=True, help="Output directory")

    # report å‘½ä»¤
    report_parser = subparsers.add_parser("report", help="Generate report")
    report_parser.add_argument("--format", choices=["json", "markdown"], default="markdown")

    # auto-commit å‘½ä»¤
    auto_parser = subparsers.add_parser("auto-commit", help="Auto commit if changed")
    auto_parser.add_argument("--interval", type=int, default=3600,
                            help="Check interval in seconds")

    args = parser.parse_args()

    # åˆ›å»ºç®¡ç†å™¨
    manager = RecordingRulesVersionManager()

    try:
        if args.command == "init":
            manager = RecordingRulesVersionManager(rules_dir=args.rules_dir)
            print(f"Initialized versioning for {args.rules_dir}")

        elif args.command == "commit":
            version_id = manager.create_version(
                author=args.author or os.getenv('USER', 'unknown'),
                message=args.message
            )
            if version_id:
                print(f"Created version: {version_id}")
            else:
                print("No changes to commit")

        elif args.command == "list":
            versions = manager.list_versions()

            if not versions:
                print("No versions found")
                return 0

            print(f"\nğŸ“‹ Recording Rules Versions (showing {min(args.number, len(versions))})\n")
            print(f"{'Version':<10} {'ID':<20} {'Author':<15} {'Message':<40} {'Changes':<10}")
            print("-" * 105)

            for version in versions[:args.number]:
                print(f"{version['version_number']:<10} "
                     f"{version['version_id']:<20} "
                     f"{version['author']:<15} "
                     f"{version['message'][:37] + '...' if len(version['message']) > 40 else version['message']:<40} "
                     f"{len(version.get('changes', [])):<10}")

        elif args.command == "rollback":
            success = manager.rollback(
                args.version,
                backup=not args.no_backup
            )
            if success:
                print(f"Successfully rolled back to {args.version}")

        elif args.command == "diff":
            diff_output = manager.diff(args.version1, args.version2)
            print(diff_output)

        elif args.command == "export":
            success = manager.export_version(args.version, args.output)
            if success:
                print(f"Exported to {args.output}")

        elif args.command == "report":
            report = manager.generate_report()

            if args.format == "json":
                print(json.dumps(report, indent=2))
            else:
                # Markdown æ ¼å¼
                print("# Recording Rules Version Report\n")
                print(f"**Generated**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

                print("## Summary\n")
                print(f"- **Total Versions**: {report['total_versions']}")
                print(f"- **Current Version**: {report['current_version']}")
                print(f"- **Last Check**: {report['last_check']}")

                print("\n## Change Statistics\n")
                stats = report['statistics']
                print(f"- **Total Changes**: {stats['total_changes']}")
                print(f"- **Additions**: {stats['adds']}")
                print(f"- **Modifications**: {stats['modifies']}")
                print(f"- **Deletions**: {stats['deletes']}")

                if report['recent_activity']:
                    print("\n## Recent Activity\n")
                    recent = report['recent_activity']
                    print(f"- **Last Version**: {recent['last_version']}")
                    print(f"- **Last Author**: {recent['last_author']}")
                    print(f"- **Last Message**: {recent['last_message']}")
                    print(f"- **Last Update**: {recent['last_timestamp']}")

                if report['versions']:
                    print("\n## Recent Versions\n")
                    print("| Version | ID | Author | Message | Changes |")
                    print("|---------|----|---------|---------|---------")
                    for v in report['versions'][:5]:
                        print(f"| {v['version_number']} | {v['version_id']} | "
                             f"{v['author']} | {v['message'][:30]}... | {v['change_count']} |")

        elif args.command == "auto-commit":
            created = manager.auto_commit(check_interval=args.interval)
            if created:
                print("Auto-commit created new version")
            else:
                print("No changes to auto-commit")

        else:
            parser.print_help()

        return 0

    except Exception as e:
        print(f"Error: {e}", file=sys.stderr)
        return 1


if __name__ == "__main__":
    sys.exit(main())