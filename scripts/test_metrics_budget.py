#!/usr/bin/env python3
"""
Metrics Budget System Test Suite
æµ‹è¯•æŒ‡æ ‡åŸºæ•°é¢„ç®—ç³»ç»Ÿçš„æ‰€æœ‰ç»„ä»¶
"""

import os
import sys
import json
import tempfile
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any
import subprocess

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# å¯¼å…¥è¦æµ‹è¯•çš„æ¨¡å—
try:
    from scripts.metrics_cardinality_tracker import (
        MetricsCardinalityTracker,
        CardinalityInfo,
        PrometheusClient,
    )
    from scripts.metrics_budget_controller import (
        MetricsBudgetController,
        BudgetConfig,
        BudgetStatus,
        Decision,
        MetricChange,
    )
    from scripts.cardinality_analysis_report import (
        CardinalityAnalysisReporter,
        Anomaly,
        Recommendation,
    )
    from scripts.metrics_auto_optimizer import (
        MetricsAutoOptimizer,
        OptimizationRule,
        OptimizationResult,
    )
except ImportError:
    from metrics_cardinality_tracker import (
        MetricsCardinalityTracker,
        CardinalityInfo,
        PrometheusClient,
    )  # type: ignore
    from metrics_budget_controller import (
        MetricsBudgetController,
        BudgetConfig,
        BudgetStatus,
        Decision,
        MetricChange,
    )  # type: ignore
    from cardinality_analysis_report import (
        CardinalityAnalysisReporter,
        Anomaly,
        Recommendation,
    )  # type: ignore
    from metrics_auto_optimizer import (
        MetricsAutoOptimizer,
        OptimizationRule,
        OptimizationResult,
    )  # type: ignore


def run_command(cmd: str, check: bool = False) -> tuple:
    """è¿è¡Œå‘½ä»¤å¹¶è¿”å›ç»“æœ"""
    try:
        result = subprocess.run(
            cmd,
            shell=True,
            capture_output=True,
            text=True,
            check=check
        )
        return result.returncode == 0, result.stdout, result.stderr
    except subprocess.CalledProcessError as e:
        return False, e.stdout, e.stderr


def test_cardinality_tracker():
    """æµ‹è¯•åŸºæ•°è¿½è¸ªå™¨"""
    print("\nğŸ” æµ‹è¯•åŸºæ•°è¿½è¸ªå™¨...")

    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
    mock_info = CardinalityInfo(
        metric_name="test_metric",
        cardinality=5000,
        labels={"method": 5, "status": 10, "path": 100},
        sample_labels=[
            {"method": "GET", "status": "200", "path": "/api/v1/test"},
            {"method": "POST", "status": "201", "path": "/api/v1/create"}
        ]
    )

    # æµ‹è¯•æˆæœ¬è®¡ç®—
    storage_mb = mock_info.storage_mb
    monthly_cost = mock_info.monthly_cost

    if storage_mb > 0 and monthly_cost > 0:
        print(f"  âœ… æˆæœ¬è®¡ç®—æ­£ç¡®: {storage_mb:.2f} MB, ${monthly_cost:.4f}/æœˆ")
    else:
        print("  âŒ æˆæœ¬è®¡ç®—å¤±è´¥")
        return False

    # æµ‹è¯•å‘½ä»¤è¡Œå·¥å…·
    success, stdout, stderr = run_command(
        "python3 scripts/metrics_cardinality_tracker.py --help"
    )
    if success:
        print("  âœ… å‘½ä»¤è¡Œå·¥å…·æ­£å¸¸")
    else:
        print(f"  âŒ å‘½ä»¤è¡Œå·¥å…·å¤±è´¥: {stderr}")
        return False

    return True


def test_budget_controller():
    """æµ‹è¯•é¢„ç®—æ§åˆ¶å™¨"""
    print("\nğŸ” æµ‹è¯•é¢„ç®—æ§åˆ¶å™¨...")

    # åˆ›å»ºæ§åˆ¶å™¨
    config = BudgetConfig(
        global_max_series=1000000,
        team_budgets={"test_team": 100000},
        service_budgets={"test_service": 50000}
    )
    controller = MetricsBudgetController(config)

    # æ›´æ–°ä½¿ç”¨æ•°æ®
    controller.update_usage({
        "test_team": {
            "metric1": 30000,
            "metric2": 40000
        }
    })

    # æ£€æŸ¥é¢„ç®—
    usage = controller.check_budget("test_team", "team")

    if usage.status == BudgetStatus.WARNING and usage.usage_percentage == 70.0:
        print(f"  âœ… é¢„ç®—æ£€æŸ¥æ­£ç¡®: {usage.usage_percentage}% ({usage.status.value})")
    else:
        print(f"  âŒ é¢„ç®—æ£€æŸ¥å¤±è´¥: {usage.usage_percentage}% ({usage.status.value})")
        return False

    # æµ‹è¯•å†³ç­–
    change = MetricChange(
        metric_name="new_metric",
        team="test_team",
        service="test_service",
        estimated_cardinality_change=5000,
        labels_added=["user_id"],
        labels_removed=[],
        reason="Testing"
    )

    decision, reason = controller.enforce_budget(change)
    if decision in [Decision.ALLOW, Decision.WARN, Decision.BLOCK]:
        print(f"  âœ… å†³ç­–ç³»ç»Ÿæ­£å¸¸: {decision.value} - {reason}")
    else:
        print("  âŒ å†³ç­–ç³»ç»Ÿå¤±è´¥")
        return False

    # æµ‹è¯•å…¨å±€çŠ¶æ€
    status = controller.get_global_status()
    if "global_budget" in status and "global_used" in status:
        print(f"  âœ… å…¨å±€çŠ¶æ€æ­£å¸¸: {status['global_used']}/{status['global_budget']}")
    else:
        print("  âŒ å…¨å±€çŠ¶æ€å¤±è´¥")
        return False

    return True


def test_analysis_reporter():
    """æµ‹è¯•åˆ†ææŠ¥å‘Šå™¨"""
    print("\nğŸ” æµ‹è¯•åˆ†ææŠ¥å‘Šå™¨...")

    # åˆ›å»ºæ¨¡æ‹Ÿè¿½è¸ªå™¨
    tracker = MetricsCardinalityTracker("http://localhost:9090")

    # æ·»åŠ æ¨¡æ‹Ÿæ•°æ®
    tracker.cardinality_cache["high_metric"] = CardinalityInfo(
        metric_name="high_metric",
        cardinality=50000,
        labels={"user_id": 10000, "path": 500},
        sample_labels=[]
    )

    tracker.cardinality_cache["normal_metric"] = CardinalityInfo(
        metric_name="normal_metric",
        cardinality=1000,
        labels={"method": 5, "status": 10},
        sample_labels=[]
    )

    # åˆ›å»ºæŠ¥å‘Šå™¨
    reporter = CardinalityAnalysisReporter(tracker)

    # æµ‹è¯•TopæŒ‡æ ‡æŠ¥å‘Š
    top_report = reporter.generate_top_offenders_report(top_n=5)
    if "top_metrics" in top_report and len(top_report["top_metrics"]) > 0:
        print(f"  âœ… TopæŒ‡æ ‡æŠ¥å‘Šç”Ÿæˆ: {len(top_report['top_metrics'])}ä¸ªæŒ‡æ ‡")
    else:
        print("  âŒ TopæŒ‡æ ‡æŠ¥å‘Šå¤±è´¥")
        return False

    # æµ‹è¯•ä¼˜åŒ–å»ºè®®
    recommendations = reporter.generate_optimization_recommendations()
    if isinstance(recommendations, list):
        print(f"  âœ… ä¼˜åŒ–å»ºè®®ç”Ÿæˆ: {len(recommendations)}æ¡")
    else:
        print("  âŒ ä¼˜åŒ–å»ºè®®ç”Ÿæˆå¤±è´¥")
        return False

    # æµ‹è¯•æŠ¥å‘Šæ ¼å¼åŒ–
    try:
        json_report = reporter._format_json(reporter.generate_full_report())
        if json_report:
            print("  âœ… JSONæ ¼å¼åŒ–æ­£å¸¸")
    except Exception as e:
        print(f"  âŒ æŠ¥å‘Šæ ¼å¼åŒ–å¤±è´¥: {e}")
        return False

    return True


def test_auto_optimizer():
    """æµ‹è¯•è‡ªåŠ¨ä¼˜åŒ–å™¨"""
    print("\nğŸ” æµ‹è¯•è‡ªåŠ¨ä¼˜åŒ–å™¨...")

    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = MetricsAutoOptimizer()

    # åˆ›å»ºæ¨¡æ‹ŸæŒ‡æ ‡ä¿¡æ¯
    metric_info = CardinalityInfo(
        metric_name="test_metric",
        cardinality=10000,
        labels={"user_id": 5000, "path": 200, "method": 5},
        sample_labels=[]
    )

    # æµ‹è¯•æ ‡ç­¾åˆå¹¶
    result = optimizer.apply_label_merging(
        metric_info,
        {"user_id": "user_category"}
    )
    if result.reduction_percentage > 0:
        print(f"  âœ… æ ‡ç­¾åˆå¹¶ä¼˜åŒ–: å‡å°‘{result.reduction_percentage}%")
    else:
        print("  âŒ æ ‡ç­¾åˆå¹¶ä¼˜åŒ–å¤±è´¥")
        return False

    # æµ‹è¯•æ ‡ç­¾åˆ é™¤
    result = optimizer.apply_label_dropping(
        metric_info,
        ["user_id"]
    )
    if result.reduction_percentage > 0:
        print(f"  âœ… æ ‡ç­¾åˆ é™¤ä¼˜åŒ–: å‡å°‘{result.reduction_percentage}%")
    else:
        print("  âŒ æ ‡ç­¾åˆ é™¤ä¼˜åŒ–å¤±è´¥")
        return False

    # æµ‹è¯•é™é‡‡æ ·é…ç½®
    downsample_config = optimizer.apply_downsampling(
        metric_info,
        {"raw": "1h", "5m": "1d", "1h": "7d"}
    )
    if "recording_rules" in downsample_config:
        print(f"  âœ… é™é‡‡æ ·é…ç½®ç”Ÿæˆ: {len(downsample_config['recording_rules'])}æ¡è§„åˆ™")
    else:
        print("  âŒ é™é‡‡æ ·é…ç½®å¤±è´¥")
        return False

    # æµ‹è¯•é…ç½®ç”Ÿæˆ
    optimizations = [
        OptimizationResult(
            metric_name="test_metric",
            original_cardinality=10000,
            optimized_cardinality=5000,
            reduction_percentage=50.0,
            optimization_type="label_dropping",
            config_changes=[],
            rollback_config={}
        )
    ]

    config = optimizer.generate_prometheus_config(optimizations)
    if "metric_relabel_configs" in config or "recording_rules" in config:
        print("  âœ… Prometheusé…ç½®ç”Ÿæˆæ­£å¸¸")
    else:
        print("  âŒ Prometheusé…ç½®ç”Ÿæˆå¤±è´¥")
        return False

    return True


def test_ci_workflow():
    """æµ‹è¯•CI/CDå·¥ä½œæµæ–‡ä»¶"""
    print("\nğŸ” æµ‹è¯•CI/CDå·¥ä½œæµ...")

    workflow_file = ".github/workflows/metrics-budget-check.yml"

    if Path(workflow_file).exists():
        print(f"  âœ… {workflow_file} å­˜åœ¨")

        # éªŒè¯YAMLç»“æ„
        with open(workflow_file, 'r') as f:
            content = f.read()
            if 'name:' in content and 'jobs:' in content and 'on:' in content:
                print("    âœ“ åŸºæœ¬ç»“æ„æ­£ç¡®")

                # æ£€æŸ¥å…³é”®job
                required_jobs = [
                    'analyze-metrics-changes',
                    'check-cardinality-budget',
                    'calculate-cost-impact',
                    'post-pr-comment'
                ]

                missing_jobs = []
                for job in required_jobs:
                    if job not in content:
                        missing_jobs.append(job)

                if not missing_jobs:
                    print(f"    âœ“ æ‰€æœ‰å¿…éœ€çš„jobå­˜åœ¨")
                else:
                    print(f"    âœ— ç¼ºå°‘job: {', '.join(missing_jobs)}")
                    return False
            else:
                print("    âœ— ç»“æ„å¯èƒ½æœ‰é—®é¢˜")
                return False
    else:
        print(f"  âŒ {workflow_file} ä¸å­˜åœ¨")
        return False

    return True


def test_integration():
    """é›†æˆæµ‹è¯•"""
    print("\nğŸ” è¿è¡Œé›†æˆæµ‹è¯•...")

    # åˆ›å»ºå®Œæ•´çš„æ•°æ®æµ
    tracker = MetricsCardinalityTracker("http://localhost:9090")
    controller = MetricsBudgetController()
    reporter = CardinalityAnalysisReporter(tracker, controller)
    optimizer = MetricsAutoOptimizer()

    # æ¨¡æ‹Ÿå®Œæ•´æµç¨‹
    # 1. æ·»åŠ æŒ‡æ ‡æ•°æ®
    tracker.cardinality_cache["integration_test"] = CardinalityInfo(
        metric_name="integration_test",
        cardinality=15000,
        labels={"id": 8000, "type": 10},
        sample_labels=[]
    )

    # 2. æ›´æ–°é¢„ç®—ä½¿ç”¨
    controller.update_usage({
        "platform": {"integration_test": 15000}
    })

    # 3. ç”Ÿæˆå»ºè®®
    recommendations = reporter.generate_optimization_recommendations()

    # 4. åº”ç”¨ä¼˜åŒ–
    if recommendations:
        results = optimizer.optimize_metrics(tracker, recommendations[:1])
        if results:
            print(f"  âœ… é›†æˆæµ‹è¯•å®Œæˆ: ä¼˜åŒ–äº†{len(results)}ä¸ªæŒ‡æ ‡")
            return True

    print("  âš ï¸ é›†æˆæµ‹è¯•å®Œæˆä½†æ— ä¼˜åŒ–ç»“æœï¼ˆå¯èƒ½æ˜¯æ­£å¸¸çš„ï¼‰")
    return True


def generate_test_report(results: Dict[str, bool]):
    """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•æ€»ç»“æŠ¥å‘Š")
    print("=" * 60)

    total = len(results)
    passed = sum(1 for r in results.values() if r)

    print(f"\næ€»æµ‹è¯•: {total}")
    print(f"é€šè¿‡: {passed}")
    print(f"å¤±è´¥: {total - passed}")
    print(f"é€šè¿‡ç‡: {(passed/total*100):.1f}%")

    print("\nè¯¦ç»†ç»“æœ:")
    for name, result in results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"  - {name}: {status}")

    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æŒ‡æ ‡åŸºæ•°é¢„ç®—ç³»ç»Ÿæ­£å¸¸å·¥ä½œï¼")
        return True
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³åŠŸèƒ½ã€‚")
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æµ‹è¯• Day 5-7 æŒ‡æ ‡åŸºæ•°é¢„ç®—ç³»ç»Ÿ...")
    print("=" * 60)

    # æ£€æŸ¥Pythonç‰ˆæœ¬
    if sys.version_info < (3, 8):
        print("âš ï¸ è­¦å‘Š: Pythonç‰ˆæœ¬ä½äº3.8ï¼ŒæŸäº›åŠŸèƒ½å¯èƒ½ä¸å…¼å®¹")

    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    results = {
        "åŸºæ•°è¿½è¸ªå™¨": test_cardinality_tracker(),
        "é¢„ç®—æ§åˆ¶å™¨": test_budget_controller(),
        "åˆ†ææŠ¥å‘Šå™¨": test_analysis_reporter(),
        "è‡ªåŠ¨ä¼˜åŒ–å™¨": test_auto_optimizer(),
        "CI/CDå·¥ä½œæµ": test_ci_workflow(),
        "é›†æˆæµ‹è¯•": test_integration()
    }

    # ç”Ÿæˆæ€»ç»“
    success = generate_test_report(results)

    # ç”Ÿæˆä½¿ç”¨å»ºè®®
    print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
    print("1. é…ç½®Prometheusè¿æ¥:")
    print("   export PROMETHEUS_URL=http://your-prometheus:9090")
    print("\n2. è¿è¡ŒåŸºæ•°åˆ†æ:")
    print("   python3 scripts/cardinality_analysis_report.py --format markdown")
    print("\n3. é…ç½®é¢„ç®—é™åˆ¶:")
    print("   ç¼–è¾‘ budget_config.json è®¾ç½®å›¢é˜Ÿ/æœåŠ¡é¢„ç®—")
    print("\n4. å¯ç”¨CI/CDæ£€æŸ¥:")
    print("   åœ¨GitHubä»“åº“å¯ç”¨ metrics-budget-check.yml å·¥ä½œæµ")

    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
