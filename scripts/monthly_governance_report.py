#!/usr/bin/env python3
"""
Monthly Governance Report Generator
æœˆåº¦æ²»ç†æŠ¥å‘Šç”Ÿæˆå™¨ - æ±‡æ€»æ‰€æœ‰æ²»ç†æŒ‡æ ‡å’Œåˆè§„çŠ¶æ€
"""

import json
import sys
import subprocess
from pathlib import Path
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, field, asdict
from datetime import datetime, timedelta
import calendar


@dataclass
class GovernanceMetric:
    """æ²»ç†æŒ‡æ ‡"""
    category: str
    metric_name: str
    current_value: Any
    target_value: Any
    status: str  # pass, warning, fail
    trend: str  # improving, stable, degrading
    details: str


@dataclass
class ComplianceSection:
    """åˆè§„éƒ¨åˆ†"""
    name: str
    score: float  # 0-100
    violations: List[str]
    recommendations: List[str]
    metrics: List[GovernanceMetric]


@dataclass
class MonthlyGovernanceReport:
    """æœˆåº¦æ²»ç†æŠ¥å‘Š"""
    report_month: str
    generation_date: datetime
    overall_score: float
    executive_summary: str
    sections: List[ComplianceSection]
    achievements: List[str]
    issues: List[str]
    action_items: List[Dict[str, str]]
    trends: Dict[str, Any]


class GovernanceReportGenerator:
    """æ²»ç†æŠ¥å‘Šç”Ÿæˆå™¨"""

    def __init__(self, month: Optional[str] = None):
        self.project_root = Path(__file__).parent.parent
        self.reports_dir = self.project_root / "reports" / "governance"
        self.reports_dir.mkdir(parents=True, exist_ok=True)

        # è®¾ç½®æŠ¥å‘Šæœˆä»½
        if month:
            self.report_month = month
        else:
            # é»˜è®¤ä¸ºä¸Šä¸ªæœˆ
            today = datetime.now()
            if today.month == 1:
                self.report_month = f"{today.year - 1}-12"
            else:
                self.report_month = f"{today.year}-{today.month - 1:02d}"

        self.sections: List[ComplianceSection] = []
        self.achievements: List[str] = []
        self.issues: List[str] = []
        self.action_items: List[Dict[str, str]] = []

    def generate_report(self) -> MonthlyGovernanceReport:
        """ç”Ÿæˆå®Œæ•´æŠ¥å‘Š"""
        print(f"ğŸ“Š Generating Monthly Governance Report for {self.report_month}")
        print("=" * 60)

        # æ”¶é›†å„ä¸ªéƒ¨åˆ†çš„æ•°æ®
        self._collect_error_code_metrics()
        self._collect_metrics_compliance()
        self._collect_resilience_metrics()
        self._collect_cardinality_metrics()
        self._collect_drift_metrics()
        self._collect_adaptive_metrics()

        # è®¡ç®—æ€»ä½“åˆ†æ•°
        overall_score = self._calculate_overall_score()

        # ç”Ÿæˆæ‰§è¡Œæ‘˜è¦
        executive_summary = self._generate_executive_summary(overall_score)

        # åˆ†æè¶‹åŠ¿
        trends = self._analyze_trends()

        # åˆ›å»ºæŠ¥å‘Š
        report = MonthlyGovernanceReport(
            report_month=self.report_month,
            generation_date=datetime.now(),
            overall_score=overall_score,
            executive_summary=executive_summary,
            sections=self.sections,
            achievements=self.achievements,
            issues=self.issues,
            action_items=self.action_items,
            trends=trends
        )

        return report

    def _collect_error_code_metrics(self):
        """æ”¶é›†é”™è¯¯ç ç”Ÿå‘½å‘¨æœŸæŒ‡æ ‡"""
        print("ğŸ“ Collecting error code lifecycle metrics...")

        metrics = []

        # æ¨¡æ‹Ÿæ•°æ®ï¼ˆå®é™…åº”ä»å®¡è®¡å·¥å…·è·å–ï¼‰
        total_codes = 85
        active_codes = 62
        deprecated_codes = 8
        unused_codes = 15

        metrics.append(GovernanceMetric(
            category="Error Codes",
            metric_name="Total Error Codes",
            current_value=total_codes,
            target_value=100,
            status="pass" if total_codes <= 100 else "fail",
            trend="stable",
            details=f"{total_codes} error codes defined"
        ))

        metrics.append(GovernanceMetric(
            category="Error Codes",
            metric_name="Active Usage Rate",
            current_value=f"{active_codes/total_codes*100:.1f}%",
            target_value=">70%",
            status="pass" if active_codes/total_codes > 0.7 else "warning",
            trend="improving",
            details=f"{active_codes} codes actively used"
        ))

        metrics.append(GovernanceMetric(
            category="Error Codes",
            metric_name="Deprecation Candidates",
            current_value=deprecated_codes + unused_codes,
            target_value="<20",
            status="warning" if deprecated_codes + unused_codes < 20 else "fail",
            trend="stable",
            details=f"{deprecated_codes} deprecated, {unused_codes} unused"
        ))

        # è®¡ç®—éƒ¨åˆ†åˆ†æ•°
        score = 80.0 if active_codes/total_codes > 0.7 else 60.0

        violations = []
        if unused_codes > 10:
            violations.append(f"{unused_codes} unused error codes detected")

        recommendations = []
        if deprecated_codes > 0:
            recommendations.append(f"Remove {deprecated_codes} deprecated error codes")
        if unused_codes > 0:
            recommendations.append(f"Review and remove {unused_codes} unused codes")

        section = ComplianceSection(
            name="Error Code Lifecycle",
            score=score,
            violations=violations,
            recommendations=recommendations,
            metrics=metrics
        )

        self.sections.append(section)

        if score >= 80:
            self.achievements.append("Error code usage rate above 70%")
        else:
            self.issues.append("High number of unused error codes")

    def _collect_metrics_compliance(self):
        """æ”¶é›†æŒ‡æ ‡åˆè§„æ€§æ•°æ®"""
        print("ğŸ“ Collecting metrics compliance data...")

        metrics = []

        # æ¨¡æ‹Ÿæ•°æ®
        total_metrics = 45
        compliant_metrics = 38
        label_violations = 3
        cardinality_warnings = 4

        compliance_rate = compliant_metrics / total_metrics * 100

        metrics.append(GovernanceMetric(
            category="Metrics",
            metric_name="Schema Compliance",
            current_value=f"{compliance_rate:.1f}%",
            target_value=">90%",
            status="pass" if compliance_rate > 90 else "warning",
            trend="improving",
            details=f"{compliant_metrics}/{total_metrics} metrics compliant"
        ))

        metrics.append(GovernanceMetric(
            category="Metrics",
            metric_name="Label Violations",
            current_value=label_violations,
            target_value=0,
            status="warning" if label_violations > 0 else "pass",
            trend="improving",
            details=f"{label_violations} metrics with forbidden labels"
        ))

        score = max(0, 100 - label_violations * 5 - cardinality_warnings * 2)

        violations = []
        if label_violations > 0:
            violations.append(f"{label_violations} metrics using forbidden labels")

        recommendations = []
        if label_violations > 0:
            recommendations.append("Remove sensitive labels (user_id, session_id)")
        if cardinality_warnings > 0:
            recommendations.append("Review high cardinality metrics")

        section = ComplianceSection(
            name="Metrics Compliance",
            score=score,
            violations=violations,
            recommendations=recommendations,
            metrics=metrics
        )

        self.sections.append(section)

    def _collect_resilience_metrics(self):
        """æ”¶é›†éŸ§æ€§å±‚æŒ‡æ ‡"""
        print("ğŸ›¡ï¸ Collecting resilience metrics...")

        metrics = []

        # æ¨¡æ‹Ÿæ•°æ®
        circuit_breaker_coverage = 85
        rate_limiter_coverage = 78
        avg_recovery_time = 8.5  # seconds
        failed_requests_prevented = 15420

        metrics.append(GovernanceMetric(
            category="Resilience",
            metric_name="Circuit Breaker Coverage",
            current_value=f"{circuit_breaker_coverage}%",
            target_value=">80%",
            status="pass",
            trend="stable",
            details="85% of critical paths protected"
        ))

        metrics.append(GovernanceMetric(
            category="Resilience",
            metric_name="Rate Limiter Coverage",
            current_value=f"{rate_limiter_coverage}%",
            target_value=">75%",
            status="pass",
            trend="improving",
            details="78% of endpoints rate limited"
        ))

        metrics.append(GovernanceMetric(
            category="Resilience",
            metric_name="Avg Recovery Time",
            current_value=f"{avg_recovery_time}s",
            target_value="<10s",
            status="pass",
            trend="improving",
            details="Average circuit recovery in 8.5 seconds"
        ))

        score = (circuit_breaker_coverage + rate_limiter_coverage) / 2

        section = ComplianceSection(
            name="Resilience Layer",
            score=score,
            violations=[],
            recommendations=["Increase rate limiter coverage to 85%"],
            metrics=metrics
        )

        self.sections.append(section)
        self.achievements.append(f"Prevented {failed_requests_prevented:,} cascading failures")

    def _collect_cardinality_metrics(self):
        """æ”¶é›†åŸºæ•°æ§åˆ¶æŒ‡æ ‡"""
        print("ğŸ“ˆ Collecting cardinality metrics...")

        metrics = []

        # æ¨¡æ‹Ÿæ•°æ®
        total_series = 125000
        max_series_limit = 1000000
        high_cardinality_metrics = 5
        growth_rate = 3.2  # % per week

        metrics.append(GovernanceMetric(
            category="Cardinality",
            metric_name="Total Series",
            current_value=f"{total_series:,}",
            target_value=f"<{max_series_limit:,}",
            status="pass",
            trend="stable",
            details=f"Using {total_series/max_series_limit*100:.1f}% of limit"
        ))

        metrics.append(GovernanceMetric(
            category="Cardinality",
            metric_name="Growth Rate",
            current_value=f"{growth_rate}%/week",
            target_value="<5%/week",
            status="pass",
            trend="stable",
            details="Controlled growth rate"
        ))

        metrics.append(GovernanceMetric(
            category="Cardinality",
            metric_name="High Cardinality Metrics",
            current_value=high_cardinality_metrics,
            target_value="<10",
            status="pass",
            trend="stable",
            details=f"{high_cardinality_metrics} metrics exceed threshold"
        ))

        score = 90 if high_cardinality_metrics < 10 else 70

        section = ComplianceSection(
            name="Cardinality Control",
            score=score,
            violations=[],
            recommendations=["Monitor top 5 high cardinality metrics"],
            metrics=metrics
        )

        self.sections.append(section)

    def _collect_drift_metrics(self):
        """æ”¶é›†æ¼‚ç§»æ£€æµ‹æŒ‡æ ‡"""
        print("ğŸ”„ Collecting drift detection metrics...")

        metrics = []

        # æ¨¡æ‹Ÿæ•°æ®
        drifted_metrics = 8
        critical_drifts = 1
        baseline_age_days = 14

        metrics.append(GovernanceMetric(
            category="Drift",
            metric_name="Drifted Metrics",
            current_value=drifted_metrics,
            target_value="<15",
            status="pass",
            trend="stable",
            details=f"{drifted_metrics} metrics drifted from baseline"
        ))

        metrics.append(GovernanceMetric(
            category="Drift",
            metric_name="Critical Drifts",
            current_value=critical_drifts,
            target_value=0,
            status="warning" if critical_drifts > 0 else "pass",
            trend="improving",
            details=f"{critical_drifts} critical drift detected"
        ))

        score = 85 if critical_drifts == 0 else 70

        recommendations = []
        if baseline_age_days > 30:
            recommendations.append("Update baseline (current age: 14 days)")
        if critical_drifts > 0:
            recommendations.append("Investigate critical drift immediately")

        section = ComplianceSection(
            name="Drift Detection",
            score=score,
            violations=[] if critical_drifts == 0 else [f"{critical_drifts} critical drift"],
            recommendations=recommendations,
            metrics=metrics
        )

        self.sections.append(section)

    def _collect_adaptive_metrics(self):
        """æ”¶é›†è‡ªé€‚åº”é™æµæŒ‡æ ‡"""
        print("ğŸ¯ Collecting adaptive rate limiting metrics...")

        metrics = []

        # æ¨¡æ‹Ÿæ•°æ®
        adaptive_enabled_pct = 92
        avg_adjustment_time = 1.8  # seconds
        false_positive_rate = 2.1  # %
        performance_overhead = 3.5  # %

        metrics.append(GovernanceMetric(
            category="Adaptive",
            metric_name="Coverage",
            current_value=f"{adaptive_enabled_pct}%",
            target_value=">90%",
            status="pass",
            trend="stable",
            details=f"{adaptive_enabled_pct}% endpoints adaptive-enabled"
        ))

        metrics.append(GovernanceMetric(
            category="Adaptive",
            metric_name="Response Time",
            current_value=f"{avg_adjustment_time}s",
            target_value="<2s",
            status="pass",
            trend="improving",
            details="Fast adaptation to load changes"
        ))

        metrics.append(GovernanceMetric(
            category="Adaptive",
            metric_name="P95 Overhead",
            current_value=f"{performance_overhead}%",
            target_value="<5%",
            status="pass",
            trend="stable",
            details="Within performance budget"
        ))

        score = 95 if performance_overhead < 5 else 80

        section = ComplianceSection(
            name="Adaptive Rate Limiting",
            score=score,
            violations=[],
            recommendations=[],
            metrics=metrics
        )

        self.sections.append(section)
        self.achievements.append(f"Adaptive limiting overhead only {performance_overhead}%")

    def _calculate_overall_score(self) -> float:
        """è®¡ç®—æ€»ä½“æ²»ç†åˆ†æ•°"""
        if not self.sections:
            return 0.0

        # åŠ æƒå¹³å‡
        weights = {
            "Error Code Lifecycle": 0.15,
            "Metrics Compliance": 0.20,
            "Resilience Layer": 0.25,
            "Cardinality Control": 0.15,
            "Drift Detection": 0.10,
            "Adaptive Rate Limiting": 0.15
        }

        total_score = 0.0
        total_weight = 0.0

        for section in self.sections:
            weight = weights.get(section.name, 0.1)
            total_score += section.score * weight
            total_weight += weight

        return total_score / total_weight if total_weight > 0 else 0.0

    def _generate_executive_summary(self, overall_score: float) -> str:
        """ç”Ÿæˆæ‰§è¡Œæ‘˜è¦"""
        year, month = self.report_month.split('-')
        month_name = calendar.month_name[int(month)]

        summary = f"The governance score for {month_name} {year} is {overall_score:.1f}/100. "

        if overall_score >= 85:
            summary += "The platform demonstrates excellent governance with all key metrics within targets. "
        elif overall_score >= 70:
            summary += "The platform shows good governance with most metrics meeting targets. "
        else:
            summary += "The platform requires attention in several governance areas. "

        # æ·»åŠ å…³é”®æˆå°±
        if self.achievements:
            summary += f"Key achievement: {self.achievements[0]}. "

        # æ·»åŠ ä¸»è¦é—®é¢˜
        if self.issues:
            summary += f"Main concern: {self.issues[0]}. "

        # æ·»åŠ å»ºè®®
        critical_sections = [s for s in self.sections if s.score < 70]
        if critical_sections:
            summary += f"Priority focus area: {critical_sections[0].name}."

        return summary

    def _analyze_trends(self) -> Dict[str, Any]:
        """åˆ†æè¶‹åŠ¿"""
        # æ¨¡æ‹Ÿå†å²æ•°æ®
        trends = {
            "overall_score_trend": [78.5, 80.2, 82.1, 83.5, 85.0],  # æœ€è¿‘5ä¸ªæœˆ
            "error_codes_trend": "decreasing",
            "cardinality_trend": "stable",
            "resilience_trend": "improving",
            "improvements": [
                "15% reduction in unused error codes",
                "20% increase in resilience coverage",
                "Adaptive rate limiting fully deployed"
            ],
            "concerns": [
                "Metrics cardinality growing 3.2% weekly",
                "3 metrics still using forbidden labels"
            ]
        }

        return trends

    def generate_markdown_report(self, report: MonthlyGovernanceReport) -> str:
        """ç”ŸæˆMarkdownæ ¼å¼æŠ¥å‘Š"""
        lines = []

        year, month = report.report_month.split('-')
        month_name = calendar.month_name[int(month)]

        lines.append(f"# Monthly Governance Report - {month_name} {year}")
        lines.append(f"\n**Generated**: {report.generation_date.strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append(f"**Overall Score**: {report.overall_score:.1f}/100")

        # è¯„çº§
        if report.overall_score >= 85:
            lines.append("**Rating**: â­â­â­â­â­ EXCELLENT")
        elif report.overall_score >= 75:
            lines.append("**Rating**: â­â­â­â­ GOOD")
        elif report.overall_score >= 65:
            lines.append("**Rating**: â­â­â­ SATISFACTORY")
        else:
            lines.append("**Rating**: â­â­ NEEDS IMPROVEMENT")

        lines.append(f"\n## ğŸ“‹ Executive Summary\n")
        lines.append(report.executive_summary)

        # åˆ†æ•°å¡
        lines.append("\n## ğŸ¯ Governance Scorecard\n")
        lines.append("| Category | Score | Status | Trend |")
        lines.append("|----------|-------|--------|-------|")

        for section in report.sections:
            status_emoji = "âœ…" if section.score >= 80 else "âš ï¸" if section.score >= 60 else "âŒ"
            trend_emoji = "ğŸ“ˆ" if any(m.trend == "improving" for m in section.metrics) else "â¡ï¸"
            lines.append(f"| {section.name} | {section.score:.0f} | {status_emoji} | {trend_emoji} |")

        # æˆå°±
        if report.achievements:
            lines.append("\n## ğŸ† Achievements\n")
            for achievement in report.achievements:
                lines.append(f"- âœ¨ {achievement}")

        # é—®é¢˜
        if report.issues:
            lines.append("\n## âš ï¸ Issues Identified\n")
            for issue in report.issues:
                lines.append(f"- ğŸ”´ {issue}")

        # è¯¦ç»†æŒ‡æ ‡
        lines.append("\n## ğŸ“Š Detailed Metrics\n")

        for section in report.sections:
            lines.append(f"### {section.name} (Score: {section.score:.0f}/100)\n")

            if section.metrics:
                lines.append("| Metric | Current | Target | Status |")
                lines.append("|--------|---------|--------|--------|")

                for metric in section.metrics:
                    status_icon = "âœ…" if metric.status == "pass" else "âš ï¸" if metric.status == "warning" else "âŒ"
                    lines.append(f"| {metric.metric_name} | {metric.current_value} | {metric.target_value} | {status_icon} |")

            if section.violations:
                lines.append("\n**Violations:**")
                for violation in section.violations:
                    lines.append(f"- âŒ {violation}")

            if section.recommendations:
                lines.append("\n**Recommendations:**")
                for rec in section.recommendations:
                    lines.append(f"- ğŸ’¡ {rec}")

            lines.append("")

        # è¶‹åŠ¿åˆ†æ
        lines.append("## ğŸ“ˆ Trend Analysis\n")

        if report.trends.get("overall_score_trend"):
            scores = report.trends["overall_score_trend"]
            lines.append(f"**Overall Score Trend** (Last 5 months): {' â†’ '.join(str(s) for s in scores)}")

        improvements = report.trends.get("improvements", [])
        if improvements:
            lines.append("\n**Improvements:**")
            for imp in improvements:
                lines.append(f"- ğŸ“ˆ {imp}")

        concerns = report.trends.get("concerns", [])
        if concerns:
            lines.append("\n**Concerns:**")
            for concern in concerns:
                lines.append(f"- ğŸ“‰ {concern}")

        # è¡ŒåŠ¨é¡¹
        lines.append("\n## ğŸ¬ Action Items\n")

        # ç”Ÿæˆè¡ŒåŠ¨é¡¹
        priority_items = []

        for section in report.sections:
            if section.score < 70:
                priority_items.append({
                    "priority": "HIGH",
                    "action": f"Improve {section.name}",
                    "owner": "platform-team",
                    "due": "Next sprint"
                })

        if not priority_items:
            priority_items.append({
                "priority": "MEDIUM",
                "action": "Maintain current governance standards",
                "owner": "platform-team",
                "due": "Ongoing"
            })

        lines.append("| Priority | Action | Owner | Due Date |")
        lines.append("|----------|--------|-------|----------|")

        for item in priority_items:
            priority_emoji = "ğŸ”´" if item["priority"] == "HIGH" else "ğŸŸ¡" if item["priority"] == "MEDIUM" else "ğŸŸ¢"
            lines.append(f"| {priority_emoji} {item['priority']} | {item['action']} | {item['owner']} | {item['due']} |")

        # ä¸‹æœˆé‡ç‚¹
        lines.append("\n## ğŸ¯ Next Month Focus Areas\n")
        lines.append("1. **Error Code Cleanup**: Remove deprecated and unused codes")
        lines.append("2. **Metrics Compliance**: Fix remaining label violations")
        lines.append("3. **Baseline Update**: Refresh drift detection baseline")
        lines.append("4. **Cardinality Review**: Analyze top 10 high cardinality metrics")

        # ç­¾å
        lines.append("\n---")
        lines.append("\n*This report was automatically generated by the Governance Report System.*")
        lines.append(f"*For questions, contact the Platform Team.*")

        return "\n".join(lines)

    def save_report(self, report: MonthlyGovernanceReport, format: str = "markdown"):
        """ä¿å­˜æŠ¥å‘Š"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"governance_report_{report.report_month}_{timestamp}"

        if format == "markdown":
            content = self.generate_markdown_report(report)
            filepath = self.reports_dir / f"{filename}.md"
            filepath.write_text(content)
        else:  # json
            report_dict = {
                "report_month": report.report_month,
                "generation_date": report.generation_date.isoformat(),
                "overall_score": report.overall_score,
                "executive_summary": report.executive_summary,
                "sections": [
                    {
                        "name": s.name,
                        "score": s.score,
                        "violations": s.violations,
                        "recommendations": s.recommendations,
                        "metrics": [asdict(m) for m in s.metrics]
                    }
                    for s in report.sections
                ],
                "achievements": report.achievements,
                "issues": report.issues,
                "trends": report.trends
            }
            filepath = self.reports_dir / f"{filename}.json"
            with open(filepath, 'w') as f:
                json.dump(report_dict, f, indent=2, default=str)

        print(f"âœ… Report saved to: {filepath}")
        return str(filepath)


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(
        description="Generate monthly governance report"
    )

    parser.add_argument(
        "--month",
        help="Report month (YYYY-MM format)",
        default=None
    )
    parser.add_argument(
        "--format",
        choices=["markdown", "json"],
        default="markdown",
        help="Output format"
    )
    parser.add_argument(
        "--output",
        "-o",
        help="Output file path (optional)"
    )

    args = parser.parse_args()

    # ç”ŸæˆæŠ¥å‘Š
    generator = GovernanceReportGenerator(args.month)
    report = generator.generate_report()

    # ä¿å­˜æˆ–è¾“å‡º
    if args.output:
        # ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„
        if args.format == "markdown":
            content = generator.generate_markdown_report(report)
        else:
            content = json.dumps(asdict(report), indent=2, default=str)

        with open(args.output, 'w') as f:
            f.write(content)
        print(f"\nâœ… Report saved to: {args.output}")
    else:
        # ä¿å­˜åˆ°é»˜è®¤ä½ç½®å¹¶æ‰“å°
        filepath = generator.save_report(report, args.format)

        # å¦‚æœæ˜¯markdownï¼Œä¹Ÿæ‰“å°åˆ°æ§åˆ¶å°
        if args.format == "markdown":
            print("\n" + "=" * 60)
            print(generator.generate_markdown_report(report))

    return 0


if __name__ == "__main__":
    sys.exit(main())