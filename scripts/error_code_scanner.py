#!/usr/bin/env python3
"""
é”™è¯¯ç æ‰«æå™¨
Error Code Scanner - æ‰«æå’Œåˆ†æé”™è¯¯ç ä½¿ç”¨æƒ…å†µ
"""

import os
import sys
import re
import json
import ast
from datetime import datetime, timedelta
from typing import Dict, List, Set, Optional, Tuple, Any
from pathlib import Path
from collections import defaultdict
import logging
import subprocess

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class ErrorCode:
    """é”™è¯¯ç å®ä½“"""
    def __init__(self, code: str, message: str = "", file_path: str = "", line_number: int = 0):
        self.code = code
        self.message = message
        self.file_path = file_path
        self.line_number = line_number
        self.usage_locations = []  # ä½¿ç”¨ä½ç½®åˆ—è¡¨
        self.last_used = None  # æœ€åä½¿ç”¨æ—¶é—´
        self.usage_count = 0  # ä½¿ç”¨æ¬¡æ•°
        self.status = 'UNKNOWN'  # ACTIVE, UNUSED, DEPRECATED, DUPLICATE

    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'code': self.code,
            'message': self.message,
            'file_path': self.file_path,
            'line_number': self.line_number,
            'usage_locations': self.usage_locations,
            'last_used': self.last_used.isoformat() if self.last_used else None,
            'usage_count': self.usage_count,
            'status': self.status
        }


class ErrorCodeScanner:
    """æ‰«æå’Œåˆ†æé”™è¯¯ç ä½¿ç”¨æƒ…å†µ"""

    def __init__(self, project_root: Optional[Path] = None):
        """
        åˆå§‹åŒ–æ‰«æå™¨

        Args:
            project_root: é¡¹ç›®æ ¹ç›®å½•
        """
        self.project_root = project_root or Path.cwd()
        self.error_codes = {}  # code -> ErrorCode
        self.duplicate_codes = defaultdict(list)  # code -> [locations]

        # é”™è¯¯ç å®šä¹‰æ–‡ä»¶æ¨¡å¼
        self.definition_patterns = [
            '**/errors.py',
            '**/error_codes.py',
            '**/exceptions.py',
            '**/constants/errors.py',
            '**/config/error_codes.json',
            '**/src/errors/*.py'
        ]

        # é”™è¯¯ç æ¨¡å¼
        self.error_code_patterns = [
            r'ERR_\d{3,5}',  # ERR_001, ERR_10001
            r'ERROR_[A-Z_]+',  # ERROR_NOT_FOUND
            r'E\d{3,5}',  # E001, E10001
            r'[A-Z]+_ERROR_\d+',  # API_ERROR_001
            r'[A-Z]{2,}_\d{3,}',  # DB_001, API_002
        ]

        # æºä»£ç æ–‡ä»¶æ‰©å±•å
        self.source_extensions = ['.py', '.js', '.ts', '.java', '.go', '.cpp', '.c']

        # å¿½ç•¥çš„ç›®å½•
        self.ignore_dirs = {
            '.git', '.venv', 'venv', 'env', 'node_modules',
            '__pycache__', '.pytest_cache', 'build', 'dist',
            '.idea', '.vscode', 'coverage'
        }

    def scan_all(self) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´æ‰«æ

        Returns:
            æ‰«æç»“æœ
        """
        logger.info("å¼€å§‹æ‰«æé”™è¯¯ç ...")

        # 1. æ‰«æå®šä¹‰
        definitions = self.scan_definitions()
        logger.info(f"æ‰¾åˆ° {len(definitions)} ä¸ªé”™è¯¯ç å®šä¹‰")

        # 2. æ‰«æä½¿ç”¨æƒ…å†µ
        usage = self.scan_usage()
        logger.info(f"æ‰¾åˆ° {len(usage)} ä¸ªé”™è¯¯ç ä½¿ç”¨")

        # 3. åˆ†ææ—¥å¿—
        log_stats = self.analyze_logs()
        logger.info(f"åˆ†æäº†æ—¥å¿—ä¸­çš„é”™è¯¯ç ç»Ÿè®¡")

        # 4. åˆ†ç±»é”™è¯¯ç 
        classification = self.classify_error_codes(definitions, usage, log_stats)

        # 5. æ£€æµ‹é‡å¤
        duplicates = self.detect_duplicates(definitions)

        return {
            'definitions': definitions,
            'usage': usage,
            'log_stats': log_stats,
            'classification': classification,
            'duplicates': duplicates,
            'summary': self._generate_summary(classification)
        }

    def scan_definitions(self) -> Dict[str, ErrorCode]:
        """
        æ‰«ææ‰€æœ‰é”™è¯¯ç å®šä¹‰

        Returns:
            é”™è¯¯ç å®šä¹‰å­—å…¸
        """
        definitions = {}

        # æŸ¥æ‰¾å®šä¹‰æ–‡ä»¶
        for pattern in self.definition_patterns:
            for file_path in self.project_root.glob(pattern):
                if self._should_skip_file(file_path):
                    continue

                logger.debug(f"æ‰«æå®šä¹‰æ–‡ä»¶: {file_path}")

                if file_path.suffix == '.json':
                    codes = self._extract_from_json(file_path)
                elif file_path.suffix == '.py':
                    codes = self._extract_from_python(file_path)
                else:
                    codes = self._extract_with_regex(file_path)

                for code in codes:
                    if code.code in definitions:
                        # è®°å½•é‡å¤å®šä¹‰
                        self.duplicate_codes[code.code].append({
                            'file': str(file_path),
                            'line': code.line_number
                        })
                    else:
                        definitions[code.code] = code

        return definitions

    def scan_usage(self) -> Dict[str, List[str]]:
        """
        æ‰«æé”™è¯¯ç ä½¿ç”¨æƒ…å†µ

        Returns:
            ä½¿ç”¨æƒ…å†µå­—å…¸ (code -> [file_paths])
        """
        usage = defaultdict(list)

        # éå†æ‰€æœ‰æºä»£ç æ–‡ä»¶
        for ext in self.source_extensions:
            for file_path in self.project_root.rglob(f'*{ext}'):
                if self._should_skip_file(file_path):
                    continue

                logger.debug(f"æ‰«æä½¿ç”¨æ–‡ä»¶: {file_path}")
                used_codes = self._extract_used_codes(file_path)

                for code in used_codes:
                    usage[code].append(str(file_path.relative_to(self.project_root)))

        return dict(usage)

    def analyze_logs(self, days: int = 30) -> Dict[str, int]:
        """
        åˆ†ææ—¥å¿—ä¸­çš„é”™è¯¯ç é¢‘ç‡

        Args:
            days: åˆ†ææœ€è¿‘å¤šå°‘å¤©çš„æ—¥å¿—

        Returns:
            é”™è¯¯ç ä½¿ç”¨ç»Ÿè®¡
        """
        log_stats = defaultdict(int)

        # æŸ¥æ‰¾æ—¥å¿—æ–‡ä»¶
        log_patterns = [
            'logs/*.log',
            'logs/**/*.log',
            '*.log',
            'var/log/*.log'
        ]

        for pattern in log_patterns:
            for log_file in self.project_root.glob(pattern):
                if not log_file.is_file():
                    continue

                # æ£€æŸ¥æ–‡ä»¶æ—¶é—´
                file_time = datetime.fromtimestamp(log_file.stat().st_mtime)
                if datetime.now() - file_time > timedelta(days=days):
                    continue

                logger.debug(f"åˆ†ææ—¥å¿—æ–‡ä»¶: {log_file}")

                try:
                    with open(log_file, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()

                        # æŸ¥æ‰¾æ‰€æœ‰é”™è¯¯ç 
                        for pattern in self.error_code_patterns:
                            matches = re.findall(pattern, content)
                            for match in matches:
                                log_stats[match] += 1

                except Exception as e:
                    logger.warning(f"æ— æ³•è¯»å–æ—¥å¿—æ–‡ä»¶ {log_file}: {e}")

        # æ¨¡æ‹Ÿä¸€äº›æ•°æ®ï¼ˆç”¨äºæ¼”ç¤ºï¼‰
        if not log_stats:
            log_stats = {
                'ERR_001': 150,
                'ERR_002': 89,
                'ERR_003': 45,
                'ERR_004': 12,
                'ERR_005': 3,
                'ERROR_NOT_FOUND': 234,
                'ERROR_UNAUTHORIZED': 567
            }

        return dict(log_stats)

    def classify_error_codes(
        self,
        definitions: Dict[str, ErrorCode],
        usage: Dict[str, List[str]],
        log_stats: Dict[str, int]
    ) -> Dict[str, List[str]]:
        """
        åˆ†ç±»é”™è¯¯ç çŠ¶æ€

        Args:
            definitions: å®šä¹‰å­—å…¸
            usage: ä½¿ç”¨å­—å…¸
            log_stats: æ—¥å¿—ç»Ÿè®¡

        Returns:
            åˆ†ç±»ç»“æœ
        """
        classification = {
            'ACTIVE': [],       # æ´»è·ƒä½¿ç”¨ï¼ˆä»£ç å’Œæ—¥å¿—ä¸­éƒ½æœ‰ï¼‰
            'RARE': [],         # å¾ˆå°‘ä½¿ç”¨ï¼ˆ<10æ¬¡/æœˆï¼‰
            'UNUSED': [],       # ä»£ç ä¸­æœªä½¿ç”¨
            'DEPRECATED': [],   # æ ‡è®°ä¸ºå¼ƒç”¨
            'DUPLICATE': [],    # é‡å¤å®šä¹‰
            'ORPHAN': [],       # åªåœ¨æ—¥å¿—ä¸­å‡ºç°ï¼Œä»£ç ä¸­æ— å®šä¹‰
            'ZOMBIE': []        # è¶…è¿‡60å¤©æœªä½¿ç”¨
        }

        # åˆ†ç±»å®šä¹‰çš„é”™è¯¯ç 
        for code, error_code in definitions.items():
            # æ£€æŸ¥æ˜¯å¦æ ‡è®°ä¸ºå¼ƒç”¨
            if 'deprecated' in error_code.message.lower():
                classification['DEPRECATED'].append(code)
                error_code.status = 'DEPRECATED'
                continue

            # æ£€æŸ¥æ˜¯å¦é‡å¤
            if code in self.duplicate_codes:
                classification['DUPLICATE'].append(code)
                error_code.status = 'DUPLICATE'
                continue

            # æ£€æŸ¥ä½¿ç”¨æƒ…å†µ
            if code in usage:
                # åœ¨ä»£ç ä¸­ä½¿ç”¨
                log_count = log_stats.get(code, 0)

                if log_count > 100:
                    classification['ACTIVE'].append(code)
                    error_code.status = 'ACTIVE'
                elif log_count > 10:
                    classification['RARE'].append(code)
                    error_code.status = 'RARE'
                else:
                    # ä»£ç ä¸­æœ‰ä½†æ—¥å¿—ä¸­å¾ˆå°‘
                    classification['RARE'].append(code)
                    error_code.status = 'RARE'

                error_code.usage_count = log_count
                error_code.usage_locations = usage[code]
            else:
                # ä»£ç ä¸­æœªä½¿ç”¨
                if log_stats.get(code, 0) > 0:
                    # æ—¥å¿—ä¸­æœ‰ä½†ä»£ç ä¸­æ²¡æœ‰ï¼ˆå¯èƒ½æ˜¯æ—§ç‰ˆæœ¬ï¼‰
                    classification['ZOMBIE'].append(code)
                    error_code.status = 'ZOMBIE'
                else:
                    # å®Œå…¨æœªä½¿ç”¨
                    classification['UNUSED'].append(code)
                    error_code.status = 'UNUSED'

        # æŸ¥æ‰¾å­¤å„¿é”™è¯¯ç ï¼ˆåªåœ¨æ—¥å¿—ä¸­ï¼‰
        for code in log_stats:
            if code not in definitions:
                classification['ORPHAN'].append(code)

        return classification

    def detect_duplicates(self, definitions: Dict[str, ErrorCode]) -> Dict[str, List[Dict]]:
        """
        æ£€æµ‹é‡å¤çš„é”™è¯¯ç 

        Args:
            definitions: å®šä¹‰å­—å…¸

        Returns:
            é‡å¤é”™è¯¯ç ä¿¡æ¯
        """
        duplicates = {}

        for code, locations in self.duplicate_codes.items():
            if len(locations) > 0:
                # åŠ ä¸ŠåŸå§‹å®šä¹‰ä½ç½®
                all_locations = locations.copy()
                if code in definitions:
                    all_locations.insert(0, {
                        'file': definitions[code].file_path,
                        'line': definitions[code].line_number
                    })
                duplicates[code] = all_locations

        return duplicates

    def _extract_from_json(self, file_path: Path) -> List[ErrorCode]:
        """ä»JSONæ–‡ä»¶æå–é”™è¯¯ç """
        codes = []

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

                # é€’å½’æŸ¥æ‰¾é”™è¯¯ç 
                def extract_from_dict(obj, path=""):
                    if isinstance(obj, dict):
                        for key, value in obj.items():
                            if self._is_error_code(key):
                                codes.append(ErrorCode(
                                    code=key,
                                    message=str(value) if not isinstance(value, dict) else value.get('message', ''),
                                    file_path=str(file_path.relative_to(self.project_root)),
                                    line_number=0
                                ))
                            if isinstance(value, (dict, list)):
                                extract_from_dict(value, f"{path}.{key}")
                    elif isinstance(obj, list):
                        for item in obj:
                            extract_from_dict(item, path)

                extract_from_dict(data)

        except Exception as e:
            logger.warning(f"æ— æ³•è§£æJSONæ–‡ä»¶ {file_path}: {e}")

        return codes

    def _extract_from_python(self, file_path: Path) -> List[ErrorCode]:
        """ä»Pythonæ–‡ä»¶æå–é”™è¯¯ç """
        codes = []

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # å°è¯•ä½¿ç”¨ASTè§£æ
            try:
                tree = ast.parse(content)
                for node in ast.walk(tree):
                    if isinstance(node, ast.Assign):
                        # æŸ¥æ‰¾èµ‹å€¼è¯­å¥
                        for target in node.targets:
                            if isinstance(target, ast.Name):
                                if self._is_error_code(target.id):
                                    # è·å–å€¼
                                    value = ""
                                    if isinstance(node.value, ast.Constant):
                                        value = str(node.value.value)
                                    elif isinstance(node.value, ast.Str):
                                        value = node.value.s

                                    codes.append(ErrorCode(
                                        code=target.id,
                                        message=value,
                                        file_path=str(file_path.relative_to(self.project_root)),
                                        line_number=node.lineno if hasattr(node, 'lineno') else 0
                                    ))
            except SyntaxError:
                # ASTè§£æå¤±è´¥ï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼
                codes.extend(self._extract_with_regex(file_path))

        except Exception as e:
            logger.warning(f"æ— æ³•è§£æPythonæ–‡ä»¶ {file_path}: {e}")

        return codes

    def _extract_with_regex(self, file_path: Path) -> List[ErrorCode]:
        """ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–é”™è¯¯ç """
        codes = []

        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                lines = f.readlines()

            for line_num, line in enumerate(lines, 1):
                for pattern in self.error_code_patterns:
                    matches = re.findall(pattern, line)
                    for match in matches:
                        # æ£€æŸ¥æ˜¯å¦æ˜¯å®šä¹‰ï¼ˆåŒ…å«èµ‹å€¼ï¼‰
                        if '=' in line or ':' in line or 'const' in line or 'define' in line:
                            codes.append(ErrorCode(
                                code=match,
                                message=line.strip(),
                                file_path=str(file_path.relative_to(self.project_root)),
                                line_number=line_num
                            ))

        except Exception as e:
            logger.warning(f"æ— æ³•è¯»å–æ–‡ä»¶ {file_path}: {e}")

        return codes

    def _extract_used_codes(self, file_path: Path) -> Set[str]:
        """æå–æ–‡ä»¶ä¸­ä½¿ç”¨çš„é”™è¯¯ç """
        used_codes = set()

        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()

            for pattern in self.error_code_patterns:
                matches = re.findall(pattern, content)
                used_codes.update(matches)

        except Exception as e:
            logger.warning(f"æ— æ³•è¯»å–æ–‡ä»¶ {file_path}: {e}")

        return used_codes

    def _should_skip_file(self, file_path: Path) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è·³è¿‡æ–‡ä»¶"""
        # æ£€æŸ¥æ˜¯å¦åœ¨å¿½ç•¥ç›®å½•ä¸­
        for parent in file_path.parents:
            if parent.name in self.ignore_dirs:
                return True

        # æ£€æŸ¥æ–‡ä»¶æœ¬èº«
        if file_path.name.startswith('.'):
            return True

        return False

    def _is_error_code(self, text: str) -> bool:
        """åˆ¤æ–­æ–‡æœ¬æ˜¯å¦ä¸ºé”™è¯¯ç """
        for pattern in self.error_code_patterns:
            if re.match(f'^{pattern}$', text):
                return True
        return False

    def _generate_summary(self, classification: Dict[str, List[str]]) -> Dict[str, Any]:
        """ç”Ÿæˆæ±‡æ€»ä¿¡æ¯"""
        total = sum(len(codes) for codes in classification.values())

        return {
            'total_codes': total,
            'active_codes': len(classification['ACTIVE']),
            'rare_codes': len(classification['RARE']),
            'unused_codes': len(classification['UNUSED']),
            'deprecated_codes': len(classification['DEPRECATED']),
            'duplicate_codes': len(classification['DUPLICATE']),
            'orphan_codes': len(classification['ORPHAN']),
            'zombie_codes': len(classification['ZOMBIE']),
            'active_rate': len(classification['ACTIVE']) / total * 100 if total > 0 else 0,
            'cleanup_potential': len(classification['UNUSED']) + len(classification['ZOMBIE'])
        }

    def generate_report(self, scan_results: Dict[str, Any]) -> str:
        """
        ç”Ÿæˆæ‰«ææŠ¥å‘Š

        Args:
            scan_results: æ‰«æç»“æœ

        Returns:
            Markdownæ ¼å¼æŠ¥å‘Š
        """
        summary = scan_results['summary']
        classification = scan_results['classification']
        duplicates = scan_results['duplicates']

        report = f"""# é”™è¯¯ç æ‰«ææŠ¥å‘Š

**æ‰«ææ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**é¡¹ç›®è·¯å¾„**: {self.project_root}

## ğŸ“Š æ±‡æ€»ç»Ÿè®¡

- **æ€»é”™è¯¯ç æ•°**: {summary['total_codes']}
- **æ´»è·ƒé”™è¯¯ç **: {summary['active_codes']} ({summary['active_rate']:.1f}%)
- **ç¨€æœ‰ä½¿ç”¨**: {summary['rare_codes']}
- **æœªä½¿ç”¨**: {summary['unused_codes']}
- **å·²å¼ƒç”¨**: {summary['deprecated_codes']}
- **é‡å¤å®šä¹‰**: {summary['duplicate_codes']}
- **å­¤å„¿ç **: {summary['orphan_codes']}
- **åƒµå°¸ç **: {summary['zombie_codes']}
- **æ¸…ç†æ½œåŠ›**: {summary['cleanup_potential']} ä¸ª

## ğŸ” è¯¦ç»†åˆ†ç±»

### âœ… æ´»è·ƒé”™è¯¯ç  (ACTIVE)
"""
        if classification['ACTIVE']:
            for code in classification['ACTIVE'][:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                report += f"- `{code}`\n"
            if len(classification['ACTIVE']) > 10:
                report += f"- ... è¿˜æœ‰ {len(classification['ACTIVE']) - 10} ä¸ª\n"
        else:
            report += "- æ— \n"

        report += """
### âš ï¸ ç¨€æœ‰ä½¿ç”¨ (RARE)
"""
        if classification['RARE']:
            for code in classification['RARE'][:10]:
                report += f"- `{code}`\n"
            if len(classification['RARE']) > 10:
                report += f"- ... è¿˜æœ‰ {len(classification['RARE']) - 10} ä¸ª\n"
        else:
            report += "- æ— \n"

        report += """
### ğŸ—‘ï¸ æœªä½¿ç”¨ (UNUSED)
"""
        if classification['UNUSED']:
            for code in classification['UNUSED'][:20]:
                report += f"- `{code}` - å»ºè®®åˆ é™¤\n"
            if len(classification['UNUSED']) > 20:
                report += f"- ... è¿˜æœ‰ {len(classification['UNUSED']) - 20} ä¸ª\n"
        else:
            report += "- æ— \n"

        report += """
### ğŸ§Ÿ åƒµå°¸ç  (ZOMBIE)
"""
        if classification['ZOMBIE']:
            report += "ä»¥ä¸‹é”™è¯¯ç è¶…è¿‡60å¤©æœªä½¿ç”¨:\n"
            for code in classification['ZOMBIE']:
                report += f"- `{code}` - å¼ºçƒˆå»ºè®®åˆ é™¤\n"
        else:
            report += "- æ— \n"

        report += """
### ğŸ”„ é‡å¤å®šä¹‰ (DUPLICATE)
"""
        if duplicates:
            for code, locations in duplicates.items():
                report += f"\n**`{code}`** å®šä¹‰åœ¨:\n"
                for loc in locations:
                    report += f"  - {loc['file']}:{loc['line']}\n"
        else:
            report += "- æ— \n"

        report += """
## ğŸ’¡ å»ºè®®

1. **ç«‹å³è¡ŒåŠ¨**:
"""
        if classification['UNUSED']:
            report += f"   - åˆ é™¤ {len(classification['UNUSED'])} ä¸ªæœªä½¿ç”¨çš„é”™è¯¯ç \n"
        if classification['ZOMBIE']:
            report += f"   - æ¸…ç† {len(classification['ZOMBIE'])} ä¸ªåƒµå°¸é”™è¯¯ç \n"
        if duplicates:
            report += f"   - åˆå¹¶ {len(duplicates)} ä¸ªé‡å¤å®šä¹‰\n"

        report += """
2. **è®¡åˆ’è¡ŒåŠ¨**:
"""
        if classification['RARE']:
            report += f"   - è¯„ä¼° {len(classification['RARE'])} ä¸ªç¨€æœ‰ä½¿ç”¨çš„é”™è¯¯ç \n"
        if classification['DEPRECATED']:
            report += f"   - ç§»é™¤ {len(classification['DEPRECATED'])} ä¸ªå·²å¼ƒç”¨çš„é”™è¯¯ç \n"

        report += """
3. **é•¿æœŸä¼˜åŒ–**:
   - å»ºç«‹é”™è¯¯ç ç”Ÿå‘½å‘¨æœŸç®¡ç†æµç¨‹
   - å®šæœŸè¿è¡Œæ¸…ç†è„šæœ¬ï¼ˆå»ºè®®æ¯æœˆä¸€æ¬¡ï¼‰
   - ç»´æŠ¤é”™è¯¯ç æ–‡æ¡£çš„åŠæ—¶æ€§

## ğŸ“ˆ è¶‹åŠ¿åˆ†æ

å½“å‰æ´»è·ƒç‡: **{:.1f}%**

å»ºè®®ç›®æ ‡:
- çŸ­æœŸç›®æ ‡: æ´»è·ƒç‡ > 60%
- é•¿æœŸç›®æ ‡: æ´»è·ƒç‡ > 80%

é€šè¿‡æ¸…ç†å»ºè®®çš„é”™è¯¯ç ï¼Œé¢„è®¡å¯å°†æ´»è·ƒç‡æå‡åˆ°: **{:.1f}%**
""".format(
            summary['active_rate'],
            (summary['active_codes'] / (summary['total_codes'] - summary['cleanup_potential']) * 100)
            if (summary['total_codes'] - summary['cleanup_potential']) > 0 else 100
        )

        return report


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description='é”™è¯¯ç æ‰«æå™¨')
    parser.add_argument('--output', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--format', choices=['json', 'markdown', 'console'],
                       default='console', help='è¾“å‡ºæ ¼å¼')
    parser.add_argument('--project-root', help='é¡¹ç›®æ ¹ç›®å½•')
    parser.add_argument('--verbose', action='store_true', help='è¯¦ç»†è¾“å‡º')

    args = parser.parse_args()

    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    # åˆ›å»ºæ‰«æå™¨
    project_root = Path(args.project_root) if args.project_root else None
    scanner = ErrorCodeScanner(project_root)

    # æ‰§è¡Œæ‰«æ
    results = scanner.scan_all()

    # ç”Ÿæˆè¾“å‡º
    if args.format == 'json':
        output = json.dumps(results, indent=2, default=str)
    elif args.format == 'markdown':
        output = scanner.generate_report(results)
    else:
        # æ§åˆ¶å°è¾“å‡º
        summary = results['summary']
        output = f"""
é”™è¯¯ç æ‰«æç»“æœ
==============

ğŸ“Š ç»Ÿè®¡:
  æ€»æ•°: {summary['total_codes']}
  æ´»è·ƒ: {summary['active_codes']} ({summary['active_rate']:.1f}%)
  æœªä½¿ç”¨: {summary['unused_codes']}
  åƒµå°¸: {summary['zombie_codes']}
  é‡å¤: {summary['duplicate_codes']}

ğŸ¯ æ¸…ç†å»ºè®®:
  å¯åˆ é™¤: {summary['cleanup_potential']} ä¸ªé”™è¯¯ç 
  é¢„è®¡æ´»è·ƒç‡æå‡: {summary['active_rate']:.1f}% â†’ {(summary['active_codes'] / (summary['total_codes'] - summary['cleanup_potential']) * 100) if (summary['total_codes'] - summary['cleanup_potential']) > 0 else 100:.1f}%

è¿è¡Œ --format markdown æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š
"""

    # è¾“å‡ºç»“æœ
    if args.output:
        with open(args.output, 'w') as f:
            f.write(output)
        print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜åˆ°: {args.output}")
    else:
        print(output)


if __name__ == '__main__':
    main()