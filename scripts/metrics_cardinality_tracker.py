#!/usr/bin/env python3
"""
Metrics Cardinality Tracker
å®æ—¶è¿½è¸ªå’Œåˆ†æPrometheusæŒ‡æ ‡åŸºæ•°ï¼Œé¢„æµ‹å­˜å‚¨æˆæœ¬
"""

import json
import logging
import re
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
from urllib.parse import urljoin
import requests
from collections import defaultdict
import hashlib

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class CardinalityInfo:
    """æŒ‡æ ‡åŸºæ•°ä¿¡æ¯"""
    metric_name: str
    cardinality: int  # æ—¶é—´åºåˆ—æ•°
    labels: Dict[str, int]  # labelå -> å”¯ä¸€å€¼æ•°é‡
    sample_labels: List[Dict[str, str]]  # æ ·æœ¬labelç»„åˆ
    bytes_per_sample: int = 16  # æ¯ä¸ªæ ·æœ¬çš„å­˜å‚¨å­—èŠ‚æ•°
    retention_days: int = 15  # æ•°æ®ä¿ç•™å¤©æ•°
    samples_per_day: int = 8640  # æ¯å¤©é‡‡æ ·æ•°ï¼ˆ10sé—´éš”ï¼‰

    @property
    def storage_bytes(self) -> int:
        """è®¡ç®—å­˜å‚¨å ç”¨ï¼ˆå­—èŠ‚ï¼‰"""
        return self.cardinality * self.bytes_per_sample * self.samples_per_day * self.retention_days

    @property
    def storage_mb(self) -> float:
        """å­˜å‚¨å ç”¨ï¼ˆMBï¼‰"""
        return self.storage_bytes / (1024 * 1024)

    @property
    def monthly_cost(self) -> float:
        """æœˆåº¦å­˜å‚¨æˆæœ¬ï¼ˆå‡è®¾ $0.001 per MB per monthï¼‰"""
        return self.storage_mb * 0.001


@dataclass
class TrendInfo:
    """åŸºæ•°è¶‹åŠ¿ä¿¡æ¯"""
    metric_name: str
    current_cardinality: int
    previous_cardinality: int
    growth_rate: float  # å¢é•¿ç‡ç™¾åˆ†æ¯”
    growth_absolute: int  # ç»å¯¹å¢é•¿é‡
    timestamp: str

    @property
    def is_growing(self) -> bool:
        return self.growth_rate > 0

    @property
    def is_exploding(self) -> bool:
        """æ˜¯å¦çˆ†ç‚¸å¼å¢é•¿ï¼ˆ>50%ï¼‰"""
        return self.growth_rate > 50


@dataclass
class LabelAnalysis:
    """Labelåˆ†æç»“æœ"""
    label_name: str
    unique_values: int
    entropy: float  # ä¿¡æ¯ç†µï¼Œè¶Šé«˜è¯´æ˜åˆ†å¸ƒè¶Šå‡åŒ€
    top_values: List[Tuple[str, int]]  # (å€¼, å‡ºç°æ¬¡æ•°)
    recommendation: str  # ä¼˜åŒ–å»ºè®®


class PrometheusClient:
    """Prometheuså®¢æˆ·ç«¯"""

    def __init__(self, url: str, timeout: int = 30):
        self.url = url.rstrip('/')
        self.timeout = timeout
        self.session = requests.Session()

    def query(self, query: str) -> Dict[str, Any]:
        """æ‰§è¡ŒPrometheusæŸ¥è¯¢"""
        endpoint = urljoin(self.url, '/api/v1/query')
        params = {'query': query}

        try:
            response = self.session.get(
                endpoint,
                params=params,
                timeout=self.timeout
            )
            response.raise_for_status()
            data = response.json()

            if data.get('status') != 'success':
                raise ValueError(f"Query failed: {data.get('error', 'Unknown error')}")

            return data.get('data', {})
        except Exception as e:
            logger.error(f"Prometheus query failed: {e}")
            raise

    def get_all_metrics(self) -> List[str]:
        """è·å–æ‰€æœ‰æŒ‡æ ‡åç§°"""
        endpoint = urljoin(self.url, '/api/v1/label/__name__/values')

        try:
            response = self.session.get(endpoint, timeout=self.timeout)
            response.raise_for_status()
            data = response.json()

            if data.get('status') == 'success':
                return data.get('data', [])
            return []
        except Exception as e:
            logger.error(f"Failed to get metrics list: {e}")
            return []


class MetricsCardinalityTracker:
    """æŒ‡æ ‡åŸºæ•°è¿½è¸ªå™¨"""

    def __init__(self, prometheus_url: str):
        self.prom_client = PrometheusClient(prometheus_url)
        self.cardinality_cache = {}
        self.history = defaultdict(list)  # å†å²è®°å½•

    def get_metric_cardinality(self, metric_name: str) -> Optional[CardinalityInfo]:
        """
        è·å–æŒ‡æ ‡çš„åŸºæ•°ä¿¡æ¯

        Args:
            metric_name: æŒ‡æ ‡åç§°

        Returns:
            CardinalityInfoå¯¹è±¡ï¼ŒåŒ…å«åŸºæ•°å’Œæˆæœ¬ä¿¡æ¯
        """
        try:
            # æŸ¥è¯¢è¯¥æŒ‡æ ‡çš„æ‰€æœ‰æ—¶é—´åºåˆ—
            query = f'group by(__name__, {metric_name}) ({{__name__="{metric_name}"}})'
            # ç®€åŒ–æŸ¥è¯¢ï¼šç›´æ¥è·å–æŒ‡æ ‡
            query = f'{metric_name}'

            result = self.prom_client.query(query)

            if not result or 'result' not in result:
                return None

            series_list = result['result']
            cardinality = len(series_list)

            # åˆ†ælabels
            label_stats = defaultdict(set)
            sample_labels = []

            for series in series_list[:100]:  # é‡‡æ ·å‰100ä¸ª
                labels = series.get('metric', {})
                sample_labels.append(labels)

                for key, value in labels.items():
                    if key != '__name__':
                        label_stats[key].add(value)

            # è½¬æ¢ä¸ºlabelè®¡æ•°
            labels_count = {
                key: len(values) for key, values in label_stats.items()
            }

            info = CardinalityInfo(
                metric_name=metric_name,
                cardinality=cardinality,
                labels=labels_count,
                sample_labels=sample_labels[:10]  # ä¿ç•™10ä¸ªæ ·æœ¬
            )

            # ç¼“å­˜ç»“æœ
            self.cardinality_cache[metric_name] = info

            # è®°å½•å†å²
            self.history[metric_name].append({
                'timestamp': datetime.now().isoformat(),
                'cardinality': cardinality
            })

            return info

        except Exception as e:
            logger.error(f"Failed to get cardinality for {metric_name}: {e}")
            return None

    def track_cardinality_trends(self, metrics: Optional[List[str]] = None) -> List[TrendInfo]:
        """
        è¿½è¸ªæŒ‡æ ‡åŸºæ•°å˜åŒ–è¶‹åŠ¿

        Args:
            metrics: è¦è¿½è¸ªçš„æŒ‡æ ‡åˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºæ‰€æœ‰æŒ‡æ ‡

        Returns:
            è¶‹åŠ¿ä¿¡æ¯åˆ—è¡¨
        """
        if metrics is None:
            metrics = self.prom_client.get_all_metrics()

        trends = []

        for metric in metrics:
            try:
                current_info = self.get_metric_cardinality(metric)
                if not current_info:
                    continue

                # ä»å†å²è®°å½•è·å–ä¹‹å‰çš„åŸºæ•°
                history = self.history.get(metric, [])
                if len(history) < 2:
                    continue

                previous_cardinality = history[-2]['cardinality']
                current_cardinality = current_info.cardinality

                # è®¡ç®—å¢é•¿
                growth_absolute = current_cardinality - previous_cardinality
                growth_rate = (growth_absolute / max(previous_cardinality, 1)) * 100

                trend = TrendInfo(
                    metric_name=metric,
                    current_cardinality=current_cardinality,
                    previous_cardinality=previous_cardinality,
                    growth_rate=round(growth_rate, 2),
                    growth_absolute=growth_absolute,
                    timestamp=datetime.now().isoformat()
                )

                trends.append(trend)

            except Exception as e:
                logger.error(f"Failed to track trend for {metric}: {e}")

        # æŒ‰å¢é•¿ç‡æ’åº
        trends.sort(key=lambda x: abs(x.growth_rate), reverse=True)

        return trends

    def identify_high_cardinality_labels(self, metric_name: str, threshold: int = 100) -> List[LabelAnalysis]:
        """
        è¯†åˆ«é«˜åŸºæ•°çš„labels

        Args:
            metric_name: æŒ‡æ ‡åç§°
            threshold: é«˜åŸºæ•°é˜ˆå€¼

        Returns:
            Labelåˆ†æç»“æœåˆ—è¡¨
        """
        info = self.cardinality_cache.get(metric_name) or self.get_metric_cardinality(metric_name)

        if not info:
            return []

        analyses = []

        for label_name, unique_count in info.labels.items():
            # è®¡ç®—è¯¥labelçš„å€¼åˆ†å¸ƒ
            value_counts = defaultdict(int)
            for sample in info.sample_labels:
                if label_name in sample:
                    value_counts[sample[label_name]] += 1

            # è®¡ç®—ä¿¡æ¯ç†µ
            total = sum(value_counts.values())
            entropy = 0
            if total > 0:
                for count in value_counts.values():
                    p = count / total
                    if p > 0:
                        entropy -= p * (p if p == 1 else p * (1 - p))

            # è·å–topå€¼
            top_values = sorted(
                value_counts.items(),
                key=lambda x: x[1],
                reverse=True
            )[:5]

            # ç”Ÿæˆä¼˜åŒ–å»ºè®®
            recommendation = self._generate_label_recommendation(
                label_name, unique_count, entropy, threshold
            )

            analysis = LabelAnalysis(
                label_name=label_name,
                unique_values=unique_count,
                entropy=round(entropy, 3),
                top_values=top_values,
                recommendation=recommendation
            )

            analyses.append(analysis)

        # æŒ‰å”¯ä¸€å€¼æ•°é‡æ’åº
        analyses.sort(key=lambda x: x.unique_values, reverse=True)

        return analyses

    def _generate_label_recommendation(self, label_name: str, unique_count: int,
                                      entropy: float, threshold: int) -> str:
        """ç”Ÿæˆlabelä¼˜åŒ–å»ºè®®"""
        recommendations = []

        if unique_count > threshold * 10:
            recommendations.append(f"âš ï¸ æé«˜åŸºæ•°({unique_count})ï¼Œå»ºè®®åˆ é™¤æˆ–ä½¿ç”¨recording rule")
        elif unique_count > threshold:
            recommendations.append(f"âš¡ é«˜åŸºæ•°({unique_count})ï¼Œå»ºè®®å‡å°‘ç²’åº¦æˆ–åˆå¹¶å€¼")

        if entropy > 0.9:
            recommendations.append("ğŸ“Š åˆ†å¸ƒå‡åŒ€ï¼Œå¯èƒ½æ˜¯IDç±»å‹ï¼Œå»ºè®®ç§»é™¤")
        elif entropy < 0.3:
            recommendations.append("ğŸ“ˆ åˆ†å¸ƒé›†ä¸­ï¼Œå¯ä»¥è€ƒè™‘åªä¿ç•™topå€¼")

        # ç‰¹å®šlabelçš„å»ºè®®
        if 'id' in label_name.lower() or 'uuid' in label_name.lower():
            recommendations.append("ğŸ†” IDç±»å‹labelï¼Œå¼ºçƒˆå»ºè®®ç§»é™¤")
        elif 'user' in label_name.lower():
            recommendations.append("ğŸ‘¤ ç”¨æˆ·ç›¸å…³labelï¼Œå»ºè®®é‡‡æ ·æˆ–èšåˆ")
        elif 'path' in label_name.lower() or 'url' in label_name.lower():
            recommendations.append("ğŸ”— è·¯å¾„ç±»labelï¼Œå»ºè®®è§„èŒƒåŒ–æˆ–åˆ†ç»„")

        return " | ".join(recommendations) if recommendations else "âœ… åŸºæ•°åˆç†"

    def estimate_total_cost(self) -> Dict[str, Any]:
        """ä¼°ç®—æ€»ä½“æˆæœ¬"""
        total_cardinality = 0
        total_storage_mb = 0
        total_monthly_cost = 0
        metrics_count = 0

        top_cost_metrics = []

        for metric_name, info in self.cardinality_cache.items():
            total_cardinality += info.cardinality
            total_storage_mb += info.storage_mb
            total_monthly_cost += info.monthly_cost
            metrics_count += 1

            top_cost_metrics.append({
                'metric': metric_name,
                'cardinality': info.cardinality,
                'storage_mb': round(info.storage_mb, 2),
                'monthly_cost': round(info.monthly_cost, 4)
            })

        # æŒ‰æˆæœ¬æ’åºï¼Œå–top 10
        top_cost_metrics.sort(key=lambda x: x['monthly_cost'], reverse=True)

        return {
            'total_metrics': metrics_count,
            'total_cardinality': total_cardinality,
            'total_storage_mb': round(total_storage_mb, 2),
            'total_monthly_cost': round(total_monthly_cost, 2),
            'average_cardinality': round(total_cardinality / max(metrics_count, 1), 2),
            'top_cost_metrics': top_cost_metrics[:10]
        }

    def export_cardinality_data(self, output_file: str = None) -> str:
        """å¯¼å‡ºåŸºæ•°æ•°æ®"""
        data = {
            'timestamp': datetime.now().isoformat(),
            'metrics': {}
        }

        for metric_name, info in self.cardinality_cache.items():
            data['metrics'][metric_name] = {
                'cardinality': info.cardinality,
                'labels': info.labels,
                'storage_mb': round(info.storage_mb, 2),
                'monthly_cost': round(info.monthly_cost, 4)
            }

        # æ·»åŠ æ±‡æ€»
        data['summary'] = self.estimate_total_cost()

        json_str = json.dumps(data, indent=2, ensure_ascii=False)

        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(json_str)

        return json_str


def main():
    """ä¸»å‡½æ•° - ç”¨äºæµ‹è¯•"""
    import argparse

    parser = argparse.ArgumentParser(description='Prometheus Metrics Cardinality Tracker')
    parser.add_argument('--prometheus-url', default='http://localhost:9090',
                       help='Prometheus server URL')
    parser.add_argument('--metric', help='Specific metric to analyze')
    parser.add_argument('--top', type=int, default=10,
                       help='Number of top metrics to show')
    parser.add_argument('--output', help='Output JSON file')
    parser.add_argument('--analyze-labels', action='store_true',
                       help='Analyze high cardinality labels')

    args = parser.parse_args()

    # åˆ›å»ºè¿½è¸ªå™¨
    tracker = MetricsCardinalityTracker(args.prometheus_url)

    if args.metric:
        # åˆ†æç‰¹å®šæŒ‡æ ‡
        info = tracker.get_metric_cardinality(args.metric)
        if info:
            print(f"\nğŸ“Š Metric: {info.metric_name}")
            print(f"   Cardinality: {info.cardinality:,}")
            print(f"   Storage: {info.storage_mb:.2f} MB")
            print(f"   Monthly Cost: ${info.monthly_cost:.4f}")
            print(f"   Labels: {json.dumps(info.labels, indent=4)}")

            if args.analyze_labels:
                print("\nğŸ·ï¸ Label Analysis:")
                analyses = tracker.identify_high_cardinality_labels(args.metric)
                for analysis in analyses[:5]:
                    print(f"\n   Label: {analysis.label_name}")
                    print(f"   Unique Values: {analysis.unique_values}")
                    print(f"   Entropy: {analysis.entropy}")
                    print(f"   Recommendation: {analysis.recommendation}")
        else:
            print(f"âŒ Failed to analyze metric: {args.metric}")
    else:
        # åˆ†ææ‰€æœ‰æŒ‡æ ‡
        print("ğŸ” Analyzing all metrics...")
        metrics = tracker.prom_client.get_all_metrics()

        for metric in metrics[:args.top]:
            tracker.get_metric_cardinality(metric)

        # æ˜¾ç¤ºæˆæœ¬æ±‡æ€»
        cost_summary = tracker.estimate_total_cost()
        print(f"\nğŸ’° Cost Summary:")
        print(f"   Total Metrics: {cost_summary['total_metrics']}")
        print(f"   Total Cardinality: {cost_summary['total_cardinality']:,}")
        print(f"   Total Storage: {cost_summary['total_storage_mb']:.2f} MB")
        print(f"   Total Monthly Cost: ${cost_summary['total_monthly_cost']:.2f}")

        print(f"\nğŸ“ˆ Top {args.top} Cost Metrics:")
        for item in cost_summary['top_cost_metrics']:
            print(f"   {item['metric']}: {item['cardinality']:,} series, "
                  f"${item['monthly_cost']:.4f}/month")

    # å¯¼å‡ºæ•°æ®
    if args.output:
        tracker.export_cardinality_data(args.output)
        print(f"\nâœ… Data exported to: {args.output}")


if __name__ == "__main__":
    main()