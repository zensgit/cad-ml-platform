# DeepSeek-OCR å·¥ç¨‹è¯­ä¹‰ç†è§£å®Œæ•´æ–¹æ¡ˆ

**CAD ML Platform - OCRå¢å¼ºå­ç³»ç»ŸæŠ€æœ¯è®¾è®¡æ–‡æ¡£**

---

**æ–‡æ¡£ä¿¡æ¯**

| é¡¹ç›® | å†…å®¹ |
|------|------|
| æ–‡æ¡£ç‰ˆæœ¬ | v1.0 |
| åˆ›å»ºæ—¥æœŸ | 2025-01-14 |
| ä½œè€… | CAD ML Platform Team |
| é€‚ç”¨èŒƒå›´ | CAD ML Platform v1.1.0+ |
| æ–‡æ¡£ç±»å‹ | æŠ€æœ¯è®¾è®¡æ–¹æ¡ˆ |

**å˜æ›´å†å²**

| ç‰ˆæœ¬ | æ—¥æœŸ | å˜æ›´å†…å®¹ | ä½œè€… |
|------|------|---------|------|
| v1.0 | 2025-01-14 | åˆå§‹ç‰ˆæœ¬ | Team |

---

## ç›®å½•

1. [æ–¹æ¡ˆæ¦‚è¿°](#ä¸€æ–¹æ¡ˆæ¦‚è¿°)
2. [ç³»ç»Ÿæ¶æ„](#äºŒç³»ç»Ÿæ¶æ„)
3. [æ ¸å¿ƒæ¨¡å—è®¾è®¡](#ä¸‰æ ¸å¿ƒæ¨¡å—è®¾è®¡)
4. [APIå¥‘çº¦](#å››apiå¥‘çº¦)
5. [é…ç½®ç®¡ç†](#äº”é…ç½®ç®¡ç†)
6. [å®æ–½è·¯çº¿](#å…­å®æ–½è·¯çº¿)
7. [ç›‘æ§ä¸è¯„æµ‹](#ä¸ƒç›‘æ§ä¸è¯„æµ‹)
8. [ç”Ÿäº§éƒ¨ç½²](#å…«ç”Ÿäº§éƒ¨ç½²)
9. [éªŒæ”¶æ ‡å‡†](#ä¹éªŒæ”¶æ ‡å‡†)
10. [é™„å½•](#åé™„å½•)

---

## ä¸€ã€æ–¹æ¡ˆæ¦‚è¿°

### 1.1 ç›®æ ‡ä¸èŒƒå›´

**æ ¸å¿ƒç›®æ ‡**

é’ˆå¯¹å·¥ç¨‹å›¾/CADæˆªå›¾/æ‰«æä»¶ï¼Œç¨³å®šæŠ½å–**æ–‡æœ¬ã€å°ºå¯¸/å…¬å·®/ç¬¦å·ã€è¡¨æ ¼/æ ‡é¢˜æ **ï¼Œå¹¶æä¾›**é«˜å¯ç”¨ã€å¯è§£é‡Šã€å¯è§‚æµ‹**çš„OCRæœåŠ¡ã€‚

**èƒ½åŠ›èŒƒå›´**

- âœ… æ”¯æŒæœ¬åœ°ï¼ˆCPU/GPUï¼‰ä¸äº‘ç«¯å¤šprovideréƒ¨ç½²
- âœ… æ™ºèƒ½è·¯ç”±ï¼šæŒ‰æˆæœ¬/è´¨é‡/ååè‡ªåŠ¨é€‰æ‹©provider
- âœ… å·¥ç¨‹è¯­ä¹‰ç†è§£ï¼šå°ºå¯¸Î¦20Â±0.02 â†’ ç»“æ„åŒ–æ•°æ®
- âœ… å‡ ä½•å¯¹é½ï¼šOCRæ–‡æœ¬é”šå®šåˆ°CADå‡ ä½•å…ƒç´ 
- âœ… è¯æ®é©±åŠ¨ï¼šå®Œæ•´è¯æ®é“¾æ”¯æ’‘å¯è§£é‡Šæ€§
- âœ… ç”Ÿäº§å°±ç»ªï¼šç¼“å­˜ã€ç›‘æ§ã€é™çº§ã€å¹‚ç­‰æ€§

**ä¸ç°æœ‰ç³»ç»Ÿå¯¹é½**

- å¤ç”¨ `confidence_calibrator.py` çš„DSè¯æ®èåˆ
- å¤ç”¨ `Redis` ç¼“å­˜ä¸ `Prometheus` ç›‘æ§
- æ‰©å±•ç°æœ‰ `/api/v1/analyze` ç«¯ç‚¹
- ä¿æŒ `VisionProvider` çš„provideræ¨¡å¼ä¸€è‡´æ€§

### 1.2 æ ¸å¿ƒä»·å€¼

| ç»´åº¦ | ä¼ ç»ŸOCR | æœ¬æ–¹æ¡ˆï¼ˆå·¥ç¨‹è¯­ä¹‰OCRï¼‰ |
|------|---------|----------------------|
| **è¾“å‡º** | æ–‡æœ¬å­—ç¬¦ä¸² | ç»“æ„åŒ–å·¥ç¨‹æ•°æ® |
| **å°ºå¯¸è¯†åˆ«** | "Î¦20Â±0.02" | {type:"diameter", value:20, tolerance:0.02, unit:"mm"} |
| **å‡ ä½•å…³è”** | æ—  | å°ºå¯¸â†’å‡ ä½•å…ƒç´ é”šå®š |
| **æ ‡é¢˜æ ** | æ–‡æœ¬å †ç Œ | ç»“æ„åŒ–BOMï¼šå›¾å·/ææ–™/é‡é‡ |
| **ä¸‹æ¸¸åº”ç”¨** | æœ‰é™ | è£…é…æ¨ç†/å·¥è‰ºå»ºè®®/æˆæœ¬ä¼°ç®— |
| **è¯æ®é“¾** | æ—  | å®Œæ•´è¯æ®ï¼šprovider+ç½®ä¿¡åº¦+bbox+è§„åˆ™ |

---

## äºŒã€ç³»ç»Ÿæ¶æ„

### 2.1 æ•´ä½“æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        CAD ML Platform                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              APIå±‚ (FastAPI)                            â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚ POST /analyze    â”‚ POST /ocr/extractâ”‚ GET /health â”‚ â”‚  â”‚
â”‚  â”‚  â”‚ (é›†æˆOCRå¢å¼º)     â”‚ (ç›´é€šOCRç«¯ç‚¹)     â”‚ (å«OCRçŠ¶æ€) â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                              â†“                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚           OCRç®¡ç†å™¨ (OcrManager)                        â”‚  â”‚
â”‚  â”‚  â€¢ Providerè·¯ç”±ç­–ç•¥ (auto/paddle/deepseek_hf/vllm)      â”‚  â”‚
â”‚  â”‚  â€¢ è´¨é‡é—¨æ§ä¸Fallback                                   â”‚  â”‚
â”‚  â”‚  â€¢ ç¼“å­˜åè°ƒ (å›¾åƒå“ˆå¸Œ + provider + prompt)              â”‚  â”‚
â”‚  â”‚  â€¢ è¯æ®é“¾èšåˆ (å¤ç”¨confidence_calibrator.py)            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                              â†“                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Paddle      â”‚ DeepSeek-HF  â”‚ DeepSeek-   â”‚   Future    â”‚  â”‚
â”‚  â”‚  Provider    â”‚  Provider    â”‚   vLLM      â”‚  Providers  â”‚  â”‚
â”‚  â”‚  (CPUå¿«é€Ÿ)   â”‚ (GPUé«˜è´¨é‡)   â”‚ (GPUé«˜åå) â”‚   (æ‰©å±•)    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                              â†“                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚             å¢å¼ºå¤„ç†å±‚                                   â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚ é¢„å¤„ç†å™¨     â”‚  ç‰ˆé¢è§£æå™¨     â”‚  è£å‰ªåˆå¹¶å™¨      â”‚  â”‚  â”‚
â”‚  â”‚  â”‚ (å»å™ª/çŸ«æ­£)  â”‚ (é¡µ/å—/è¡¨æ£€æµ‹)  â”‚ (æ™ºèƒ½åˆ†å—+æ‹¼æ¥) â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚ ç»“æ„åŒ–è§£æå™¨ â”‚  å‡ ä½•å¯¹é½å™¨     â”‚ è´¨é‡æ§åˆ¶å™¨       â”‚  â”‚  â”‚
â”‚  â”‚  â”‚ (å°ºå¯¸/å…¬å·®/  â”‚ (æ–‡æœ¬â†’å‡ ä½•é”šå®š) â”‚ (é—¨æ§+é‡è¯•)     â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  ç¬¦å·/æ ‡é¢˜æ )â”‚                 â”‚                  â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                              â†“                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚          ä¸‹æ¸¸é›†æˆ (å·¥ç¨‹è¯­ä¹‰åº”ç”¨)                         â”‚  â”‚
â”‚  â”‚  â€¢ è£…é…æ¨ç†å¢å¼º (å°ºå¯¸â†’é…åˆå…³ç³»)                          â”‚  â”‚
â”‚  â”‚  â€¢ å·¥è‰ºå»ºè®®å¢å¼º (ææ–™/å…¬å·®â†’åŠ å·¥æ–¹æ³•)                     â”‚  â”‚
â”‚  â”‚  â€¢ æˆæœ¬ä¼°ç®—å¢å¼º (ææ–™/é‡é‡/å·¥è‰º)                         â”‚  â”‚
â”‚  â”‚  â€¢ ç›¸ä¼¼åº¦æ£€ç´¢å¢å¼º (è¯­ä¹‰+ç¬¦å·å‘é‡)                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚              æ¨ªåˆ‡å…³æ³¨ç‚¹ (Cross-Cutting Concerns)                â”‚
â”‚  â€¢ ç¼“å­˜: Redis (å›¾åƒå“ˆå¸Œ + å¹‚ç­‰æ€§Key)                          â”‚
â”‚  â€¢ ç›‘æ§: PrometheusæŒ‡æ ‡ + Grafanaé¢æ¿                          â”‚
â”‚  â€¢ æ—¥å¿—: ç»“æ„åŒ–JSONæ—¥å¿— + è¯æ®é“¾è¿½è¸ª                           â”‚
â”‚  â€¢ é…ç½®: ç¯å¢ƒåˆ†å±‚ (.env.dev / .env.prod)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 æ•°æ®æµå›¾

```
è¾“å…¥å›¾åƒ
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. é¢„å¤„ç†                                      â”‚
â”‚  â€¢ æ ¼å¼æ£€æµ‹ (çŸ¢é‡/æ‰«æ)                         â”‚
â”‚  â€¢ å»å™ª/äºŒå€¼åŒ–/çŸ«æ­£ (æŒ‰éœ€)                      â”‚
â”‚  â€¢ å¤§å›¾æ£€æµ‹ (>4Kè§¦å‘è£å‰ª)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. ç¼“å­˜æ£€æŸ¥                                    â”‚
â”‚  Key = sha256(image) + provider + prompt        â”‚
â”‚  Hit â†’ ç›´æ¥è¿”å›                                 â”‚
â”‚  Miss â†’ ç»§ç»­æµç¨‹                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Provideré€‰æ‹© (ç­–ç•¥è·¯ç”±)                     â”‚
â”‚  â€¢ auto: paddle â†’ (ä½ç½®ä¿¡åº¦) â†’ deepseek_hf      â”‚
â”‚  â€¢ explicit: æŒ‡å®šprovider                       â”‚
â”‚  â€¢ degraded: é™çº§åˆ°å¤‡ç”¨provider                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. OCRæ‰§è¡Œ                                     â”‚
â”‚  â€¢ PaddleOCR: æ£€æµ‹+è¯†åˆ«+ç‰ˆé¢åˆ†æ                â”‚
â”‚  â€¢ DeepSeek-HF: Transformersæ¨ç† + JSONè¾“å‡º     â”‚
â”‚  â€¢ DeepSeek-vLLM: å¼‚æ­¥æ‰¹å¤„ç† (Phase 3)         â”‚
â”‚  è¾“å‡º: {text, blocks[], layout, confidence}     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. ç»“æœè§„èŒƒåŒ–                                  â”‚
â”‚  â€¢ æ–‡æœ¬æ¸…æ´— (å…¨åŠè§’/ç¬¦å·ç»Ÿä¸€)                   â”‚
â”‚  â€¢ å•ä½æ ‡å‡†åŒ– (â†’mm)                             â”‚
â”‚  â€¢ BBoxåæ ‡æ ¡æ­£                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. ç»“æ„åŒ–è§£æ                                  â”‚
â”‚  â€¢ å°ºå¯¸è§£æ: Î¦20Â±0.02 â†’ {type:"diameter",       â”‚
â”‚    value:20, tolerance:0.02, unit:"mm"}         â”‚
â”‚  â€¢ å…¬å·®è§£æ: IT7, 6H/f7 â†’ å…¬å·®å¸¦æŸ¥è¡¨            â”‚
â”‚  â€¢ ç¬¦å·è§£æ: Ra3.2, âŸ‚A â†’ ç¬¦å·è¯å…¸åŒ¹é…           â”‚
â”‚  â€¢ æ ‡é¢˜æ è§£æ: å…³é”®è¯å®šä½ + è¡¨æ ¼ç»“æ„æ¢å¤        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  7. å‡ ä½•å¯¹é½ (å¦‚æœæœ‰CADæ•°æ®)                    â”‚
â”‚  â€¢ ç©ºé—´ç´¢å¼•æ„å»º (R-tree)                        â”‚
â”‚  â€¢ BBox â†’ å‡ ä½•å…ƒç´ æ˜ å°„ (è·ç¦»+æ•°å€¼åŒ¹é…)          â”‚
â”‚  â€¢ ç”ŸæˆAlignedDimension (æ–‡æœ¬+å‡ ä½•åŒé‡è¯æ®)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  8. è´¨é‡é—¨æ§                                    â”‚
â”‚  â€¢ æ£€æŸ¥å…³é”®å­—æ®µ (å›¾å·/ææ–™/ä¸»è¦å°ºå¯¸)            â”‚
â”‚  â€¢ æ£€æŸ¥ç½®ä¿¡åº¦é˜ˆå€¼                               â”‚
â”‚  â€¢ è§¦å‘Fallback (deepseek_hf) æˆ–è¿”å›            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  9. è¯æ®é“¾èåˆ                                  â”‚
â”‚  â€¢ å¤ç”¨confidence_calibrator.py                 â”‚
â”‚  â€¢ DSç†è®ºèåˆå¤šproviderç»“æœ                     â”‚
â”‚  â€¢ ç”Ÿæˆcalibrated_confidence                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  10. ç¼“å­˜å†™å…¥ + è¿”å›ç»“æœ                        â”‚
â”‚  â€¢ è½ç›˜ç¼“å­˜ (TTL=24h)                           â”‚
â”‚  â€¢ è®°å½•PrometheusæŒ‡æ ‡                           â”‚
â”‚  â€¢ è¿”å›EnhancedOcrResult                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.3 Provideré€‰æ‹©ç­–ç•¥

```python
# Autoç­–ç•¥å†³ç­–æ ‘
def select_provider(image, context):
    # Step 1: å¿«é€Ÿpaddle
    paddle_result = paddle.extract(image)

    # Step 2: åˆ¤æ–­æ˜¯å¦éœ€è¦å¢å¼º
    if paddle_result.confidence >= 0.85 and \
       has_critical_fields(paddle_result):
        return paddle_result  # âœ… è¶³å¤Ÿå¥½

    # Step 3: DeepSeekå¢å¼º
    deepseek_result = deepseek_hf.extract(image)

    # Step 4: èåˆç»“æœ
    return merge([paddle_result, deepseek_result])
```

---

## ä¸‰ã€æ ¸å¿ƒæ¨¡å—è®¾è®¡

### 3.1 ç›®å½•ç»“æ„

```
src/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ ocr/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py                 # æŠ½è±¡åŸºç±»ä¸æ•°æ®æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ manager.py              # OCRç®¡ç†å™¨ (è·¯ç”±+èåˆ)
â”‚   â”‚   â”œâ”€â”€ providers/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ paddle.py           # PaddleOCRå®ç°
â”‚   â”‚   â”‚   â”œâ”€â”€ deepseek_hf.py      # DeepSeek Transformers
â”‚   â”‚   â”‚   â””â”€â”€ deepseek_vllm.py    # DeepSeek vLLM (Phase 3)
â”‚   â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ image_enhancer.py   # å»å™ª/çŸ«æ­£/äºŒå€¼åŒ–
â”‚   â”‚   â”‚   â””â”€â”€ cropper.py          # æ™ºèƒ½è£å‰ªä¸åˆå¹¶
â”‚   â”‚   â”œâ”€â”€ parsing/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ dimension_parser.py # å°ºå¯¸/å…¬å·®è§£æ
â”‚   â”‚   â”‚   â”œâ”€â”€ symbol_parser.py    # ç¬¦å·è§£æ
â”‚   â”‚   â”‚   â”œâ”€â”€ title_block_parser.py # æ ‡é¢˜æ è§£æ
â”‚   â”‚   â”‚   â”œâ”€â”€ normalizer.py       # æ–‡æœ¬è§„èŒƒåŒ–
â”‚   â”‚   â”‚   â””â”€â”€ json_validator.py   # JSONä¸¥æ ¼æ ¡éªŒ
â”‚   â”‚   â”œâ”€â”€ alignment/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ geometric_aligner.py # å‡ ä½•å¯¹é½
â”‚   â”‚   â”œâ”€â”€ quality/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ gate.py             # è´¨é‡é—¨æ§
â”‚   â”‚   â”‚   â””â”€â”€ validator.py        # ç»“æœéªŒè¯
â”‚   â”‚   â”œâ”€â”€ concurrency.py          # å¹¶å‘æ§åˆ¶
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ prompt_templates.py # DeepSeekæç¤ºæ¨¡æ¿
â”‚   â”‚       â””â”€â”€ metrics.py          # OCRä¸“ç”¨æŒ‡æ ‡
â”‚   â””â”€â”€ vision_analyzer.py (æ‰©å±•: é›†æˆOcrManager)
â”‚
â”œâ”€â”€ api/
â”‚   â””â”€â”€ v1/
â”‚       â”œâ”€â”€ ocr.py                  # æ–°å¢: ç›´é€šOCRç«¯ç‚¹
â”‚       â”œâ”€â”€ analyze.py (æ‰©å±•: enable_ocrå‚æ•°)
â”‚       â””â”€â”€ __init__.py (æ‰©å±•: æ³¨å†ŒOCRè·¯ç”±)
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ ocr_models.py               # Pydanticæ•°æ®æ¨¡å‹
â”‚
â””â”€â”€ config/
    â””â”€â”€ ocr_config.py               # OCRé…ç½®ç±»
```

### 3.2 æ ¸å¿ƒç±»è®¾è®¡

#### 3.2.1 åŸºç¡€æŠ½è±¡ (base.py)

```python
"""
OCRåŸºç¡€æŠ½è±¡ä¸æ•°æ®æ¨¡å‹
src/core/ocr/base.py
"""

from abc import ABC, abstractmethod
from typing import List, Dict, Optional, Any
from pydantic import BaseModel, Field
from enum import Enum


class OcrProviderType(str, Enum):
    """OCR Providerç±»å‹"""
    PADDLE = "paddle"
    DEEPSEEK_HF = "deepseek_hf"
    DEEPSEEK_VLLM = "deepseek_vllm"
    AUTO = "auto"


class BBox(BaseModel):
    """è¾¹ç•Œæ¡†"""
    x: float
    y: float
    width: float
    height: float

    @property
    def center(self) -> tuple[float, float]:
        return (self.x + self.width/2, self.y + self.height/2)

    def iou(self, other: 'BBox') -> float:
        """è®¡ç®—IoU"""
        # ... å®ç°çœç•¥ ...


class DimensionInfo(BaseModel):
    """å°ºå¯¸ä¿¡æ¯ (ç»“æ„åŒ–)"""
    type: str = Field(..., description="ç±»å‹: diameter/radius/length/thread")
    value: float = Field(..., description="æ•°å€¼")
    unit: str = Field(default="mm", description="å•ä½")
    tolerance: Optional[float] = Field(None, description="å…¬å·®å€¼")
    tolerance_grade: Optional[str] = Field(None, description="å…¬å·®ç­‰çº§: IT6/IT7")
    bbox: BBox
    confidence: float
    source_text: str = Field(..., description="åŸå§‹æ–‡æœ¬")


class TitleBlockInfo(BaseModel):
    """æ ‡é¢˜æ ä¿¡æ¯"""
    drawing_number: Optional[str] = None
    part_name: Optional[str] = None
    material: Optional[str] = None
    scale: Optional[str] = None
    weight: Optional[float] = None
    unit: str = "mm"
    version: Optional[str] = None


class OcrResult(BaseModel):
    """OCRç»“æœ"""
    provider: OcrProviderType
    text: str
    blocks: List[OcrBlock] = []
    dimensions: List[DimensionInfo] = []
    symbols: List[SymbolInfo] = []
    title_block: Optional[TitleBlockInfo] = None

    overall_confidence: float
    calibrated_confidence: Optional[float] = None

    # å…ƒæ•°æ®
    cache_hit: bool = False
    processing_time_ms: float = 0.0
    quality_report: Optional[QualityReport] = None
    evidence_chain: List[Dict] = []


class OcrClient(ABC):
    """OCRå®¢æˆ·ç«¯æŠ½è±¡åŸºç±»"""

    @abstractmethod
    async def extract(
        self,
        image: bytes,
        prompt: Optional[str] = None,
        options: Optional[Dict] = None
    ) -> OcrResult:
        """æ‰§è¡ŒOCRæå–"""
        pass

    @abstractmethod
    async def health_check(self) -> bool:
        """å¥åº·æ£€æŸ¥"""
        pass

    @abstractmethod
    async def warmup(self):
        """æ¨¡å‹é¢„çƒ­"""
        pass
```

#### 3.2.2 OCRç®¡ç†å™¨ (manager.py)

```python
"""
OCRç®¡ç†å™¨ - ç­–ç•¥è·¯ç”±ã€è´¨é‡é—¨æ§ã€è¯æ®èåˆ
src/core/ocr/manager.py
"""

import hashlib
from typing import Dict, Optional, List

from src.core.ocr.base import OcrClient, OcrResult, OcrProviderType
from src.core.ocr.providers.paddle import PaddleOcrClient
from src.core.ocr.providers.deepseek_hf import DeepSeekHfClient
from src.core.assembly.confidence_calibrator import ConfidenceCalibrationSystem
from src.utils.cache import cache_result, get_cached_result


class OcrManager:
    """OCRç®¡ç†å™¨ - æ ¸å¿ƒåè°ƒå™¨"""

    def __init__(self):
        # åˆå§‹åŒ–providers
        self.providers: Dict[OcrProviderType, OcrClient] = {
            OcrProviderType.PADDLE: PaddleOcrClient(),
            OcrProviderType.DEEPSEEK_HF: DeepSeekHfClient(),
        }

        # è´¨é‡æ§åˆ¶å™¨
        self.quality_controller = QualityController(...)

        # ç½®ä¿¡åº¦æ ¡å‡† (å¤ç”¨ç°æœ‰)
        self.calibrator = ConfidenceCalibrationSystem(method='isotonic')
        self.calibrator.load_calibrator()

    async def extract(
        self,
        image: bytes,
        strategy: str = "auto",
        prompt: Optional[str] = None,
        idempotency_key: Optional[str] = None
    ) -> OcrResult:
        """
        ç»Ÿä¸€OCRæå–å…¥å£

        æµç¨‹:
        1. ç¼“å­˜æ£€æŸ¥
        2. Provideré€‰æ‹©ä¸æ‰§è¡Œ
        3. è´¨é‡é—¨æ§ä¸fallback
        4. ç½®ä¿¡åº¦æ ¡å‡†
        5. ç¼“å­˜å†™å…¥
        """

        # 1. ç¼“å­˜æ£€æŸ¥
        cache_key = self._generate_cache_key(image, strategy, prompt, idempotency_key)
        cached = await get_cached_result(cache_key)
        if cached:
            return OcrResult(**cached)

        # 2. Provideræ‰§è¡Œ
        if strategy == "auto":
            result = await self._auto_strategy(image, prompt)
        else:
            result = await self._execute_provider(
                OcrProviderType(strategy), image, prompt
            )

        # 3. è´¨é‡é—¨æ§
        result = await self.quality_controller.validate_and_fallback(result, image, self)

        # 4. ç½®ä¿¡åº¦æ ¡å‡†
        result = self._calibrate_confidence(result)

        # 5. ç¼“å­˜å†™å…¥
        await cache_result(cache_key, result.dict(), ttl=86400)

        return result

    async def _auto_strategy(self, image: bytes, prompt: Optional[str] = None) -> OcrResult:
        """
        Autoç­–ç•¥: å…ˆpaddleï¼Œä½ç½®ä¿¡åº¦è§¦å‘deepseek
        """
        # å¿«é€Ÿpaddle
        paddle_result = await self._execute_provider(OcrProviderType.PADDLE, image)

        # åˆ¤æ–­æ˜¯å¦éœ€è¦å¢å¼º
        needs_enhancement = (
            paddle_result.overall_confidence < 0.85 or
            self._missing_critical_content(paddle_result)
        )

        if not needs_enhancement:
            return paddle_result

        # DeepSeekå¢å¼º
        deepseek_result = await self._execute_provider(
            OcrProviderType.DEEPSEEK_HF, image, prompt
        )

        # èåˆç»“æœ (ä½¿ç”¨DSè¯æ®ç†è®º)
        return self._merge_results([paddle_result, deepseek_result])

    def _calibrate_confidence(self, result: OcrResult) -> OcrResult:
        """æ ¡å‡†ç½®ä¿¡åº¦ (å¤ç”¨confidence_calibrator.py)"""
        result.calibrated_confidence = self.calibrator.calibrator.calibrate(
            result.overall_confidence
        )
        return result
```

#### 3.2.3 DeepSeek Provider (deepseek_hf.py)

```python
"""
DeepSeek-HF Provider
src/core/ocr/providers/deepseek_hf.py
"""

import torch
from transformers import AutoModel, AutoTokenizer
from PIL import Image
import io

from src.core.ocr.base import OcrClient, OcrResult
from src.core.ocr.parsing.json_validator import JsonValidator


class DeepSeekHfClient(OcrClient):
    """DeepSeek OCR - Transformerså®ç°"""

    def __init__(self, model_name: str = "deepseek-ai/DeepSeek-OCR", device: str = "cuda"):
        self.model_name = model_name
        self.device = device if torch.cuda.is_available() else "cpu"

        self.model = None
        self.tokenizer = None
        self._model_loaded = False

        # JSONæ ¡éªŒå™¨
        self.json_validator = JsonValidator(max_retries=2)

    async def warmup(self):
        """æ¨¡å‹é¢„çƒ­"""
        if not self._model_loaded:
            await self._load_model()

            # é¢„çƒ­æ¨ç†
            dummy_image = Image.new('RGB', (640, 480), color='white')
            await self._infer(dummy_image, "<image>\n<|grounding|>Free OCR.")

    async def _load_model(self):
        """åŠ è½½æ¨¡å‹"""
        self.tokenizer = AutoTokenizer.from_pretrained(
            self.model_name, trust_remote_code=True
        )

        self.model = AutoModel.from_pretrained(
            self.model_name,
            trust_remote_code=True,
            torch_dtype=torch.float16 if self.device == "cuda" else torch.float32
        ).to(self.device)

        self.model.eval()
        self._model_loaded = True

    async def extract(self, image: bytes, prompt: Optional[str] = None, options: Optional[Dict] = None) -> OcrResult:
        """OCRæå–"""
        if not self._model_loaded:
            await self._load_model()

        # è½¬æ¢å›¾åƒ
        pil_image = Image.open(io.BytesIO(image)).convert('RGB')

        # é€‰æ‹©prompt
        if prompt is None:
            prompt = self._get_engineering_drawing_prompt()

        # æ‰§è¡Œæ¨ç†
        raw_output = await self._infer(pil_image, prompt)

        # ä¸¥æ ¼JSONæ ¡éªŒ
        validated = self.json_validator.validate_and_heal(raw_output)

        if validated:
            return self._build_result_from_validated(validated, pil_image.size)
        else:
            # Fallbackåˆ°æ–‡æœ¬è§£æ
            return await self._parse_text_output(raw_output, pil_image.size)

    def _get_engineering_drawing_prompt(self) -> str:
        """å·¥ç¨‹å›¾ç»“æ„åŒ–prompt"""
        return """<image>
<|grounding|>Extract dimensions/tolerances/surface-roughness/threads as strict JSON:
{
  "dimensions": [{"type":"diameter|radius|length", "value":float, "unit":"mm", "tolerance":float, "bbox":{}}],
  "symbols": [{"type":"surface_roughness|perpendicular", "value":str, "bbox":{}}],
  "title_block": {"drawing_number":str, "material":str, "part_name":str}
}"""

    async def _infer(self, image: Image.Image, prompt: str) -> str:
        """æ‰§è¡Œæ¨¡å‹æ¨ç†"""
        inputs = self.tokenizer(prompt, images=image, return_tensors="pt").to(self.device)

        with torch.no_grad():
            outputs = self.model.generate(**inputs, max_new_tokens=4096, temperature=0.0)

        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)

    async def health_check(self) -> bool:
        """å¥åº·æ£€æŸ¥"""
        try:
            if not self._model_loaded:
                await self._load_model()
            return True
        except:
            return False
```

#### 3.2.4 å°ºå¯¸è§£æå™¨ (dimension_parser.py)

```python
"""
å°ºå¯¸ä¸å…¬å·®è§£æå™¨
src/core/ocr/parsing/dimension_parser.py
"""

import re
from typing import List, Optional
from src.core.ocr.base import DimensionInfo, BBox


class DimensionParser:
    """å·¥ç¨‹å›¾å°ºå¯¸è§£æå™¨"""

    def __init__(self):
        self.patterns = {
            'diameter': r'[Î¦âŒ€âˆ…](\d+\.?\d*)([Â±+\-]\d+\.?\d*)?',
            'radius': r'R(\d+\.?\d*)([Â±+\-]\d+\.?\d*)?',
            'thread': r'M(\d+)(Ã—|x|\*)(\d+\.?\d*)?',
            'length': r'(\d+\.?\d*)([Â±]\d+\.?\d*)',
        }

    def parse_from_text(self, text: str) -> List[DimensionInfo]:
        """ä»æ–‡æœ¬è§£æå°ºå¯¸"""
        dimensions = []

        # è§£æç›´å¾„
        for match in re.finditer(self.patterns['diameter'], text):
            value = float(match.group(1))
            tolerance = self._parse_tolerance(match.group(2)) if match.group(2) else None

            dimensions.append(DimensionInfo(
                type='diameter',
                value=value,
                unit='mm',
                tolerance=tolerance,
                bbox=BBox(x=0, y=0, width=0, height=0),
                confidence=0.85,
                source_text=match.group(0)
            ))

        # è§£æåŠå¾„ã€èºçº¹...
        # (ç±»ä¼¼é€»è¾‘çœç•¥)

        return dimensions

    def _parse_tolerance(self, tol_str: str) -> Optional[float]:
        """è§£æå…¬å·®å€¼"""
        if 'Â±' in tol_str:
            return abs(float(tol_str.replace('Â±', '')))
        return None
```

#### 3.2.5 JSONä¸¥æ ¼æ ¡éªŒ (json_validator.py)

```python
"""
DeepSeek JSONè¾“å‡ºä¸¥æ ¼æ ¡éªŒ
src/core/ocr/parsing/json_validator.py
"""

from pydantic import BaseModel, Field, ValidationError
import json
import re


class StrictDimensionOutput(BaseModel):
    """ä¸¥æ ¼çš„å°ºå¯¸è¾“å‡ºæ¨¡å‹"""
    type: str = Field(..., regex="^(diameter|radius|length|thread)$")
    value: float = Field(..., ge=0, le=10000)
    unit: str = Field(default="mm", regex="^(mm|cm|m|inch)$")
    tolerance: Optional[float] = Field(None, ge=0, le=10)
    bbox: Dict[str, float]
    confidence: float = Field(..., ge=0, le=1)
    source_text: str

    class Config:
        extra = 'forbid'


class JsonValidator:
    """JSONæ ¡éªŒå™¨ + è‡ªæ„ˆé‡è¯•"""

    def __init__(self, max_retries: int = 2):
        self.max_retries = max_retries

    def validate_and_heal(self, raw_json: str, attempt: int = 0) -> Optional[StrictOcrJsonOutput]:
        """
        æ ¡éªŒå¹¶è‡ªæ„ˆJSONè¾“å‡º

        ç­–ç•¥:
        1. JSONè§£æ
        2. Pydanticä¸¥æ ¼æ ¡éªŒ
        3. è‡ªæ„ˆå¸¸è§é”™è¯¯ (å°¾éšé€—å·ã€å•å¼•å·ã€ç¼ºå¤±å­—æ®µ)
        4. æœ€å¤šé‡è¯•2æ¬¡
        """

        try:
            data = json.loads(raw_json)
        except json.JSONDecodeError as e:
            # è‡ªæ„ˆè¯­æ³•é”™è¯¯
            healed_json = self._heal_json_syntax(raw_json)
            if healed_json and attempt < self.max_retries:
                return self.validate_and_heal(healed_json, attempt + 1)
            return None

        try:
            validated = StrictOcrJsonOutput(**data)
            return validated
        except ValidationError as e:
            # è‡ªæ„ˆæ•°æ®ç»“æ„é—®é¢˜
            healed_data = self._heal_data_structure(data, e)
            if healed_data and attempt < self.max_retries:
                try:
                    return StrictOcrJsonOutput(**healed_data)
                except:
                    pass
            return None

    def _heal_json_syntax(self, raw_json: str) -> Optional[str]:
        """ä¿®å¤JSONè¯­æ³•é”™è¯¯"""
        # å¸¸è§é—®é¢˜1: å°¾éšé€—å·
        healed = re.sub(r',\s*}', '}', raw_json)
        healed = re.sub(r',\s*]', ']', healed)

        # å¸¸è§é—®é¢˜2: å•å¼•å·
        healed = healed.replace("'", '"')

        try:
            json.loads(healed)
            return healed
        except:
            return None
```

---

## å››ã€APIå¥‘çº¦

### 4.1 æ•°æ®æ¨¡å‹

```python
"""
OCR APIæ•°æ®æ¨¡å‹
src/models/ocr_models.py
"""

from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any


class OcrExtractRequest(BaseModel):
    """OCRæå–è¯·æ±‚"""
    provider: str = Field(default="auto", description="Provider: auto/paddle/deepseek_hf")
    prompt: Optional[str] = Field(None, description="è‡ªå®šä¹‰prompt (DeepSeek)")
    enable_geometric_alignment: bool = Field(default=False, description="å‡ ä½•å¯¹é½")
    idempotency_key: Optional[str] = Field(None, description="å¹‚ç­‰æ€§Key")


class OcrExtractResponse(BaseModel):
    """OCRæå–å“åº”"""
    request_id: str
    provider: OcrProviderType
    text: str
    dimensions: List[DimensionInfo] = []
    symbols: List[SymbolInfo] = []
    title_block: Optional[TitleBlockInfo] = None

    overall_confidence: float
    calibrated_confidence: Optional[float] = None

    cache_hit: bool = False
    processing_time_ms: float = 0.0
    quality_report: Optional[QualityReport] = None
    evidence_chain: List[Dict[str, Any]] = []
```

### 4.2 APIç«¯ç‚¹

#### 4.2.1 ç›´é€šOCRç«¯ç‚¹

```python
"""
OCRç›´é€šç«¯ç‚¹
src/api/v1/ocr.py
"""

from fastapi import APIRouter, File, UploadFile, Form, Header

router = APIRouter()
ocr_manager = OcrManager()


@router.post("/extract", response_model=OcrExtractResponse)
async def extract_ocr(
    file: UploadFile = File(..., description="å›¾åƒæ–‡ä»¶"),
    provider: str = Form(default="auto"),
    prompt: Optional[str] = Form(None),
    idempotency_key: Optional[str] = Header(None, alias="Idempotency-Key"),
    api_key: str = Depends(get_api_key)
):
    """
    OCRç›´é€šæå–ç«¯ç‚¹

    æ”¯æŒæ ¼å¼: JPG, PNG, PDF (å•é¡µ)

    Providerè¯´æ˜:
    - auto: æ™ºèƒ½é€‰æ‹© (å…ˆpaddleï¼Œä½ç½®ä¿¡åº¦â†’deepseek)
    - paddle: å¿«é€ŸCPU OCR
    - deepseek_hf: é«˜è´¨é‡GPU OCR
    """

    image_data = await file.read()

    result = await ocr_manager.extract(
        image=image_data,
        strategy=provider,
        prompt=prompt,
        idempotency_key=idempotency_key
    )

    return OcrExtractResponse(
        request_id=str(uuid.uuid4()),
        provider=result.provider,
        text=result.text,
        dimensions=result.dimensions,
        symbols=result.symbols,
        title_block=result.title_block,
        overall_confidence=result.overall_confidence,
        calibrated_confidence=result.calibrated_confidence,
        cache_hit=result.cache_hit,
        processing_time_ms=result.processing_time_ms,
        quality_report=result.quality_report,
        evidence_chain=result.evidence_chain
    )


@router.get("/health")
async def ocr_health_check():
    """OCRå¥åº·æ£€æŸ¥"""
    health_status = {"status": "healthy", "providers": {}}

    for provider_name, provider in ocr_manager.providers.items():
        is_healthy = await provider.health_check()
        health_status["providers"][provider_name.value] = {
            "status": "up" if is_healthy else "down"
        }

    return health_status
```

#### 4.2.2 é›†æˆåˆ°analyzeç«¯ç‚¹

```python
"""
æ‰©å±•ç°æœ‰analyzeç«¯ç‚¹
src/api/v1/analyze.py (éƒ¨åˆ†)
"""

class AnalysisOptions(BaseModel):
    # ... åŸæœ‰å­—æ®µ ...

    # OCRå¢å¼º
    enable_ocr: bool = Field(default=False, description="å¯ç”¨OCRå¢å¼º")
    ocr_provider: str = Field(default="auto", description="OCR Provider")


@router.post("/", response_model=AnalysisResult)
async def analyze_cad_file(
    file: UploadFile = File(...),
    options: str = Form(...),
    api_key: str = Depends(get_api_key)
):
    # ... ç°æœ‰é€»è¾‘ ...

    # OCRå¢å¼º
    if analysis_options.enable_ocr:
        ocr_manager = OcrManager()
        ocr_result = await ocr_manager.extract(
            image=content,
            strategy=analysis_options.ocr_provider
        )

        # åˆå¹¶åˆ°åˆ†æç»“æœ
        results['ocr'] = {
            'text': ocr_result.text,
            'dimensions': [d.dict() for d in ocr_result.dimensions],
            'title_block': ocr_result.title_block.dict() if ocr_result.title_block else None,
            'confidence': ocr_result.calibrated_confidence
        }

        # ä½¿ç”¨OCRå¢å¼ºå·¥è‰ºå»ºè®®
        if ocr_result.title_block and ocr_result.title_block.material:
            results['process']['material_specific'] = \
                await get_material_specific_process(ocr_result.title_block.material)

    # ...
```

---

## äº”ã€é…ç½®ç®¡ç†

### 5.1 ç¯å¢ƒé…ç½®çŸ©é˜µ

```python
"""
ç¯å¢ƒé…ç½®
src/config/ocr_config.py
"""

from enum import Enum
from pydantic_settings import BaseSettings


class Environment(str, Enum):
    DEVELOPMENT = "development"
    GPU_WORKSTATION = "gpu_workstation"
    PRODUCTION = "production"


class OcrConfig(BaseSettings):
    """OCRé…ç½®"""

    # ç¯å¢ƒ
    ENVIRONMENT: Environment = Environment.DEVELOPMENT

    # Provideré…ç½®
    OCR_PROVIDER: str = "auto"

    # DeepSeeké…ç½®
    DEEPSEEK_ENABLED: bool = True
    DEEPSEEK_MODEL: str = "deepseek-ai/DeepSeek-OCR"
    DEEPSEEK_DEVICE: str = "cuda"
    DEEPSEEK_MODE: str = "hf"  # hf/vllm

    # è´¨é‡æ§åˆ¶
    CONFIDENCE_THRESHOLD: float = 0.7
    CONFIDENCE_FALLBACK: float = 0.85
    OCR_TIMEOUT_MS: int = 15000

    # å¹¶å‘æ§åˆ¶
    OCR_MAX_CONCURRENT: int = 5
    OCR_QUEUE_SIZE: int = 100

    # ç¼“å­˜
    OCR_CACHE_ENABLED: bool = True
    OCR_CACHE_TTL: int = 86400  # 24h

    # ç°åº¦å‘å¸ƒ
    ENABLE_GRADUAL_ROLLOUT: bool = False
    DEEPSEEK_ROLLOUT_PERCENTAGE: int = 0

    class Config:
        env_file = ".env"
```

### 5.2 ç¯å¢ƒé…ç½®æ–‡ä»¶

```bash
# .env.development (å¼€å‘ç¯å¢ƒ - CPU)
ENVIRONMENT=development
OCR_PROVIDER=auto
DEEPSEEK_ENABLED=false
PADDLE_ENABLED=true
PADDLE_USE_GPU=false
CONFIDENCE_FALLBACK=0.85
OCR_TIMEOUT_MS=10000
LOG_LEVEL=DEBUG

# .env.gpu_workstation (GPUå·¥ä½œç«™)
ENVIRONMENT=gpu_workstation
OCR_PROVIDER=deepseek_hf
DEEPSEEK_ENABLED=true
DEEPSEEK_DEVICE=cuda
PADDLE_USE_GPU=true
CONFIDENCE_FALLBACK=0.80
OCR_MAX_CONCURRENT=8

# .env.production (ç”Ÿäº§ç¯å¢ƒ)
ENVIRONMENT=production
OCR_PROVIDER=auto
DEEPSEEK_ENABLED=true
DEEPSEEK_DEVICE=cuda
DEEPSEEK_MODE=vllm

CONFIDENCE_FALLBACK=0.85
OCR_MAX_CONCURRENT=10
FALLBACK_ON_ERROR=true

ENABLE_GRADUAL_ROLLOUT=true
DEEPSEEK_ROLLOUT_PERCENTAGE=20

ENABLE_METRICS=true
```

---

## å…­ã€å®æ–½è·¯çº¿

### Week 1: æ ¸å¿ƒèƒ½åŠ› (MVP)

| æ—¥æœŸ | ä»»åŠ¡ | äº¤ä»˜ç‰© | éªŒæ”¶æ ‡å‡† |
|------|------|--------|----------|
| **Day 1-2** | åŸºç¡€æ¡†æ¶ | - base.pyæŠ½è±¡<br>- OcrManager<br>- DeepSeek-HF Provider<br>- Paddle Provider<br>- /ocr/extractç«¯ç‚¹ | - APIå¯åŠ¨æˆåŠŸ<br>- 3ä¸ªæ ·æœ¬æµ‹è¯•é€šè¿‡<br>- å¥åº·æ£€æŸ¥æ­£å¸¸ |
| **Day 3** | ç»“æ„åŒ–è§£æ | - DimensionParser<br>- SymbolParser<br>- Normalizer<br>- Promptä¼˜åŒ– | - JSONè§£ææˆåŠŸç‡>80%<br>- å…³é”®å­—æ®µå¬å›>70% |
| **Day 4** | è¯æ®é“¾ | - å¤ç”¨calibrator<br>- Evidenceé›†æˆ<br>- DSèåˆ | - Brier score <0.15<br>- è¯æ®é“¾å®Œæ•´ |
| **Day 5** | é›†æˆ/analyze | - æ‰©å±•AnalysisOptions<br>- OCRâ†’ææ–™/å·¥è‰º<br>- APIæ–‡æ¡£ | - ç«¯åˆ°ç«¯æµ‹è¯•é€šè¿‡<br>- å“åº”æ—¶é—´å¢é‡<30% |

### Week 2: æ™ºèƒ½è·¯ç”± + è´¨é‡æ§åˆ¶

| æ—¥æœŸ | ä»»åŠ¡ | äº¤ä»˜ç‰© | éªŒæ”¶æ ‡å‡† |
|------|------|--------|----------|
| **Day 1-2** | Autoç­–ç•¥ | - Fallbacké€»è¾‘<br>- å¤šproviderèåˆ<br>- ç¼“å­˜ä¼˜åŒ– | - Fallbackè§¦å‘ç‡<20%<br>- èåˆåF1æå‡>10% |
| **Day 3** | è´¨é‡é—¨æ§ | - QualityGate<br>- é‡è¯•æ§åˆ¶<br>- è¶…æ—¶å¤„ç† | - å…³é”®å­—æ®µå®Œæ•´æ€§>90%<br>- è¶…æ—¶å›é€€æ­£å¸¸ |
| **Day 4-5** | è¯„æµ‹ä½“ç³» | - 10ä¸ªgolden cases<br>- CIé›†æˆ<br>- æŒ‡æ ‡è®¡ç®— | - Edge F1â‰¥0.75<br>- å¬å›â‰¥0.80<br>- P95å»¶è¿Ÿ<5s |

### Week 3-4: é«˜çº§ç‰¹æ€§ (æŒ‰éœ€)

- **Week 3**: å‡ ä½•å¯¹é½ (å¯¹é½æˆåŠŸç‡>60%)
- **Week 4**: ç›‘æ§å®Œå–„ (Grafanaé¢æ¿ã€ç°åº¦å‘å¸ƒ)

---

## ä¸ƒã€ç›‘æ§ä¸è¯„æµ‹

### 7.1 PrometheusæŒ‡æ ‡

```python
"""
OCR PrometheusæŒ‡æ ‡
src/core/ocr/utils/metrics.py
"""

from prometheus_client import Counter, Histogram, Gauge

# è¯·æ±‚è®¡æ•°
ocr_requests_total = Counter(
    'ocr_requests_total',
    'Total OCR requests',
    ['provider', 'status']
)

# å­—æ®µå¬å›ç‡
ocr_field_recall = Gauge(
    'ocr_field_recall',
    'Critical field recall rate',
    ['field_type']  # dimension/tolerance/title_block
)

# ç½®ä¿¡åº¦åˆ†å¸ƒ
ocr_confidence_score = Histogram(
    'ocr_confidence_score',
    'Calibrated confidence distribution',
    buckets=[0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99]
)

# Fallbackè§¦å‘
ocr_fallback_triggered = Counter(
    'ocr_fallback_triggered',
    'Fallback to secondary provider',
    ['reason']  # low_confidence/missing_field/parse_error
)

# å¤„ç†æ—¶å»¶
ocr_processing_time = Histogram(
    'ocr_processing_time_seconds',
    'OCR processing latency',
    ['provider'],
    buckets=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0]
)
```

### 7.2 è¯„æµ‹æ•°æ®é›†

```python
"""
OCRè¯„æµ‹æ•°æ®é›†
tests/ocr/golden_cases.py
"""

GOLDEN_CASES = [
    {
        "name": "clear_vector_drawing",
        "description": "æ¸…æ™°çŸ¢é‡å›¾",
        "image_path": "test_data/clear_vector.png",
        "ground_truth": {
            "dimensions": [
                {"type": "diameter", "value": 20.0, "tolerance": 0.02},
                {"type": "radius", "value": 5.0},
            ],
            "title_block": {
                "drawing_number": "GJ-2024-001",
                "material": "20CrMnTi",
            }
        },
        "min_confidence": 0.90
    },
    {
        "name": "scanned_drawing",
        "description": "æ‰«æå›¾çº¸",
        "min_confidence": 0.75
    },
    {
        "name": "blurry_photo",
        "description": "æ¨¡ç³Šç…§ç‰‡",
        "min_confidence": 0.60
    },
    # ... æ›´å¤šç”¨ä¾‹
]
```

### 7.3 CIé›†æˆ

```yaml
# .github/workflows/ocr_tests.yml
name: OCR Quality Tests

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  ocr-evaluation:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: 3.9

    - name: Install dependencies
      run: pip install -r requirements.txt

    - name: Run golden set evaluation
      run: python tests/ocr/run_golden_evaluation.py

    - name: Check quality gates
      run: |
        python scripts/check_ocr_metrics.py \
          --min-edge-f1 0.75 \
          --min-field-recall 0.80 \
          --max-p95-latency 5000
```

---

## å…«ã€ç”Ÿäº§éƒ¨ç½²

### 8.1 Docker Compose

```yaml
# docker-compose.ocr.yml
version: '3.8'

services:
  cad-ml-platform:
    build: .
    environment:
      - ENVIRONMENT=production
      - OCR_PROVIDER=auto
      - DEEPSEEK_ENABLED=true
      - DEEPSEEK_DEVICE=cuda
      - REDIS_URL=redis://redis:6379
    volumes:
      - ./models:/models
    ports:
      - "8000:8000"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    depends_on:
      - redis

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
```

### 8.2 å¥åº·æ£€æŸ¥ä¸é¢„çƒ­

```python
"""
FastAPI lifespané›†æˆ
src/main.py (æ›´æ–°)
"""

@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""

    # å¯åŠ¨é˜¶æ®µ
    logger.info("ğŸš€ Starting CAD ML Platform...")

    # 1. åˆå§‹åŒ–Redis
    await init_redis()

    # 2. åŠ è½½MLæ¨¡å‹
    await load_models()

    # 3. åˆå§‹åŒ–OCR
    app.state.ocr_manager = OcrManager()

    # 4. OCRé¢„çƒ­
    for provider_name, provider in app.state.ocr_manager.providers.items():
        logger.info(f"ğŸ”¥ Warming up {provider_name.value}...")
        await provider.warmup()
        logger.info(f"âœ… {provider_name.value} ready")

    # 5. è®­ç»ƒæ ¡å‡†å™¨
    if not app.state.ocr_manager.calibrator.calibrator.fitted:
        app.state.ocr_manager._train_calibrator_from_golden_set(
            app.state.ocr_manager.calibrator
        )

    logger.info("âœ… CAD ML Platform started")

    yield

    # å…³é—­é˜¶æ®µ
    logger.info("ğŸ›‘ Shutting down...")


# å¢å¼ºå¥åº·æ£€æŸ¥
@app.get("/health")
async def health_check(request: Request):
    """ç»¼åˆå¥åº·æ£€æŸ¥"""
    health_status = {
        "status": "healthy",
        "services": {
            "api": "up",
            "redis": await _check_redis(),
            "ml": await _check_ml_models()
        }
    }

    # OCRå¥åº·æ£€æŸ¥
    if hasattr(request.app.state, 'ocr_manager'):
        ocr_manager = request.app.state.ocr_manager
        ocr_health = {"overall": "unknown", "providers": {}}

        for provider_name, provider in ocr_manager.providers.items():
            is_healthy = await provider.health_check()
            is_circuit_broken = ocr_manager.executor.fallback_strategy.should_skip_provider(
                provider_name.value
            )

            ocr_health["providers"][provider_name.value] = {
                "status": "up" if is_healthy else "down",
                "ready": is_healthy and not is_circuit_broken,
                "circuit_broken": is_circuit_broken
            }

        any_ready = any(p["ready"] for p in ocr_health["providers"].values())
        ocr_health["overall"] = "up" if any_ready else "degraded"

        health_status["services"]["ocr"] = ocr_health

    return health_status
```

### 8.3 å¿«é€Ÿå¯åŠ¨è„šæœ¬

```bash
#!/bin/bash
# scripts/quick_start_ocr.sh

set -e

echo "ğŸš€ CAD ML Platform OCR Quick Start"

# ç¯å¢ƒæ£€æµ‹
if command -v nvidia-smi &> /dev/null; then
    echo "âœ… GPU detected"
    ENV="gpu_workstation"
else
    echo "âš ï¸  CPU mode"
    ENV="development"
fi

# é…ç½®ç¯å¢ƒ
cp .env.example .env.$ENV
export ENVIRONMENT=$ENV

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

if [ "$ENV" = "gpu_workstation" ]; then
    pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
fi

# ä¸‹è½½æ¨¡å‹
if [ ! -d "models/deepseek-ocr" ]; then
    python scripts/download_models.py --model deepseek-ocr
fi

# é¢„çƒ­æµ‹è¯•
python scripts/test_ocr_warmup.py

# å¯åŠ¨æœåŠ¡
if [ "$ENV" = "development" ]; then
    python src/main.py
else
    gunicorn src.main:app --workers 4 --worker-class uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000
fi
```

### 8.4 Kubernetesç”Ÿäº§éƒ¨ç½²

```yaml
# k8s/ocr-deployment.yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: cad-ml-ocr
  namespace: production
  labels:
    app: cad-ml-platform
    component: ocr
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0  # é›¶åœæœºéƒ¨ç½²
  selector:
    matchLabels:
      app: cad-ml-platform
      component: ocr
  template:
    metadata:
      labels:
        app: cad-ml-platform
        component: ocr
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8000"
        prometheus.io/path: "/metrics"
    spec:
      nodeSelector:
        gpu: "nvidia-t4"  # GPUèŠ‚ç‚¹é€‰æ‹©
      containers:
      - name: ocr-service
        image: your-registry/cad-ml-platform:ocr-v1.0.0
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 8000
          name: http
          protocol: TCP
        env:
        - name: ENVIRONMENT
          value: "production"
        - name: DEEPSEEK_DEVICE
          value: "cuda"
        - name: OCR_MAX_CONCURRENT
          value: "10"
        - name: REDIS_URL
          valueFrom:
            secretKeyRef:
              name: cad-ml-secrets
              key: redis-url
        resources:
          requests:
            memory: "4Gi"
            cpu: "2000m"
            nvidia.com/gpu: 1
          limits:
            memory: "8Gi"
            cpu: "4000m"
            nvidia.com/gpu: 1
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 120  # æ¨¡å‹åŠ è½½éœ€è¦æ—¶é—´
          periodSeconds: 30
          timeoutSeconds: 5
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 60
          periodSeconds: 10
          timeoutSeconds: 3
          failureThreshold: 2
        volumeMounts:
        - name: model-cache
          mountPath: /app/models
        - name: config
          mountPath: /app/config
          readOnly: true
      volumes:
      - name: model-cache
        persistentVolumeClaim:
          claimName: ocr-model-pvc
      - name: config
        configMap:
          name: ocr-config
      initContainers:
      - name: model-downloader
        image: your-registry/model-downloader:latest
        command: ['sh', '-c', 'python /scripts/download_models.py']
        volumeMounts:
        - name: model-cache
          mountPath: /app/models
---
apiVersion: v1
kind: Service
metadata:
  name: cad-ml-ocr-service
  namespace: production
spec:
  type: ClusterIP
  selector:
    app: cad-ml-platform
    component: ocr
  ports:
  - port: 80
    targetPort: 8000
    protocol: TCP
    name: http
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: cad-ml-ocr-hpa
  namespace: production
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: cad-ml-ocr
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Pods
    pods:
      metric:
        name: ocr_requests_per_second
      target:
        type: AverageValue
        averageValue: "50"
```

### 8.5 è´Ÿè½½å‡è¡¡ä¸æ‰©ç¼©å®¹ç­–ç•¥

**è´Ÿè½½å‡è¡¡é…ç½®** (Nginx Ingress):

```yaml
# k8s/ingress.yaml

apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: cad-ml-ocr-ingress
  namespace: production
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/proxy-body-size: "50m"  # OCRå›¾ç‰‡ä¸Šä¼ 
    nginx.ingress.kubernetes.io/proxy-read-timeout: "30"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "30"
    nginx.ingress.kubernetes.io/rate-limit: "100"  # é™æµ
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
spec:
  tls:
  - hosts:
    - api.cad-ml.yourcompany.com
    secretName: cad-ml-tls
  rules:
  - host: api.cad-ml.yourcompany.com
    http:
      paths:
      - path: /api/v1/ocr
        pathType: Prefix
        backend:
          service:
            name: cad-ml-ocr-service
            port:
              number: 80
```

**æ‰©ç¼©å®¹ç­–ç•¥å†³ç­–æ ‘**:

```yaml
scaling_strategy:
  # åœºæ™¯1: æ—¥å¸¸è´Ÿè½½ (å·¥ä½œæ—¥ 9:00-18:00)
  business_hours:
    min_replicas: 3
    max_replicas: 6
    target_cpu: 70%
    target_qps: 50

  # åœºæ™¯2: é«˜å³°æœŸ (æœˆæœ«å‡ºå›¾é«˜å³°)
  peak_hours:
    min_replicas: 6
    max_replicas: 10
    target_cpu: 60%
    target_qps: 100

  # åœºæ™¯3: ä½è°·æœŸ (å¤œé—´/å‘¨æœ«)
  off_hours:
    min_replicas: 1
    max_replicas: 3
    target_cpu: 80%

  # è‡ªåŠ¨ç­–ç•¥: åŸºäºCronHPA
  scheduled_scaling:
    - schedule: "0 8 * * 1-5"  # å·¥ä½œæ—¥æ—©8ç‚¹
      replicas: 3
    - schedule: "0 18 * * 1-5"  # å·¥ä½œæ—¥æ™š6ç‚¹
      replicas: 1
    - schedule: "0 8 25-31 * *"  # æœˆæœ«æ—©8ç‚¹
      replicas: 6
```

### 8.6 å¤‡ä»½ä¸ç¾éš¾æ¢å¤

**å…³é”®æ•°æ®å¤‡ä»½**:

```bash
#!/bin/bash
# scripts/backup_ocr_data.sh

# 1. Redisç¼“å­˜å¿«ç…§ (å¯é€‰,ç¼“å­˜æ•°æ®å¯é‡å»º)
redis-cli --rdb /backup/redis/ocr_cache_$(date +%Y%m%d).rdb

# 2. ç½®ä¿¡åº¦æ ¡å‡†æ¨¡å‹ (å…³é”®)
cp models/calibration/*.pkl /backup/models/$(date +%Y%m%d)/

# 3. Goldenæµ‹è¯•é›† (å…³é”®)
tar -czf /backup/golden_sets/golden_$(date +%Y%m%d).tar.gz tests/ocr/golden_cases/

# 4. é…ç½®æ–‡ä»¶
cp -r config/ /backup/config/$(date +%Y%m%d)/

# 5. PrometheusæŒ‡æ ‡å†å² (å¯é€‰)
curl -X POST http://prometheus:9090/api/v1/admin/tsdb/snapshot > /backup/metrics/snapshot_$(date +%Y%m%d).json

echo "âœ… Backup completed: $(date)"
```

**ç¾éš¾æ¢å¤è®¡åˆ’ (RTO/RPO)**:

| æ•…éšœåœºæ™¯ | RTOç›®æ ‡ | RPOç›®æ ‡ | æ¢å¤æ­¥éª¤ |
|---------|---------|---------|---------|
| **å•Podæ•…éšœ** | <1åˆ†é’Ÿ | 0 (æ— æŸ) | K8sè‡ªåŠ¨é‡å¯,æ— éœ€å¹²é¢„ |
| **èŠ‚ç‚¹æ•…éšœ** | <5åˆ†é’Ÿ | 0 | K8sè°ƒåº¦åˆ°å…¶ä»–èŠ‚ç‚¹ |
| **Redisæ•…éšœ** | <10åˆ†é’Ÿ | <1å°æ—¶ | åˆ‡æ¢åˆ°å¤‡ç”¨Rediså®ä¾‹ |
| **æ¨¡å‹æŸå** | <30åˆ†é’Ÿ | 0 | ä»å¤‡ä»½æ¢å¤calibrationæ¨¡å‹ |
| **æ•´ä¸ªé›†ç¾¤æ•…éšœ** | <2å°æ—¶ | <4å°æ—¶ | DRé›†ç¾¤æ¿€æ´»+æ•°æ®æ¢å¤ |
| **æ•°æ®ä¸­å¿ƒæ•…éšœ** | <4å°æ—¶ | <12å°æ—¶ | å¼‚åœ°å®¹ç¾ä¸­å¿ƒæ¥ç®¡ |

**æ¢å¤æ¼”ç»ƒè„šæœ¬**:

```bash
#!/bin/bash
# scripts/disaster_recovery_drill.sh

echo "ğŸ”¥ å¼€å§‹ç¾éš¾æ¢å¤æ¼”ç»ƒ..."

# 1. æ¨¡æ‹Ÿæ•…éšœ
kubectl delete deployment cad-ml-ocr -n production

# 2. å¯åŠ¨è®¡æ—¶
start_time=$(date +%s)

# 3. æ‰§è¡Œæ¢å¤
kubectl apply -f k8s/ocr-deployment.yaml

# 4. ç­‰å¾…å¥åº·
kubectl wait --for=condition=ready pod -l app=cad-ml-platform -n production --timeout=300s

# 5. éªŒè¯åŠŸèƒ½
curl -f http://api.cad-ml.yourcompany.com/health || exit 1

# 6. è®¡ç®—RTO
end_time=$(date +%s)
rto=$((end_time - start_time))

echo "âœ… æ¢å¤å®Œæˆ! RTOå®é™…: ${rto}ç§’ (ç›®æ ‡: <600ç§’)"

if [ $rto -gt 600 ]; then
    echo "âŒ RTOè¶…æ ‡,éœ€ä¼˜åŒ–!"
    exit 1
fi
```

### 8.7 å®‰å…¨åŠ å›º

**Secretsç®¡ç†** (ä½¿ç”¨Kubernetes Secrets + Sealed Secrets):

```yaml
# k8s/sealed-secrets.yaml (åŠ å¯†åå¯å®‰å…¨æäº¤Git)

apiVersion: bitnami.com/v1alpha1
kind: SealedSecret
metadata:
  name: cad-ml-secrets
  namespace: production
spec:
  encryptedData:
    redis-url: AgBXYZ...  # åŠ å¯†çš„Redisè¿æ¥ä¸²
    deepseek-api-key: AgBABC...  # å¦‚ä½¿ç”¨APIæ¨¡å¼
    prometheus-token: AgBDEF...
```

**APIå¯†é’¥è½®è½¬**:

```python
"""
API Keyè½®è½¬ç­–ç•¥
src/core/security/key_rotation.py
"""

import hashlib
from datetime import datetime, timedelta

class ApiKeyRotation:
    """APIå¯†é’¥è‡ªåŠ¨è½®è½¬"""

    def __init__(self, rotation_days: int = 90):
        self.rotation_days = rotation_days

    async def should_rotate(self, key_created_at: datetime) -> bool:
        """æ£€æŸ¥æ˜¯å¦éœ€è¦è½®è½¬"""
        age = datetime.utcnow() - key_created_at
        return age > timedelta(days=self.rotation_days)

    async def rotate_key(self, old_key: str) -> tuple[str, str]:
        """è½®è½¬å¯†é’¥,è¿”å›(new_key, old_key_hash)"""
        new_key = self._generate_key()
        old_hash = hashlib.sha256(old_key.encode()).hexdigest()

        # å®½é™æœŸ: æ–°æ—§keyéƒ½æœ‰æ•ˆ24å°æ—¶
        await self._set_dual_mode(new_key, old_hash, grace_hours=24)

        return new_key, old_hash
```

**è®¿é—®æ§åˆ¶** (RBAC):

```python
"""
åŸºäºè§’è‰²çš„è®¿é—®æ§åˆ¶
src/middleware/rbac.py
"""

from enum import Enum
from fastapi import HTTPException, Header

class UserRole(str, Enum):
    ADMIN = "admin"
    ENGINEER = "engineer"
    VIEWER = "viewer"

class PermissionMatrix:
    """æƒé™çŸ©é˜µ"""

    PERMISSIONS = {
        UserRole.ADMIN: {
            "/api/v1/ocr/extract",
            "/api/v1/ocr/batch",
            "/api/v1/admin/*"
        },
        UserRole.ENGINEER: {
            "/api/v1/ocr/extract",
            "/api/v1/ocr/batch"
        },
        UserRole.VIEWER: {
            "/api/v1/ocr/extract"  # ä»…å•æ¬¡æŸ¥è¯¢
        }
    }

async def check_permission(
    endpoint: str,
    x_user_role: str = Header(..., alias="X-User-Role")
):
    """æƒé™æ£€æŸ¥ä¸­é—´ä»¶"""
    role = UserRole(x_user_role)
    allowed = PermissionMatrix.PERMISSIONS.get(role, set())

    if not any(endpoint.startswith(p.rstrip('*')) for p in allowed):
        raise HTTPException(status_code=403, detail="Insufficient permissions")
```

### 8.8 æ€§èƒ½è°ƒä¼˜æŒ‡å—

**GPUä¼˜åŒ–é…ç½®**:

```python
"""
GPUæ¨ç†ä¼˜åŒ–
src/core/ocr/providers/deepseek_hf.py (ä¼˜åŒ–ç‰ˆ)
"""

import torch
from transformers import AutoModelForCausalLM

class OptimizedDeepSeekClient:
    """æ€§èƒ½ä¼˜åŒ–ç‰ˆDeepSeekå®¢æˆ·ç«¯"""

    def __init__(self):
        # 1. æ··åˆç²¾åº¦æ¨ç† (FP16)
        self.model = AutoModelForCausalLM.from_pretrained(
            "deepseek-ai/deepseek-vl2-tiny",
            torch_dtype=torch.float16,  # èŠ‚çœ50%æ˜¾å­˜
            device_map="auto"
        )

        # 2. ç¼–è¯‘æ¨¡å‹ (PyTorch 2.0+)
        self.model = torch.compile(self.model, mode="reduce-overhead")

        # 3. KVç¼“å­˜ä¼˜åŒ–
        self.model.config.use_cache = True

        # 4. Flash Attention (éœ€æ”¯æŒ)
        if hasattr(self.model.config, 'attn_implementation'):
            self.model.config.attn_implementation = "flash_attention_2"

    async def batch_infer(self, images: list[bytes]) -> list[OcrResult]:
        """æ‰¹é‡æ¨ç† (æå‡åå)"""
        # Dynamic batching: æ”¶é›†50mså†…è¯·æ±‚
        batch = await self._collect_batch(images, timeout_ms=50)

        with torch.no_grad(), torch.cuda.amp.autocast():  # è‡ªåŠ¨æ··åˆç²¾åº¦
            outputs = self.model.generate(
                batch,
                max_new_tokens=512,
                num_beams=1,  # Greedyè§£ç æ›´å¿«
                do_sample=False
            )

        return [self._parse(o) for o in outputs]
```

**ç¼“å­˜ç­–ç•¥ä¼˜åŒ–**:

```python
"""
å¤šçº§ç¼“å­˜
src/core/ocr/cache/multi_tier.py
"""

from functools import lru_cache
import hashlib

class MultiTierCache:
    """ä¸‰çº§ç¼“å­˜: å†…å­˜ â†’ Redis â†’ S3"""

    def __init__(self):
        self.l1_cache = {}  # å†…å­˜LRU (100æ¡)
        self.redis_client = Redis()  # L2 (10Kæ¡, 1å°æ—¶TTL)
        self.s3_client = S3Client()  # L3 (æ°¸ä¹…å½’æ¡£)

    async def get(self, image_hash: str) -> Optional[OcrResult]:
        """ç¼“å­˜æŸ¥è¯¢"""
        # L1: å†…å­˜
        if result := self.l1_cache.get(image_hash):
            metrics.cache_hit.labels(tier="l1").inc()
            return result

        # L2: Redis
        if cached := await self.redis_client.get(f"ocr:{image_hash}"):
            result = OcrResult.parse_raw(cached)
            self.l1_cache[image_hash] = result  # å›å¡«L1
            metrics.cache_hit.labels(tier="l2").inc()
            return result

        # L3: S3 (ä½é¢‘è®¿é—®)
        if archived := await self.s3_client.get(f"ocr-archive/{image_hash}.json"):
            result = OcrResult.parse_raw(archived)
            await self.redis_client.setex(f"ocr:{image_hash}", 3600, result.json())
            metrics.cache_hit.labels(tier="l3").inc()
            return result

        metrics.cache_miss.inc()
        return None
```

**æ•°æ®åº“è¿æ¥æ± è°ƒä¼˜**:

```python
"""
Redisè¿æ¥æ± ä¼˜åŒ–
src/core/database/redis_pool.py
"""

from redis.asyncio import ConnectionPool, Redis

def create_optimized_pool():
    """ä¼˜åŒ–çš„Redisè¿æ¥æ± """
    return ConnectionPool(
        host="redis.production.svc.cluster.local",
        port=6379,
        db=0,

        # è¿æ¥æ± å¤§å° = å¹¶å‘æ•° * 1.2
        max_connections=12,  # 10å¹¶å‘ * 1.2

        # å¥åº·æ£€æŸ¥
        health_check_interval=30,

        # è¶…æ—¶æ§åˆ¶
        socket_connect_timeout=5,
        socket_timeout=3,

        # é‡è¯•ç­–ç•¥
        retry_on_timeout=True,
        retry=Retry(ExponentialBackoff(), 3)
    )
```

### 8.9 ç›‘æ§å‘Šè­¦é…ç½®

**Prometheuså‘Šè­¦è§„åˆ™**:

```yaml
# k8s/prometheus-alerts.yaml

apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: ocr-alerts
  namespace: production
spec:
  groups:
  - name: ocr.errors
    interval: 30s
    rules:
    - alert: OcrHighErrorRate
      expr: |
        rate(ocr_requests_total{status="error"}[5m])
        / rate(ocr_requests_total[5m]) > 0.05
      for: 2m
      labels:
        severity: warning
        component: ocr
      annotations:
        summary: "OCRé”™è¯¯ç‡è¿‡é«˜"
        description: "é”™è¯¯ç‡{{ $value | humanizePercentage }}, è¶…è¿‡5%é˜ˆå€¼"

    - alert: OcrP95LatencyHigh
      expr: |
        histogram_quantile(0.95,
          rate(ocr_processing_duration_seconds_bucket[5m])
        ) > 5
      for: 3m
      labels:
        severity: warning
      annotations:
        summary: "OCR P95å»¶è¿Ÿè¿‡é«˜"
        description: "P95å»¶è¿Ÿ{{ $value }}ç§’, è¶…è¿‡5ç§’SLA"

    - alert: DeepSeekProviderDown
      expr: |
        ocr_provider_health{provider="deepseek_hf"} == 0
      for: 1m
      labels:
        severity: critical
      annotations:
        summary: "DeepSeekæœåŠ¡å¼‚å¸¸"
        description: "DeepSeek providerå¥åº·æ£€æŸ¥å¤±è´¥"

    - alert: OcrCacheMissRateHigh
      expr: |
        rate(ocr_cache_miss_total[10m])
        / rate(ocr_cache_requests_total[10m]) > 0.8
      for: 5m
      labels:
        severity: info
      annotations:
        summary: "ç¼“å­˜å‘½ä¸­ç‡ä½"
        description: "ç¼“å­˜æœªå‘½ä¸­ç‡{{ $value | humanizePercentage }}"

  - name: ocr.capacity
    interval: 1m
    rules:
    - alert: OcrConcurrencyNearLimit
      expr: |
        ocr_concurrent_requests > 8
      for: 2m
      labels:
        severity: warning
      annotations:
        summary: "å¹¶å‘æ•°æ¥è¿‘ä¸Šé™"
        description: "å½“å‰å¹¶å‘{{ $value }}, ä¸Šé™10"

    - alert: GpuMemoryHigh
      expr: |
        nvidia_gpu_memory_used_bytes
        / nvidia_gpu_memory_total_bytes > 0.85
      for: 3m
      labels:
        severity: warning
      annotations:
        summary: "GPUæ˜¾å­˜ä½¿ç”¨ç‡é«˜"
        description: "GPUæ˜¾å­˜ä½¿ç”¨{{ $value | humanizePercentage }}"
```

**Grafanaä»ªè¡¨ç›˜JSON** (å…³é”®é¢æ¿):

```json
{
  "dashboard": {
    "title": "CAD ML OCRç›‘æ§",
    "panels": [
      {
        "title": "QPS & é”™è¯¯ç‡",
        "targets": [
          {
            "expr": "rate(ocr_requests_total[1m])",
            "legendFormat": "QPS"
          },
          {
            "expr": "rate(ocr_requests_total{status='error'}[1m])",
            "legendFormat": "é”™è¯¯QPS"
          }
        ]
      },
      {
        "title": "å»¶è¿Ÿåˆ†ä½æ•°",
        "targets": [
          {
            "expr": "histogram_quantile(0.50, rate(ocr_processing_duration_seconds_bucket[5m]))",
            "legendFormat": "P50"
          },
          {
            "expr": "histogram_quantile(0.95, rate(ocr_processing_duration_seconds_bucket[5m]))",
            "legendFormat": "P95"
          },
          {
            "expr": "histogram_quantile(0.99, rate(ocr_processing_duration_seconds_bucket[5m]))",
            "legendFormat": "P99"
          }
        ]
      },
      {
        "title": "Providerå¥åº·åº¦",
        "targets": [
          {
            "expr": "ocr_provider_health",
            "legendFormat": "{{provider}}"
          }
        ],
        "type": "stat",
        "fieldConfig": {
          "thresholds": {
            "steps": [
              {"value": 0, "color": "red"},
              {"value": 1, "color": "green"}
            ]
          }
        }
      },
      {
        "title": "ç¼“å­˜å‘½ä¸­ç‡",
        "targets": [
          {
            "expr": "rate(ocr_cache_hit_total[5m]) / rate(ocr_cache_requests_total[5m])",
            "legendFormat": "å‘½ä¸­ç‡"
          }
        ]
      }
    ]
  }
}
```

### 8.10 æˆæœ¬ä¼˜åŒ–ç­–ç•¥

**GPUå®ä¾‹æˆæœ¬ä¼˜åŒ–**:

```yaml
cost_optimization_playbook:

  # ç­–ç•¥1: Spotå®ä¾‹ (èŠ‚çœ70%æˆæœ¬)
  spot_instances:
    enabled: true
    interruption_handling: graceful_shutdown
    fallback: on_demand_instances
    saving: ~70%

  # ç­–ç•¥2: æ··åˆå®ä¾‹ç»„
  instance_mix:
    on_demand: 1  # æ ¸å¿ƒèŠ‚ç‚¹
    spot: 2       # å¼¹æ€§èŠ‚ç‚¹
    saving: ~50%

  # ç­–ç•¥3: æŒ‰éœ€Auto Scaling
  autoscaling:
    scale_down_delay: 5m  # å¿«é€Ÿç¼©å®¹
    scale_up_threshold: cpu>60% OR qps>80
    saving: ~40%

  # ç­–ç•¥4: DeepSeekç°åº¦ç­–ç•¥
  deepseek_rollout:
    strategy: confidence_based  # ä»…ä½ç½®ä¿¡åº¦è§¦å‘
    percentage: 20%  # ä»…20%è¯·æ±‚ä½¿ç”¨GPU
    saving: ~80% GPU hours

  # ç­–ç•¥5: ç¼“å­˜å»¶é•¿TTL
  cache_optimization:
    redis_ttl: 24h  # ä»1hå»¶é•¿åˆ°24h
    hit_rate_gain: +30%
    cost_reduction: -30% API calls
```

**æˆæœ¬ç›‘æ§ä»ªè¡¨ç›˜**:

```python
"""
æˆæœ¬è·Ÿè¸ª
src/observability/cost_tracker.py
"""

from prometheus_client import Counter, Gauge

# æˆæœ¬æŒ‡æ ‡
cost_metrics = {
    "gpu_hours": Gauge("cost_gpu_hours_total", "GPUä½¿ç”¨å°æ—¶æ•°"),
    "api_calls": Counter("cost_api_calls_total", "APIè°ƒç”¨æ¬¡æ•°", ["provider"]),
    "storage_gb": Gauge("cost_storage_gb", "å­˜å‚¨ä½¿ç”¨é‡GB"),
    "network_gb": Counter("cost_network_gb_total", "ç½‘ç»œä¼ è¾“GB")
}

class CostCalculator:
    """æˆæœ¬è®¡ç®—å™¨"""

    PRICING = {
        "gpu_t4_hour": 0.35,  # USD/hour
        "deepseek_api_call": 0.001,  # USD/call (å¦‚ä½¿ç”¨API)
        "redis_gb_month": 0.10,
        "bandwidth_gb": 0.02
    }

    async def calculate_daily_cost(self) -> float:
        """è®¡ç®—æ¯æ—¥æˆæœ¬"""
        gpu_cost = cost_metrics["gpu_hours"].get() * self.PRICING["gpu_t4_hour"]
        api_cost = cost_metrics["api_calls"].labels(provider="deepseek").get() * self.PRICING["deepseek_api_call"]
        storage_cost = cost_metrics["storage_gb"].get() * self.PRICING["redis_gb_month"] / 30
        network_cost = cost_metrics["network_gb"].get() * self.PRICING["bandwidth_gb"]

        total = gpu_cost + api_cost + storage_cost + network_cost

        return total
```

### 8.11 æ•…éšœæ’æŸ¥æ‰‹å†Œ

**å¸¸è§é—®é¢˜è¯Šæ–­æµç¨‹**:

```bash
#!/bin/bash
# scripts/troubleshoot_ocr.sh

echo "ğŸ” OCRæ•…éšœæ’æŸ¥å·¥å…·"

# 1. æ£€æŸ¥PodçŠ¶æ€
echo "=== Podå¥åº·æ£€æŸ¥ ==="
kubectl get pods -n production -l component=ocr
kubectl describe pod -n production -l component=ocr | grep -A 5 "Events:"

# 2. æ£€æŸ¥æ—¥å¿—
echo "=== æœ€è¿‘é”™è¯¯æ—¥å¿— ==="
kubectl logs -n production -l component=ocr --tail=50 | grep -i "error\|exception"

# 3. æ£€æŸ¥GPUå¯ç”¨æ€§
echo "=== GPUçŠ¶æ€ ==="
kubectl exec -n production -it $(kubectl get pod -n production -l component=ocr -o jsonpath='{.items[0].metadata.name}') -- nvidia-smi

# 4. æ£€æŸ¥Providerå¥åº·
echo "=== Providerå¥åº·åº¦ ==="
curl -s http://api.cad-ml.yourcompany.com/ocr/health | jq '.providers'

# 5. æ£€æŸ¥PrometheusæŒ‡æ ‡
echo "=== å…³é”®æŒ‡æ ‡ ==="
curl -s http://prometheus:9090/api/v1/query?query=ocr_requests_total | jq '.data.result[] | {metric, value}'

# 6. æ£€æŸ¥ç†”æ–­å™¨çŠ¶æ€
echo "=== ç†”æ–­å™¨çŠ¶æ€ ==="
curl -s http://api.cad-ml.yourcompany.com/ocr/circuit-breaker-status

# 7. ç½‘ç»œè¿é€šæ€§
echo "=== Redisè¿æ¥ ==="
kubectl exec -n production $(kubectl get pod -n production -l component=ocr -o jsonpath='{.items[0].metadata.name}') -- redis-cli -h redis.production.svc.cluster.local ping

echo "âœ… æ’æŸ¥å®Œæˆ"
```

**é”™è¯¯ä»£ç å¯¹ç…§è¡¨**:

| é”™è¯¯ä»£ç  | å«ä¹‰ | æ’æŸ¥æ­¥éª¤ | è§£å†³æ–¹æ¡ˆ |
|---------|------|---------|---------|
| `OCR_001` | Provideråˆå§‹åŒ–å¤±è´¥ | 1) æ£€æŸ¥GPUå¯ç”¨æ€§<br>2) æ£€æŸ¥æ¨¡å‹æ–‡ä»¶ | é‡å¯Pod / é‡æ–°ä¸‹è½½æ¨¡å‹ |
| `OCR_002` | JSONè§£æå¤±è´¥ | 1) æŸ¥çœ‹åŸå§‹è¾“å‡º<br>2) æ£€æŸ¥prompt | å¯ç”¨Markdown fallback |
| `OCR_003` | ç½®ä¿¡åº¦æ ¡å‡†å™¨æœªè®­ç»ƒ | 1) æ£€æŸ¥golden set<br>2) æŸ¥çœ‹calibratoræ—¥å¿— | è¿è¡Œ`python scripts/train_calibrator.py` |
| `OCR_004` | Redisè¿æ¥è¶…æ—¶ | 1) ping Redis<br>2) æ£€æŸ¥ç½‘ç»œç­–ç•¥ | æ£€æŸ¥Rediså¥åº· / å¢åŠ è¶…æ—¶ |
| `OCR_005` | å¹¶å‘æ•°è¶…é™ | 1) æŸ¥çœ‹å½“å‰å¹¶å‘<br>2) æ£€æŸ¥HPA | æ‰©å®¹Pod / å¢åŠ `OCR_MAX_CONCURRENT` |
| `OCR_006` | ç†”æ–­å™¨è§¦å‘ | 1) æŸ¥çœ‹é”™è¯¯æ—¥å¿—<br>2) æ£€æŸ¥providerå¥åº· | ç­‰å¾…è‡ªåŠ¨æ¢å¤ / æ‰‹åŠ¨é‡ç½® |

### 8.12 SLA/SLOå®šä¹‰

**æœåŠ¡ç­‰çº§ç›®æ ‡** (SLO):

```yaml
slo_targets:

  # å¯ç”¨æ€§SLO
  availability:
    target: 99.5%  # æ¯æœˆå…è®¸åœæœº 3.6å°æ—¶
    measurement: uptime / total_time
    breach_threshold: < 99.0%

  # å»¶è¿ŸSLO
  latency:
    p50_target: "< 2s"
    p95_target: "< 5s"
    p99_target: "< 10s"
    measurement: histogram_quantile(0.95, ocr_processing_duration_seconds)
    breach_threshold: p95 > 7s

  # å‡†ç¡®æ€§SLO
  accuracy:
    edge_f1_target: "> 0.75"
    field_recall_target: "> 0.80"
    measurement: weekly_evaluation_report
    breach_threshold: edge_f1 < 0.70

  # é”™è¯¯ç‡SLO
  error_rate:
    target: "< 2%"
    measurement: error_requests / total_requests
    breach_threshold: > 5%
```

**SLAæ‰¿è¯º** (å¯¹å¤–):

```markdown
# CAD ML OCRæœåŠ¡SLA

## æœåŠ¡å¯ç”¨æ€§
- **æ ‡å‡†æ‰¿è¯º**: 99.5% æœˆåº¦å¯ç”¨æ€§
- **èµ”å¿é˜ˆå€¼**: < 99.0%
- **è®¡ç®—å…¬å¼**: (æ€»æ—¶é—´ - æ•…éšœæ—¶é—´) / æ€»æ—¶é—´

## æ€§èƒ½æ‰¿è¯º
- **P95å»¶è¿Ÿ**: < 5ç§’
- **P99å»¶è¿Ÿ**: < 10ç§’
- **æµ‹é‡å‘¨æœŸ**: æ¯5åˆ†é’Ÿæ»šåŠ¨çª—å£

## å‡†ç¡®æ€§ä¿è¯
- **è¾¹ç¼˜F1åˆ†æ•°**: â‰¥ 0.75 (å‘¨å¹³å‡)
- **å­—æ®µå¬å›ç‡**: â‰¥ 0.80 (dimension/title_block)
- **ç½®ä¿¡åº¦æ ¡å‡†**: Brier Score < 0.20

## æ”¯æŒå“åº”æ—¶é—´
- **P0 (æœåŠ¡å…¨é¢ä¸­æ–­)**: 15åˆ†é’Ÿå“åº”, 2å°æ—¶æ¢å¤
- **P1 (æ ¸å¿ƒåŠŸèƒ½ä¸å¯ç”¨)**: 1å°æ—¶å“åº”, 8å°æ—¶æ¢å¤
- **P2 (æ€§èƒ½ä¸‹é™)**: 4å°æ—¶å“åº”, 24å°æ—¶æ¢å¤
- **P3 (ä¸€èˆ¬é—®é¢˜)**: 1å·¥ä½œæ—¥å“åº”

## ç»´æŠ¤çª—å£
- **è®¡åˆ’ç»´æŠ¤**: æ¯æœˆç¬¬äºŒä¸ªå‘¨æ—¥ 02:00-05:00 UTC+8
- **æå‰é€šçŸ¥**: è‡³å°‘æå‰7å¤©é€šçŸ¥
- **ç´§æ€¥ç»´æŠ¤**: æå‰24å°æ—¶é€šçŸ¥
```

---

## ä¹ã€éªŒæ”¶æ ‡å‡†

### 9.1 Week 1 MVPéªŒæ”¶

#### Day 1-2: åŸºç¡€æ¡†æ¶

```bash
âœ… ç¯å¢ƒé…ç½®æ–‡ä»¶: .env.dev, .env.gpu, .env.prod å­˜åœ¨
âœ… æœåŠ¡å¯åŠ¨: python src/main.py æ— é”™è¯¯
âœ… å¥åº·æ£€æŸ¥: curl http://localhost:8000/health è¿”å›200
âœ… OCRå¥åº·: curl http://localhost:8000/ocr/health æ˜¾ç¤ºprovidersçŠ¶æ€
âœ… Paddleå¯ç”¨: paddle provider ready=true (å¼€å‘ç¯å¢ƒ)
âœ… DeepSeekå¯ç”¨: deepseek_hf provider ready=true (GPUç¯å¢ƒ)
```

#### Day 3: ç»“æ„åŒ–è§£æ

```bash
âœ… JSONæ ¡éªŒé€šè¿‡ç‡: >80% (åœ¨æµ‹è¯•æ ·æœ¬ä¸Š)
âœ… Markdown fallback: JSONå¤±è´¥æ—¶èƒ½é™çº§è§£æ
âœ… å°ºå¯¸è§£æå‡†ç¡®ç‡: èƒ½è¯†åˆ«Î¦/R/M/Â±t, >70%
âœ… ç¬¦å·è§£æ: èƒ½è¯†åˆ«Ra/âŸ‚/âˆ¥, >60%
```

#### Day 4: è¯æ®é“¾

```bash
âœ… ç½®ä¿¡åº¦æ ¡å‡†: calibrated_confidenceå­—æ®µæ­£å¸¸è¾“å‡º
âœ… è¯æ®é“¾å®Œæ•´: evidence_chainåŒ…å«provider/confidence/source
âœ… Brier score: <0.20 (åœ¨golden setä¸Š)
âœ… DSèåˆ: å¤šproviderç»“æœèƒ½æ­£ç¡®èåˆ
```

#### Day 5: ç«¯åˆ°ç«¯é›†æˆ

```bash
âœ… /api/v1/analyzeé›†æˆ: enable_ocr=trueè¿”å›OCRå­—æ®µ
âœ… ææ–™è¯†åˆ«: title_block.materialèƒ½æ­£ç¡®æå–
âœ… å·¥è‰ºå¢å¼º: åŸºäºææ–™è¿”å›å·¥è‰ºå»ºè®®
âœ… å“åº”æ—¶é—´: P95 <5s (autoæ¨¡å¼)
âœ… ç¼“å­˜å‘½ä¸­: é‡å¤è¯·æ±‚ç¼“å­˜ç”Ÿæ•ˆ
```

### 9.2 Week 2 å®Œæ•´éªŒæ”¶

```bash
âœ… Autoç­–ç•¥: Fallbackè§¦å‘ç‡ <20%
âœ… è´¨é‡é—¨æ§: å…³é”®å­—æ®µå®Œæ•´æ€§ >90%
âœ… è¯„æµ‹æŒ‡æ ‡: Edge F1 â‰¥0.75
âœ… å­—æ®µå¬å›: dimension/title_blockå¬å› â‰¥0.80
âœ… å»¶è¿Ÿæ§åˆ¶: P95 <5s, P99 <10s
âœ… å¹¶å‘ç¨³å®š: 10å¹¶å‘è¯·æ±‚æ— è¶…æ—¶
âœ… CIé›†æˆ: GitHub Actionsè‡ªåŠ¨è¿è¡Œè¯„æµ‹
```

### 9.3 ç”Ÿäº§å°±ç»ªæ£€æŸ¥æ¸…å•

- [x] **å¤šç¯å¢ƒé…ç½®**: dev/gpu/prodä¸‰å¥—é…ç½®
- [x] **å¥åº·æ£€æŸ¥**: /health + /ready + /ocr/health
- [x] **ç›‘æ§æŒ‡æ ‡**: PrometheusæŒ‡æ ‡å®Œæ•´
- [x] **æ—¥å¿—è§„èŒƒ**: ç»“æ„åŒ–JSONæ—¥å¿—
- [x] **é”™è¯¯å¤„ç†**: è¶…æ—¶/ç†”æ–­/é™çº§
- [x] **æ–‡æ¡£å®Œå–„**: APIæ–‡æ¡£ + éƒ¨ç½²æ‰‹å†Œ
- [x] **æµ‹è¯•è¦†ç›–**: golden cases + CIé›†æˆ
- [x] **æ€§èƒ½ä¼˜åŒ–**: ç¼“å­˜ + é¢„çƒ­ + å¹¶å‘æ§åˆ¶

---

## åã€é™„å½•

### 10.1 Promptæ¨¡æ¿åº“

```python
"""
DeepSeek Promptæ¨¡æ¿
src/core/ocr/utils/prompt_templates.py
"""

class PromptTemplates:
    """Promptæ¨¡æ¿åº“"""

    @staticmethod
    def free_ocr() -> str:
        """é€šç”¨OCR"""
        return "<image>\n<|grounding|>Free OCR."

    @staticmethod
    def engineering_drawing_structured() -> str:
        """å·¥ç¨‹å›¾ç»“æ„åŒ–"""
        return """<image>
<|grounding|>Extract dimensions/tolerances/surface-roughness/threads as strict JSON:
{
  "dimensions": [{"type":"diameter|radius|length|thread", "value":float, "unit":"mm", "tolerance":float, "bbox":{}}],
  "symbols": [{"type":"surface_roughness|perpendicular|parallel", "value":str, "bbox":{}}],
  "title_block": {"drawing_number":str, "material":str, "part_name":str, "scale":str}
}"""

    @staticmethod
    def title_block_focused() -> str:
        """æ ‡é¢˜æ ä¸“æ³¨"""
        return """<image>
<|grounding|>Focus on the title block (usually bottom-right corner).
Extract as JSON: {"drawing_number":str, "material":str, "part_name":str, "scale":str, "weight":float}"""
```

### 10.2 å¸¸è§é—®é¢˜FAQ

**Q1: DeepSeekæ¨¡å‹åŠ è½½å¤±è´¥ï¼Ÿ**

```bash
# æ£€æŸ¥GPUå¯ç”¨æ€§
nvidia-smi

# æ£€æŸ¥CUDAç‰ˆæœ¬
python -c "import torch; print(torch.cuda.is_available())"

# é™çº§åˆ°CPUæ¨¡å¼
export DEEPSEEK_DEVICE=cpu
```

**Q2: JSONè§£æå¤±è´¥ç‡é«˜ï¼Ÿ**

```bash
# æ–¹æ¡ˆ1: ä¼˜åŒ–promptï¼Œå¼ºè°ƒJSONæ ¼å¼
# æ–¹æ¡ˆ2: å¯ç”¨Markdown fallback
# æ–¹æ¡ˆ3: é™ä½confidence_thresholdè§¦å‘deepseekå¢å¼º
```

**Q3: ç¼“å­˜ä¸ç”Ÿæ•ˆï¼Ÿ**

```bash
# æ£€æŸ¥Redisè¿æ¥
redis-cli ping

# æ£€æŸ¥ç¼“å­˜é…ç½®
echo $OCR_CACHE_ENABLED  # åº”ä¸ºtrue
```

**Q4: æ€§èƒ½ä¼˜åŒ–å»ºè®®ï¼Ÿ**

1. **å¯ç”¨GPU**: `DEEPSEEK_DEVICE=cuda`
2. **æé«˜å¹¶å‘**: `OCR_MAX_CONCURRENT=10`
3. **ä¼˜åŒ–ç¼“å­˜**: å¢å¤§`OCR_CACHE_TTL`
4. **é¢„çƒ­æ¨¡å‹**: å¯åŠ¨æ—¶è°ƒç”¨`/ocr/warmup`
5. **ç°åº¦DeepSeek**: `DEEPSEEK_ROLLOUT_PERCENTAGE=20`

### 10.3 å‚è€ƒèµ„æ–™

- [DeepSeek-OCR GitHub](https://github.com/deepseek-ai/DeepSeek-OCR)
- [PaddleOCR æ–‡æ¡£](https://github.com/PaddlePaddle/PaddleOCR)
- [Dempster-Shafer è¯æ®ç†è®º](https://en.wikipedia.org/wiki/Dempster%E2%80%93Shafer_theory)
- [Isotonic Regression æ ¡å‡†](https://scikit-learn.org/stable/modules/calibration.html)

### 10.4 æœ¯è¯­è¡¨

| æœ¯è¯­ | å«ä¹‰ |
|------|------|
| **Provider** | OCRæœåŠ¡æä¾›å•† (paddle/deepseek_hf/vllm) |
| **Autoç­–ç•¥** | æ™ºèƒ½è·¯ç”±ï¼šå…ˆpaddleï¼Œä½ç½®ä¿¡åº¦â†’deepseek |
| **å‡ ä½•å¯¹é½** | OCRæ–‡æœ¬æ¡†é”šå®šåˆ°CADå‡ ä½•å…ƒç´  |
| **è¯æ®é“¾** | å®Œæ•´çš„å†³ç­–è·¯å¾„ï¼šprovider+ç½®ä¿¡åº¦+bbox+è§„åˆ™ |
| **DSèåˆ** | Dempster-Shaferè¯æ®ç†è®ºèåˆ |
| **è´¨é‡é—¨æ§** | å…³é”®å­—æ®µæ£€æŸ¥+ç½®ä¿¡åº¦é˜ˆå€¼æ§åˆ¶ |
| **ç†”æ–­é™çº§** | é”™è¯¯ç´¯ç§¯è§¦å‘è‡ªåŠ¨åˆ‡æ¢å¤‡ç”¨provider |
| **å¹‚ç­‰æ€§** | ç›¸åŒè¯·æ±‚è¿”å›ç›¸åŒç»“æœ (é€šè¿‡Idempotency-Key) |

---

**æ–‡æ¡£ç»“æŸ**

**ä¸‹ä¸€æ­¥è¡ŒåŠ¨**:
1. æ‰§è¡Œ `scripts/quick_start_ocr.sh` å¿«é€Ÿå¯åŠ¨
2. é˜…è¯» `docs/API_DOCUMENTATION.md` äº†è§£æ¥å£è¯¦æƒ…
3. è¿è¡Œ `pytest tests/ocr/` æ‰§è¡Œå•å…ƒæµ‹è¯•
4. å‚è€ƒ `examples/ocr_demo.py` å­¦ä¹ ä½¿ç”¨ç¤ºä¾‹

**è”ç³»ä¸æ”¯æŒ**:
- æŠ€æœ¯æ”¯æŒ: tech-support@yourcompany.com
- Issueè¿½è¸ª: [GitHub Issues](https://github.com/your-org/cad-ml-platform/issues)
