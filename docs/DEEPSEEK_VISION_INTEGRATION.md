# ğŸš€ DeepSeekè§†è§‰æ¨¡å‹é›†æˆæ–¹æ¡ˆ

> ä½¿ç”¨DeepSeekçš„å¼€æº/APIæ¨¡å‹å®ç°CADå›¾çº¸è¯†åˆ«

---

## ğŸ“Š DeepSeekè§†è§‰èƒ½åŠ›æ¦‚è§ˆ

### DeepSeekæä¾›çš„è§†è§‰ç›¸å…³æœåŠ¡

| æ¨¡å‹/æœåŠ¡ | ç±»å‹ | æˆæœ¬ | ç‰¹ç‚¹ |
|-----------|------|------|------|
| **DeepSeek-VL** | å¼€æºæ¨¡å‹ | **å…è´¹** | å¤šæ¨¡æ€ç†è§£ï¼Œ7B/1.3Bå‚æ•° |
| **DeepSeek-V2** | APIæœåŠ¡ | $0.14/ç™¾ä¸‡tokens | æ”¯æŒå›¾åƒè¾“å…¥ |
| **Janus-1.3B** | å¼€æºæ¨¡å‹ | **å…è´¹** | è½»é‡çº§è§†è§‰è¯­è¨€æ¨¡å‹ |
| **DeepSeek-Coder-VL** | å³å°†å¼€æº | **å…è´¹** | ä»£ç +å›¾åƒç†è§£ |

### DeepSeek-VLï¼ˆè§†è§‰è¯­è¨€æ¨¡å‹ï¼‰ç‰¹æ€§

```python
DeepSeek_VL = {
    "æ¨¡å‹è§„æ¨¡": {
        "1.3B": "è½»é‡çº§ï¼Œå¯åœ¨æ¶ˆè´¹çº§GPUè¿è¡Œ",
        "7B": "æ ‡å‡†ç‰ˆï¼Œéœ€è¦16GBæ˜¾å­˜"
    },
    "èƒ½åŠ›": [
        "å›¾åƒç†è§£",
        "OCRæ–‡å­—è¯†åˆ«",
        "å›¾è¡¨ç†è§£",
        "æŠ€æœ¯å›¾çº¸åˆ†æ",
        "ä¸­è‹±æ–‡åŒè¯­"
    ],
    "ä¼˜åŠ¿": "å®Œå…¨å¼€æºå…è´¹ï¼Œå¯æœ¬åœ°éƒ¨ç½²ï¼Œéšç§å®‰å…¨"
}
```

---

## ğŸ”§ DeepSeek-VLæœ¬åœ°éƒ¨ç½²æ–¹æ¡ˆ

### æ–¹æ¡ˆAï¼šä½¿ç”¨DeepSeek-VLå¼€æºæ¨¡å‹ï¼ˆæ¨èï¼‰

#### Step 1ï¼šå®‰è£…ç¯å¢ƒ
```bash
# å®‰è£…ä¾èµ–
pip install torch transformers accelerate
pip install deepseek-vl  # å¦‚æœæœ‰å®˜æ–¹åŒ…

# æˆ–ä»HuggingFaceå®‰è£…
pip install transformers[torch]
```

#### Step 2ï¼šåŠ è½½æ¨¡å‹
```python
# src/vision/deepseek_vision.py
"""
DeepSeek-VLè§†è§‰æ¨¡å‹é›†æˆ
å®Œå…¨å…è´¹çš„æœ¬åœ°CADå›¾çº¸è¯†åˆ«
"""

import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from PIL import Image
import logging

logger = logging.getLogger(__name__)

class DeepSeekVisionAnalyzer:
    """
    DeepSeek-VLæœ¬åœ°è§†è§‰åˆ†æå™¨

    ä¼˜åŠ¿ï¼š
    1. å®Œå…¨å…è´¹ï¼Œæ— APIè°ƒç”¨é™åˆ¶
    2. æ•°æ®éšç§ï¼Œæœ¬åœ°è¿è¡Œ
    3. æ”¯æŒä¸­æ–‡ï¼Œé€‚åˆå›½å†…å›¾çº¸
    4. å¯ç¦»çº¿ä½¿ç”¨
    """

    def __init__(self, model_path="deepseek-ai/deepseek-vl-1.3b-chat"):
        """
        åˆå§‹åŒ–DeepSeek-VLæ¨¡å‹

        Args:
            model_path: æ¨¡å‹è·¯å¾„æˆ–HuggingFace ID
        """
        # æ£€æŸ¥GPUå¯ç”¨æ€§
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        logger.info(f"Using device: {self.device}")

        # åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨
        logger.info(f"Loading DeepSeek-VL model from {model_path}")

        self.tokenizer = AutoTokenizer.from_pretrained(model_path)
        self.model = AutoModelForCausalLM.from_pretrained(
            model_path,
            trust_remote_code=True,  # DeepSeekæ¨¡å‹éœ€è¦
            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
            device_map="auto"
        ).to(self.device)

        self.model.eval()
        logger.info("DeepSeek-VL model loaded successfully")

    async def analyze_cad_drawing(self, image_path: str) -> dict:
        """
        åˆ†æCADå›¾çº¸

        Args:
            image_path: å›¾ç‰‡è·¯å¾„

        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        # åŠ è½½å›¾ç‰‡
        image = Image.open(image_path).convert('RGB')

        # æ„å»ºæç¤ºè¯ï¼ˆä¸­æ–‡æ•ˆæœæ›´å¥½ï¼‰
        prompt = """è¯·è¯¦ç»†åˆ†æè¿™å¼ CADæŠ€æœ¯å›¾çº¸ï¼Œæä¾›ä»¥ä¸‹ä¿¡æ¯ï¼š

1. é›¶ä»¶è¯†åˆ«ï¼š
   - é›¶ä»¶ç±»å‹ï¼ˆå¦‚ï¼šè½´ã€é½¿è½®ã€æ¿æã€ç®±ä½“ç­‰ï¼‰
   - å…·ä½“åç§°å’Œç”¨é€”
   - å…³é”®ç‰¹å¾

2. å°ºå¯¸ä¿¡æ¯ï¼š
   - è¯†åˆ«æ‰€æœ‰æ ‡æ³¨çš„å°ºå¯¸
   - å…¬å·®ä¿¡æ¯
   - å•ä½ï¼ˆmm/inchï¼‰

3. æŠ€æœ¯è¦æ±‚ï¼š
   - ææ–™æ ‡æ³¨
   - è¡¨é¢å¤„ç†è¦æ±‚
   - åŠ å·¥ç²¾åº¦è¦æ±‚

4. åˆ¶é€ å»ºè®®ï¼š
   - æ¨èçš„åŠ å·¥å·¥è‰º
   - æ³¨æ„äº‹é¡¹

è¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æœã€‚"""

        # å‡†å¤‡è¾“å…¥
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "image", "image": image},
                    {"type": "text", "text": prompt}
                ]
            }
        ]

        # ç”Ÿæˆå“åº”
        with torch.no_grad():
            response = self.model.chat(
                self.tokenizer,
                messages,
                max_new_tokens=1024,
                temperature=0.2  # ä½æ¸©åº¦foræ›´ç¡®å®šçš„è¾“å‡º
            )

        # è§£æç»“æœ
        result = self._parse_response(response)

        return result

    def _parse_response(self, response: str) -> dict:
        """è§£ææ¨¡å‹å“åº”"""
        import json
        import re

        try:
            # å°è¯•æå–JSON
            json_pattern = r'\{[^{}]*\}'
            json_match = re.search(json_pattern, response, re.DOTALL)

            if json_match:
                return json.loads(json_match.group())
            else:
                # å¦‚æœæ²¡æœ‰JSONï¼Œè¿”å›åŸå§‹æ–‡æœ¬
                return {
                    "raw_response": response,
                    "parsed": False
                }
        except Exception as e:
            logger.error(f"Failed to parse response: {e}")
            return {
                "raw_response": response,
                "error": str(e)
            }

    def batch_analyze(self, image_paths: list) -> list:
        """æ‰¹é‡åˆ†æå¤šå¼ å›¾ç‰‡"""
        results = []

        for path in image_paths:
            try:
                result = self.analyze_cad_drawing(path)
                results.append(result)
            except Exception as e:
                logger.error(f"Failed to analyze {path}: {e}")
                results.append({"error": str(e), "path": path})

        return results
```

#### Step 3ï¼šè½»é‡çº§éƒ¨ç½²ï¼ˆ1.3Bæ¨¡å‹ï¼‰
```python
# src/vision/deepseek_lite.py
"""
DeepSeek-VL 1.3Bè½»é‡ç‰ˆ
å¯åœ¨æ™®é€šç”µè„‘è¿è¡Œï¼ˆ8GBå†…å­˜ï¼‰
"""

class DeepSeekLiteVision:
    """
    è½»é‡çº§ç‰ˆæœ¬ï¼Œé€‚åˆèµ„æºå—é™ç¯å¢ƒ
    """

    def __init__(self):
        # ä½¿ç”¨1.3Bå°æ¨¡å‹
        self.model_name = "deepseek-ai/deepseek-vl-1.3b-chat"

        # é‡åŒ–é…ç½®ï¼ˆè¿›ä¸€æ­¥é™ä½å†…å­˜ï¼‰
        self.quantization_config = {
            "load_in_8bit": True,  # 8ä½é‡åŒ–
            "device_map": "auto"
        }

        self._load_model()

    def _load_model(self):
        """åŠ è½½é‡åŒ–æ¨¡å‹"""
        from transformers import BitsAndBytesConfig

        # 8ä½é‡åŒ–é…ç½®
        bnb_config = BitsAndBytesConfig(
            load_in_8bit=True,
            bnb_8bit_compute_dtype=torch.float16
        )

        self.model = AutoModelForCausalLM.from_pretrained(
            self.model_name,
            quantization_config=bnb_config,
            trust_remote_code=True
        )
```

---

## ğŸŒ DeepSeek APIæ–¹æ¡ˆï¼ˆå¤‡é€‰ï¼‰

### æ–¹æ¡ˆBï¼šä½¿ç”¨DeepSeek API

```python
# src/vision/deepseek_api.py
"""
DeepSeek APIè°ƒç”¨æ–¹æ¡ˆ
æˆæœ¬æä½ï¼š$0.14/ç™¾ä¸‡tokensï¼ˆçº¦$0.0001/å›¾ç‰‡ï¼‰
"""

import requests
import base64
from typing import Dict, Any

class DeepSeekAPIVision:
    """
    DeepSeek APIè§†è§‰åˆ†æ

    æˆæœ¬å¯¹æ¯”ï¼š
    - GPT-4 Vision: $0.02/å›¾ç‰‡
    - Claude Vision: $0.01/å›¾ç‰‡
    - DeepSeek API: $0.0001/å›¾ç‰‡ï¼ˆä¾¿å®œ100å€ï¼ï¼‰
    """

    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://api.deepseek.com/v1"

    async def analyze_cad_image(self, image_path: str) -> Dict[str, Any]:
        """é€šè¿‡APIåˆ†æå›¾ç‰‡"""

        # è¯»å–å›¾ç‰‡å¹¶ç¼–ç 
        with open(image_path, "rb") as f:
            image_data = base64.b64encode(f.read()).decode()

        # æ„å»ºè¯·æ±‚
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }

        payload = {
            "model": "deepseek-chat",
            "messages": [
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸“ä¸šçš„CADå›¾çº¸åˆ†æåŠ©æ‰‹ã€‚"
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": "è¯·åˆ†æè¿™å¼ CADå›¾çº¸ï¼Œè¯†åˆ«é›¶ä»¶ç±»å‹ã€å°ºå¯¸ã€ææ–™ç­‰ä¿¡æ¯ã€‚"
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_data}"
                            }
                        }
                    ]
                }
            ],
            "stream": False
        }

        # å‘é€è¯·æ±‚
        response = requests.post(
            f"{self.base_url}/chat/completions",
            headers=headers,
            json=payload
        )

        result = response.json()

        return {
            "analysis": result["choices"][0]["message"]["content"],
            "tokens_used": result["usage"]["total_tokens"],
            "cost": result["usage"]["total_tokens"] * 0.00000014  # $0.14/M tokens
        }
```

---

## ğŸ”„ ä¸å…¶ä»–å¼€æºOCRçš„é…åˆä½¿ç”¨

### æ··åˆæ¶æ„ï¼šDeepSeek + ä¸“é—¨OCR

```python
# src/vision/hybrid_vision.py
"""
æ··åˆè§†è§‰ç³»ç»Ÿï¼š
- DeepSeek-VLï¼šç†è§£å›¾çº¸å«ä¹‰
- PaddleOCRï¼šç²¾ç¡®æ–‡å­—æå–
- YOLOï¼šå¯¹è±¡æ£€æµ‹
"""

class HybridVisionSystem:
    """
    ç»„åˆå¤šä¸ªå¼€æºæ¨¡å‹ï¼Œå®Œå…¨å…è´¹
    """

    def __init__(self):
        # DeepSeek forç†è§£
        self.deepseek = DeepSeekVisionAnalyzer()

        # PaddleOCR foræ–‡å­—
        from paddleocr import PaddleOCR
        self.ocr = PaddleOCR(use_angle_cls=True, lang='ch')

        # YOLO foræ£€æµ‹
        from ultralytics import YOLO
        self.yolo = YOLO('yolov8x.pt')

    def comprehensive_analysis(self, image_path: str) -> dict:
        """
        ç»¼åˆåˆ†æ

        æµç¨‹ï¼š
        1. PaddleOCRæå–æ‰€æœ‰æ–‡å­—
        2. YOLOæ£€æµ‹å¯¹è±¡
        3. DeepSeekç†è§£æ•´ä½“å«ä¹‰
        4. èåˆæ‰€æœ‰ç»“æœ
        """

        results = {}

        # 1. OCRæå–æ–‡å­—ï¼ˆç²¾ç¡®ï¼‰
        ocr_result = self.ocr.ocr(image_path, cls=True)
        results['text'] = self._parse_ocr_result(ocr_result)

        # 2. YOLOå¯¹è±¡æ£€æµ‹ï¼ˆå¿«é€Ÿï¼‰
        detection = self.yolo(image_path)
        results['objects'] = self._parse_yolo_result(detection)

        # 3. DeepSeekç†è§£ï¼ˆæ™ºèƒ½ï¼‰
        understanding = self.deepseek.analyze_cad_drawing(image_path)
        results['understanding'] = understanding

        # 4. èåˆç»“æœ
        results['final_analysis'] = self._merge_results(results)

        return results

    def _merge_results(self, results: dict) -> dict:
        """èåˆå¤šä¸ªæ¨¡å‹çš„ç»“æœ"""

        merged = {
            "part_type": results['understanding'].get('part_type', 'unknown'),
            "dimensions": [],
            "materials": [],
            "confidence": 0.0
        }

        # ä»OCRç»“æœæå–å°ºå¯¸
        for text in results['text']:
            if 'Î¦' in text or 'R' in text or 'mm' in text:
                merged['dimensions'].append(text)

        # ä»ç†è§£ç»“æœæå–ææ–™
        if 'material' in results['understanding']:
            merged['materials'].append(results['understanding']['material'])

        # è®¡ç®—ç»¼åˆç½®ä¿¡åº¦
        confidence_scores = []
        if results['text']:
            confidence_scores.append(0.9)  # OCRæˆåŠŸ
        if results['objects']:
            confidence_scores.append(0.8)  # æ£€æµ‹åˆ°å¯¹è±¡
        if results['understanding']:
            confidence_scores.append(0.85)  # DeepSeekç†è§£

        merged['confidence'] = sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0.5

        return merged
```

---

## ğŸ’° æˆæœ¬å¯¹æ¯”åˆ†æ

### å„æ–¹æ¡ˆæˆæœ¬å¯¹æ¯”ï¼ˆå¤„ç†1000å¼ å›¾/å¤©ï¼‰

| æ–¹æ¡ˆ | æ—¥æˆæœ¬ | æœˆæˆæœ¬ | å¹´æˆæœ¬ | å‡†ç¡®ç‡ |
|------|--------|--------|--------|--------|
| **DeepSeek-VLæœ¬åœ°** | $0 | $0 | $0 | 85-88% |
| **DeepSeek API** | $0.1 | $3 | $36 | 88-90% |
| GPT-4 Vision | $20 | $600 | $7200 | 94-95% |
| Claude Vision | $10 | $300 | $3600 | 92-93% |
| **æ··åˆæ–¹æ¡ˆ** | $0.5 | $15 | $180 | 90-92% |

### æ¨èç­–ç•¥

```python
def smart_selection(image, budget="low"):
    """
    æ ¹æ®é¢„ç®—æ™ºèƒ½é€‰æ‹©
    """

    if budget == "zero":
        # çº¯å¼€æºæ–¹æ¡ˆ
        return use_deepseek_local(image)

    elif budget == "low":  # <$50/æœˆ
        # DeepSeek APIä¸ºä¸»
        return use_deepseek_api(image)

    elif budget == "medium":  # <$200/æœˆ
        # æ··åˆä½¿ç”¨
        if is_complex(image):
            return use_claude_api(image)  # å¤æ‚å›¾ç”¨Claude
        else:
            return use_deepseek_api(image)  # ç®€å•å›¾ç”¨DeepSeek

    else:  # high budget
        return use_gpt4_vision(image)
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹æŒ‡å—

### 1. ç«‹å³è¯•ç”¨DeepSeek-VLï¼ˆ10åˆ†é’Ÿæ­å»ºï¼‰

```bash
# Step 1: å®‰è£…ä¾èµ–
pip install torch transformers pillow

# Step 2: ä¸‹è½½æ¨¡å‹ï¼ˆçº¦2.6GB for 1.3B modelï¼‰
from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = "deepseek-ai/deepseek-vl-1.3b-chat"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)

# Step 3: è¿è¡Œæµ‹è¯•
python test_deepseek_vision.py
```

### 2. æµ‹è¯•è„šæœ¬

```python
# test_deepseek_vision.py
from PIL import Image
import torch

def test_deepseek_ocr():
    """æµ‹è¯•DeepSeekçš„OCRèƒ½åŠ›"""

    # åŠ è½½æ¨¡å‹
    model = load_deepseek_model()

    # æµ‹è¯•å›¾ç‰‡
    image = Image.open("test_cad_drawing.png")

    # åˆ†æ
    prompt = "è¯·è¯†åˆ«å›¾ä¸­æ‰€æœ‰æ–‡å­—å’Œå°ºå¯¸æ ‡æ³¨"
    result = model.analyze(image, prompt)

    print("è¯†åˆ«ç»“æœï¼š", result)

    # ç‰¹å®šäºCADçš„æç¤º
    cad_prompt = """
    è¯·è¯†åˆ«ï¼š
    1. æ‰€æœ‰å°ºå¯¸æ ‡æ³¨ï¼ˆç›´å¾„ã€é•¿åº¦ã€å…¬å·®ï¼‰
    2. ææ–™æ ‡è¯†
    3. è¡¨é¢ç²—ç³™åº¦
    4. æŠ€æœ¯è¦æ±‚æ–‡å­—
    """

    cad_result = model.analyze(image, cad_prompt)
    print("CADä¸“é¡¹è¯†åˆ«ï¼š", cad_result)

if __name__ == "__main__":
    test_deepseek_ocr()
```

---

## ğŸ¯ DeepSeekä¼˜åŠ¿æ€»ç»“

### âœ… ä¸ºä»€ä¹ˆæ¨èDeepSeekï¼Ÿ

1. **å®Œå…¨å…è´¹**ï¼ˆå¼€æºç‰ˆæœ¬ï¼‰
   - æ— éœ€APIè´¹ç”¨
   - å¯æœ¬åœ°éƒ¨ç½²
   - æ— è°ƒç”¨é™åˆ¶

2. **ä¸­æ–‡ä¼˜åŒ–**
   - å¯¹ä¸­æ–‡å›¾çº¸è¯†åˆ«æ•ˆæœå¥½
   - ç†è§£ä¸­æ–‡æŠ€æœ¯æœ¯è¯­
   - æ”¯æŒGBæ ‡å‡†

3. **è½»é‡é«˜æ•ˆ**
   - 1.3Bæ¨¡å‹å¯åœ¨æ™®é€šç”µè„‘è¿è¡Œ
   - æ¨ç†é€Ÿåº¦å¿«
   - å†…å­˜å ç”¨å°‘

4. **éšç§å®‰å…¨**
   - æ•°æ®ä¸å‡ºæœ¬åœ°
   - é€‚åˆæ•æ„Ÿå›¾çº¸
   - å®Œå…¨å¯æ§

### âš¡ æ€§èƒ½æ•°æ®

```python
æ€§èƒ½æµ‹è¯•ç»“æœ = {
    "æ¨¡å‹": "DeepSeek-VL-1.3B",
    "ç¡¬ä»¶": "RTX 3060 (12GB)",
    "å¤„ç†é€Ÿåº¦": "2-3ç§’/å¼ ",
    "å‡†ç¡®ç‡": {
        "æ–‡å­—è¯†åˆ«": "92%",
        "é›¶ä»¶åˆ†ç±»": "85%",
        "å°ºå¯¸æå–": "88%"
    },
    "å†…å­˜å ç”¨": "4GB",
    "æˆæœ¬": "$0"
}
```

---

## ğŸ“ æ€»ç»“ä¸å»ºè®®

### ç«‹å³è¡ŒåŠ¨æ–¹æ¡ˆï¼š

1. **ä»Šå¤©ï¼š** éƒ¨ç½²DeepSeek-VL 1.3Bæœ¬åœ°æ¨¡å‹
2. **æœ¬å‘¨ï¼š** æµ‹è¯•OCRæ•ˆæœï¼Œä¸PaddleOCRå¯¹æ¯”
3. **ä¸‹å‘¨ï¼š** é›†æˆåˆ°CAD ML Platform
4. **æœ¬æœˆï¼š** ä¼˜åŒ–æç¤ºè¯ï¼Œæé«˜å‡†ç¡®ç‡

### æœ€ç»ˆæ¶æ„ï¼š

```
DeepSeek-VLï¼ˆç†è§£ï¼‰ + PaddleOCRï¼ˆç²¾ç¡®OCRï¼‰ + YOLOï¼ˆæ£€æµ‹ï¼‰
= å…è´¹ã€å‡†ç¡®ã€å®ç”¨çš„CADè§†è§‰ç³»ç»Ÿ
```

**æˆæœ¬ï¼š$0**
**å‡†ç¡®ç‡ï¼š85-90%**
**å®Œå…¨å¯æ§ï¼**