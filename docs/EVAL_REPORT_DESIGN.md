# Evaluation Report System - Design Document

**Version**: Phase 1 (MVP)
**Date**: 2025-11-17
**Status**: Implemented

---

## 1. Overview

Static HTML evaluation report generator for CAD ML Platform. Creates offline-viewable reports with:
- Combined Score summary (Vision + OCR)
- Historical evaluation table
- Embedded trend charts (base64 inline)
- Health endpoint links

### Goals
- **Offline Accessibility**: No external dependencies (CDN/network)
- **CI-Friendly**: Single command, automated artifact generation
- **Comprehensive**: End-to-end system health visibility
- **Privacy-Aware**: Optional redaction of branch/commit info

---

## 2. Architecture

```
reports/eval_history/
├── *.json                    # Combined/OCR history files
├── plots/
│   ├── combined_trend.png    # Generated by eval_trend.py
│   └── ocr_trend.png
└── report/
    └── index.html            # Generated static report
```

### Data Flow
```
make eval-combined-save     # Step 1: Generate evaluation data
         ↓
make eval-trend              # Step 2: Generate trend charts
         ↓
generate_eval_report.py      # Step 3: Assemble HTML report
         ↓
index.html (standalone)      # Final output
```

---

## 3. Components

### 3.1 Report Generator Script

**File**: `scripts/generate_eval_report.py`
**Lines**: ~550
**Dependencies**: Standard library only (json, base64, datetime, subprocess, pathlib)

**Core Functions**:
- `load_combined_history()`: Load `*_combined.json` files
- `load_ocr_history()`: Load OCR-only evaluation files
- `encode_image_base64()`: Convert PNG to base64 data URI
- `generate_css()`: Inline responsive CSS
- `generate_html_report()`: Assemble complete HTML

**CLI Arguments**:
```bash
--out DIR           # Output directory (default: reports/eval_history/report)
--redact-commit     # Hide commit hashes (privacy/compliance)
--redact-branch     # Hide branch names (privacy/compliance)
```

### 3.2 HTML Report Structure

```html
<!DOCTYPE html>
<html>
<head>
  <style>/* Inline CSS, no external refs */</style>
</head>
<body>
  <div class="container">
    <!-- Summary Card: Latest Combined Score -->
    <div class="summary-card">
      <div class="score-large">0.821</div>
      Vision: 0.667 | OCR: 0.975 | Weights: 50%/50%
      Branch: main | Commit: abc1234
    </div>

    <!-- Health Links -->
    <div class="links">/health | /docs</div>

    <!-- Embedded Trend Charts (base64) -->
    <img src="data:image/png;base64,..." />

    <!-- Historical Table -->
    <table>...</table>

    <!-- Footer -->
    <div class="footer">Generated with make eval-report</div>
  </div>
</body>
</html>
```

### 3.3 Makefile Integration

**Target**: `make eval-report`

```makefile
eval-report: ## 生成静态 HTML 评测报告
	@echo "Step 1/3: Running combined evaluation..."
	@$(MAKE) eval-combined-save || echo "Warning..."
	@echo "Step 2/3: Generating trend charts..."
	@$(MAKE) eval-trend || echo "Warning..."
	@echo "Step 3/3: Generating HTML report..."
	$(PYTHON) scripts/generate_eval_report.py
	@echo "Open: file://$(PWD)/reports/eval_history/report/index.html"
```

**Error Resilience**: Each step uses `|| echo "Warning..."` to continue even if dependencies fail.

---

## 4. Report Features

### 4.1 Score Visualization
- **Large Display**: Combined score in prominent 3em font
- **Color Coding**: Green (≥0.85), Orange (0.70-0.85), Red (<0.70)
- **Component Breakdown**: Vision score, OCR score, weights

### 4.2 Trend Charts
- **Embedded Images**: Base64-encoded PNGs (~30-50KB each)
- **Offline Support**: No external image server required
- **Graceful Degradation**: Shows "chart not available" if missing

### 4.3 Historical Table
- **Combined History**: Last 20 entries (timestamp, scores, weights, branch, commit)
- **OCR History**: Last 10 entries (recall, brier, edge F1)
- **Sortable by Time**: Descending order (most recent first)

### 4.4 Privacy Controls
```bash
# Hide internal info for external sharing
python3 scripts/generate_eval_report.py --redact-commit --redact-branch
```
Displays `[redacted]` instead of actual values.

---

## 5. Verification Checklist

### Phase 1 MVP (Implemented)
- [x] Script generates standalone HTML
- [x] Report opens offline in browser
- [x] Summary displays latest Combined Score (0.821)
- [x] Trend charts embedded as base64
- [x] Historical table with 20+ entries
- [x] Health endpoint links included
- [x] No network/CDN dependencies
- [x] Makefile target `eval-report` works
- [x] Report file size reasonable (~67KB)
- [x] Graceful handling when history is empty

### Future Enhancements (Phase 2/3)
- [ ] Interactive charts (Chart.js/Plotly via CDN)
- [ ] Branch filtering dropdown
- [ ] Threshold visualization lines
- [ ] CSV export option
- [ ] CI artifact upload (GitHub Actions)
- [ ] GitHub Pages deployment
- [ ] Multiple report formats (PDF, Markdown)

---

## 6. Usage Guide

### Local Development
```bash
# Full pipeline
make eval-report

# Just regenerate HTML (if data already exists)
python3 scripts/generate_eval_report.py

# View report
open reports/eval_history/report/index.html
```

### CI Integration (Future)
```yaml
# GitHub Actions example
- name: Generate Evaluation Report
  run: make eval-report

- name: Upload Report Artifact
  uses: actions/upload-artifact@v3
  with:
    name: eval-report
    path: reports/eval_history/report/
```

### Privacy-Conscious Export
```bash
# For external sharing without internal branch/commit info
python3 scripts/generate_eval_report.py --redact-branch --redact-commit
```

---

## 7. File Size Analysis

| Component | Size | Notes |
|-----------|------|-------|
| HTML Structure | ~10KB | Inline CSS, templates |
| Combined Trend PNG | ~30KB | Base64 encoded |
| OCR Trend PNG | ~25KB | Base64 encoded |
| Historical Data | ~2KB | 20 combined + 10 OCR entries |
| **Total** | **~67KB** | Fully self-contained |

**Scalability**: With 100+ history entries, report size may reach ~100-150KB. Consider pagination or external file linking for larger datasets.

---

## 8. Known Limitations

1. **No Real-Time Updates**: Static snapshot, must regenerate for latest data
2. **Large Image Embedding**: Base64 increases file size ~33% vs external images
3. **Table Not Interactive**: No sorting/filtering in Phase 1
4. **Single Branch View**: Shows all branches together (no filtering)
5. **Deprecated API Warnings**: Uses `datetime.utcnow()` (to be fixed)

---

## 9. Security Considerations

- **No User Input**: Report reads JSON files, no injection risk
- **Local File Access Only**: No network requests in Phase 1
- **Redaction Support**: Can hide sensitive info before sharing
- **No Authentication**: Reports are publicly accessible if served

---

## 10. Dependencies

**Required**:
- Python 3.10+
- Standard library (json, base64, datetime, subprocess, pathlib, argparse)

**Optional** (for trend charts):
- matplotlib (already in requirements.txt)
- Agg backend configured for headless environments

---

## 11. Related Commands

| Command | Description |
|---------|-------------|
| `make eval-combined-save` | Save combined evaluation to JSON |
| `make eval-trend` | Generate trend chart PNGs |
| `make eval-report` | Full pipeline (save → chart → HTML) |
| `make health-check` | Quick terminal summary |
| `make ci-combined-check` | CI quality gate with thresholds |

---

## 12. Conclusion

Phase 1 MVP delivers a fully functional, offline-capable HTML report generator. The system provides comprehensive visibility into Vision + OCR combined evaluation metrics with:

- **Zero External Dependencies**: Standalone HTML file
- **Automated Pipeline**: Single `make eval-report` command
- **Visual Insights**: Embedded trend charts and color-coded scores
- **Historical Context**: Timestamped evaluation records
- **Privacy Support**: Optional branch/commit redaction

Future phases will add interactive charting, CI artifact integration, and advanced filtering capabilities.
