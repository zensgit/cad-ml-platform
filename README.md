# ğŸ¤– CAD ML Platform - æ™ºèƒ½CADåˆ†æå¾®æœåŠ¡å¹³å°

## ç›®å½•
- é¡¹ç›®æ¦‚è¿°
- ç³»ç»Ÿæ¶æ„
- å¿«é€Ÿå¼€å§‹
- è¯„ä¼°ä¸å¯è§‚æµ‹æ€§ï¼ˆå¥åº·æ£€æŸ¥ã€æŒ‡æ ‡ã€PromQLï¼‰
- CI & å®‰å…¨å·¥ä½œæµ
- API æ–‡æ¡£
  - æ¥å£è¿ç§»ä¸åºŸå¼ƒç­–ç•¥
  - PromQL ç¤ºä¾‹
  - Runbooks & å‘Šè­¦è§„åˆ™
  - é…ç½®é€ŸæŸ¥è¡¨
  - æ ¸å¿ƒAPIç«¯ç‚¹

> ç‹¬ç«‹çš„ã€å¯æ‰©å±•çš„CADæœºå™¨å­¦ä¹ åˆ†ææœåŠ¡ï¼Œä¸ºå¤šä¸ªç³»ç»Ÿæä¾›ç»Ÿä¸€çš„æ™ºèƒ½åˆ†æèƒ½åŠ›

[![Docker](https://img.shields.io/badge/docker-ready-blue)](https://www.docker.com/)
[![Python](https://img.shields.io/badge/python-3.10+-green)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-orange)](https://fastapi.tiangolo.com/)
[![License](https://img.shields.io/badge/license-proprietary-red)](LICENSE)
[![Evaluation](https://img.shields.io/badge/evaluation-passing-brightgreen)](docs/EVAL_SYSTEM_COMPLETE_GUIDE.md)
[![Integrity](https://img.shields.io/badge/integrity-monitored-blue)](config/eval_frontend.json)

---

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

CAD ML Platform æ˜¯ä¸€ä¸ªå®Œå…¨ç‹¬ç«‹çš„å¾®æœåŠ¡å¹³å°ï¼Œä¸“é—¨ä¸ºCADå›¾çº¸å’Œå·¥ç¨‹å›¾å½¢æä¾›æœºå™¨å­¦ä¹ å¢å¼ºçš„åˆ†ææœåŠ¡ã€‚å®ƒå¯ä»¥æœåŠ¡äºå¤šä¸ªä¸šåŠ¡ç³»ç»Ÿï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼š

- **DedupCAD**: CADå›¾çº¸æŸ¥é‡ç³»ç»Ÿ
- **Stainless Steel Cutting**: ä¸é”ˆé’¢åˆ‡å‰²å·¥è‰ºç³»ç»Ÿ
- **ERPç³»ç»Ÿ**: ä¼ä¸šèµ„æºè§„åˆ’
- **MESç³»ç»Ÿ**: åˆ¶é€ æ‰§è¡Œç³»ç»Ÿ
- **PLMç³»ç»Ÿ**: äº§å“ç”Ÿå‘½å‘¨æœŸç®¡ç†

### æ ¸å¿ƒç‰¹æ€§

- ğŸ” **é›¶ä»¶è¯†åˆ«**: è‡ªåŠ¨è¯†åˆ«8ç§æœºæ¢°é›¶ä»¶ç±»å‹
- ğŸ“Š **ç‰¹å¾æå–**: 95ç»´æ·±åº¦ç‰¹å¾å‘é‡
- ğŸ”„ **æ ¼å¼è½¬æ¢**: æ”¯æŒDXFã€STEPã€IGESç­‰å¤šç§æ ¼å¼
- ğŸ¯ **ç›¸ä¼¼åº¦åˆ†æ**: å‡ ä½•+è¯­ä¹‰åŒé‡åˆ†æ (æ”¯æŒ Top-Kã€ææ–™/å¤æ‚åº¦è¿‡æ»¤ã€å‘é‡ç®¡ç†)
- ğŸ“ˆ **è´¨é‡è¯„ä¼°**: å›¾çº¸è´¨é‡è‡ªåŠ¨è¯„åˆ†
- ğŸ­ **å·¥è‰ºæ¨è**: æ™ºèƒ½åŠ å·¥å·¥è‰ºå»ºè®®
- ğŸ”Œ **å¤šè¯­è¨€SDK**: Pythonã€JavaScriptã€Javaå®¢æˆ·ç«¯
- ğŸš€ **é«˜æ€§èƒ½**: ç¼“å­˜ã€å¹¶å‘ã€åˆ†å¸ƒå¼å¤„ç†

---

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

```mermaid
graph TB
    subgraph "å®¢æˆ·ç«¯ç³»ç»Ÿ"
        A[DedupCAD]
        B[åˆ‡å‰²ç³»ç»Ÿ]
        C[ERPç³»ç»Ÿ]
        D[å…¶ä»–ç³»ç»Ÿ]
    end

    subgraph "CAD ML Platform"
        E[APIç½‘å…³]
        F[åˆ†ææœåŠ¡]
        G[æ¨¡å‹æœåŠ¡]
        H[é€‚é…å™¨]
        I[ç¼“å­˜å±‚]
        J[çŸ¥è¯†åº“]
    end

    A --> E
    B --> E
    C --> E
    D --> E

    E --> F
    E --> G
    F --> H
    F --> I
    G --> J
```

### æŠ€æœ¯æ ˆ

| ç»„ä»¶ | æŠ€æœ¯é€‰å‹ | ç”¨é€” |
|------|---------|------|
| **APIæ¡†æ¶** | FastAPI | é«˜æ€§èƒ½å¼‚æ­¥API |
| **MLæ¡†æ¶** | scikit-learn, TensorFlow | æœºå™¨å­¦ä¹ æ¨¡å‹ |
| **CADå¤„ç†** | ezdxf, FreeCAD | CADæ–‡ä»¶è§£æ |
| **ç¼“å­˜** | Redis | ç»“æœç¼“å­˜ |
| **æ¶ˆæ¯é˜Ÿåˆ—** | RabbitMQ/Kafka | å¼‚æ­¥å¤„ç† |
| **å®¹å™¨åŒ–** | Docker | éƒ¨ç½²æ ‡å‡†åŒ– |
| **ç¼–æ’** | Kubernetes | ç”Ÿäº§ç¯å¢ƒç¼–æ’ |
| **ç›‘æ§** | Prometheus + Grafana | æ€§èƒ½ç›‘æ§ |

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å‰ç½®è¦æ±‚

- Python 3.9+
- Docker 20.10+
- Redis 6.0+ (å¯é€‰)
- CUDA 11.0+ (GPUåŠ é€Ÿï¼Œå¯é€‰)

### å®‰è£…æ­¥éª¤

#### 1. å…‹éš†ä»“åº“

```bash
git clone https://github.com/your-org/cad-ml-platform.git
cd cad-ml-platform
```

#### 2. ç¯å¢ƒé…ç½®

```bash
# åˆ›å»ºPythonè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
pip install -r requirements-dev.txt  # å¼€å‘å·¥å…·ï¼ˆlint/type/type-test/é¢„æäº¤ï¼‰
```

#### 3. é…ç½®æ–‡ä»¶

```bash
# å¤åˆ¶é…ç½®æ¨¡æ¿
cp config/config.example.yaml config/config.yaml

# ç¼–è¾‘é…ç½®
vim config/config.yaml
```

#### 4. å¯åŠ¨æœåŠ¡

**å¼€å‘ç¯å¢ƒ**:
```bash
# ä½¿ç”¨Docker Compose
docker-compose up -d

# æˆ–ç›´æ¥è¿è¡Œ
python src/main.py
```

**ç”Ÿäº§ç¯å¢ƒ**:
```bash
# Kuberneteséƒ¨ç½²
kubectl apply -f deployments/kubernetes/
```

---

## ğŸ”¬ è¯„ä¼°ä¸å¯è§‚æµ‹æ€§

### å®Œæ•´è¯„ä¼°ç³»ç»Ÿ

æˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªä¼ä¸šçº§çš„è¯„ä¼°ç›‘æ§ç³»ç»Ÿï¼Œæä¾›å…¨é¢çš„è´¨é‡ä¿è¯å’Œå¯è§‚æµ‹æ€§ï¼š

#### æ ¸å¿ƒåŠŸèƒ½
- **è”åˆè¯„ä¼°**: Vision + OCR åŠ æƒè¯„åˆ†ç³»ç»Ÿ
- **æ•°æ®å®Œæ•´æ€§**: SHA-384 å“ˆå¸ŒéªŒè¯ï¼ŒSchema v1.0.0 è§„èŒƒ
- **è‡ªåŠ¨æŠ¥å‘Š**: é™æ€/äº¤äº’å¼ HTML æŠ¥å‘Šï¼ŒChart.js å¯è§†åŒ–
- **æ•°æ®ä¿ç•™**: 5å±‚ä¿ç•™ç­–ç•¥ï¼ˆ7å¤©å…¨é‡â†’30å¤©æ¯æ—¥â†’90å¤©æ¯å‘¨â†’365å¤©æ¯æœˆâ†’æ°¸ä¹…å­£åº¦ï¼‰
- **ç‰ˆæœ¬ç›‘æ§**: è‡ªåŠ¨ä¾èµ–æ›´æ–°æ£€æŸ¥ï¼Œå®‰å…¨è­¦æŠ¥
- **CI/CDé›†æˆ**: GitHub Actions è‡ªåŠ¨åŒ–æµæ°´çº¿

#### Grafana Dashboard (CAD Analysis)
æ–°å¢ä»ªè¡¨ç›˜æ–‡ä»¶: `config/grafana/dashboard_cad_analysis_metrics.json`

åŒ…å«é¢æ¿:
- æˆåŠŸç‡: `sum(analysis_requests_total{status='success'}) / sum(analysis_requests_total)`
- è§£æ/ç‰¹å¾æå–é˜¶æ®µå¹³å‡è€—æ—¶ (ms) ä½¿ç”¨ `rate(..._sum)/rate(..._count)`
- é˜¶æ®µè€—æ—¶ p95: `histogram_quantile(0.95, sum by (le, stage)(rate(analysis_stage_duration_seconds_bucket[5m])))`
- å®ä½“æ•°é™åˆ¶æ‹’ç»è®¡æ•°: `analysis_rejections_total{reason='entity_count_exceeded'}`
- ç‰¹å¾å‘é‡ç»´åº¦åˆ†å¸ƒ: `analysis_feature_vector_dimension_bucket`
- é”™è¯¯ç  TopK: `topk(10, rate(analysis_error_code_total[5m]))`
- ææ–™ä½¿ç”¨é€Ÿç‡: `sum by (material)(rate(analysis_material_usage_total[5m]))`

å¯¼å…¥æ­¥éª¤:
1. Grafana UI -> Dashboards -> Import
2. ç²˜è´´ JSON æˆ–é€‰æ‹©æ–‡ä»¶ `dashboard_cad_analysis_metrics.json`
3. é€‰æ‹© Prometheus æ•°æ®æº
4. ä¿å­˜å¹¶è®¾ç½®åˆ·æ–°é—´éš” (æ¨è 30s)

å»ºè®®å‘Šè­¦è§„åˆ™:
- æˆåŠŸç‡ < 90% è¿ç»­ 5m
- p95(parse) > 500ms è¿ç»­ 10m
- é”™è¯¯ç  `INTERNAL_ERROR` rate > 5/min è¿ç»­ 5m
- Rejections spike: `increase(analysis_rejections_total[10m]) > 50`

#### å¿«é€Ÿå¼€å§‹

```bash
# è¿è¡Œè¯„ä¼°
make eval                    # æ‰§è¡Œ Vision+OCR è”åˆè¯„ä¼°

# ç”ŸæˆæŠ¥å‘Š
make eval-report-v2          # ç”Ÿæˆäº¤äº’å¼æŠ¥å‘Šï¼ˆæ¨èï¼‰
make eval-report            # ç”Ÿæˆé™æ€æŠ¥å‘Šï¼ˆå¤‡ç”¨ï¼‰

# ç³»ç»Ÿå¥åº·
make health-check           # å®Œæ•´ç³»ç»Ÿå¥åº·æ£€æŸ¥
make integrity-check        # æ–‡ä»¶å®Œæ•´æ€§éªŒè¯

# æ•°æ®ç®¡ç†
make eval-history           # æŸ¥çœ‹å†å²è¶‹åŠ¿
make eval-retention         # åº”ç”¨ä¿ç•™ç­–ç•¥
```

#### è¯„ä¼°å…¬å¼
```
Combined Score = 0.5 Ã— Vision + 0.5 Ã— OCR_normalized
OCR_normalized = OCR_Recall Ã— (1 - Brier_Score)
```

#### é…ç½®ç®¡ç†
æ‰€æœ‰é…ç½®é›†ä¸­åœ¨ `config/eval_frontend.json`ï¼š
- Chart.js ç‰ˆæœ¬é”å®š (4.4.0)
- SHA-384 å®Œæ•´æ€§æ ¡éªŒ
- 5å±‚æ•°æ®ä¿ç•™ç­–ç•¥
- Schema éªŒè¯è§„åˆ™

#### æµ‹è¯•å¥—ä»¶

```bash
# å•å…ƒæµ‹è¯•å¥—ä»¶
python3 scripts/test_eval_system.py --verbose

# å®Œæ•´é›†æˆæµ‹è¯•
python3 scripts/run_full_integration_test.py
```

è¯¦ç»†æ–‡æ¡£ï¼š[è¯„ä¼°ç³»ç»Ÿå®Œæ•´æŒ‡å—](docs/EVALUATION_SYSTEM_COMPLETE.md)

#### å¥åº·æ£€æŸ¥ä¸æŒ‡æ ‡

- å¥åº·ç«¯ç‚¹ï¼š`GET /health`

---

## ğŸ§© æ–°å¢ä¸æ‰©å±•åŠŸèƒ½æ€»è§ˆ (Recent Additions)

### ğŸ”¢ ç‰¹å¾ç‰ˆæœ¬æšä¸¾ç«¯ç‚¹
`GET /api/v1/features/versions`

è¿”å›æ‰€æœ‰å·²çŸ¥ç‰¹å¾ç‰ˆæœ¬çš„ç»´åº¦ä¸ç¨³å®šæ€§ï¼š
```json
{
  "status": "ok",
  "versions": [
    {"version": "v1", "dimension": 7,  "stable": true,  "experimental": false},
    {"version": "v2", "dimension": 12, "stable": true,  "experimental": false},
    {"version": "v3", "dimension": 23, "stable": true,  "experimental": false},
    {"version": "v4", "dimension": 25, "stable": false, "experimental": true}
  ]
}
```
è¯´æ˜ï¼šv4 ä¸ºå®éªŒç‰ˆæœ¬ (surface_count + shape_entropy)ï¼Œä»…åœ¨æ˜¾å¼æŒ‡å®š `FEATURE_VERSION=v4` æˆ–è¯·æ±‚å‚æ•° `version=v4` æ—¶ç”Ÿæ•ˆã€‚

### ğŸ§ª ç‰¹å¾æ§½ä½æŸ¥è¯¢
`GET /api/v1/features/slots?version=v3`
è¿”å›è¯¥ç‰ˆæœ¬æ‰€æœ‰æ§½ä½åç§°/ç±»åˆ«/ç‰ˆæœ¬æ ‡ç­¾ã€‚å¤±è´¥ç¤ºä¾‹ï¼ˆä¸æ”¯æŒç‰ˆæœ¬ï¼‰ï¼šHTTP 422 + `{ "code":"INPUT_VALIDATION_FAILED", "stage":"feature_slots" }`ã€‚

### ğŸ›¡ï¸ æ¨¡å‹å¥åº·ä¸å®‰å…¨
`GET /api/v1/health/model`
ç¤ºä¾‹å“åº”ï¼š
```json
{
  "status": "ok",
  "version": "v2",
  "hash": "abcd1234ef567890",
  "path": "models/classifier.pkl",
  "loaded": true,
  "loaded_at": 1732464000.123,
  "uptime_seconds": 12.45
}
```

æ¨¡å‹çƒ­é‡è½½å®‰å…¨æµç¨‹ (`POST /api/v1/model/reload`)ï¼š
1. å¤§å°é™åˆ¶æ ¡éªŒ (`MODEL_MAX_MB`)
2. Magic Number / Pickle åè®®éªŒè¯
3. Hash ç™½åå• (`ALLOWED_MODEL_HASHES`)
4. Opcode æ‰«æï¼ˆé˜»æ–­ `GLOBAL` / `STACK_GLOBAL` / `REDUCE`ï¼‰å¯é€šè¿‡ `MODEL_OPCODE_SCAN=0` å…³é—­ï¼›`MODEL_OPCODE_STRICT=1` ä¸ºä¸¥æ ¼æ¨¡å¼
5. æ¥å£éªŒè¯ï¼ˆå¿…é¡»å­˜åœ¨ `predict` æ–¹æ³•ï¼‰
6. å¤±è´¥å›æ»šï¼ˆä¸€çº§/äºŒçº§ï¼‰

å®‰å…¨å¤±è´¥æŒ‡æ ‡ï¼š`model_security_fail_total{reason="magic_number_invalid|hash_mismatch|opcode_blocked|opcode_scan_error|forged_file"}`ã€‚

### ğŸ“¦ æ‰¹é‡ç›¸ä¼¼åº¦æŸ¥è¯¢
`POST /api/v1/vectors/similarity/batch`
è¯·æ±‚ä½“ï¼š
```json
{
  "ids": ["vecA","vecB"],
  "top_k": 5,
  "material": "steel",
  "complexity": "high",
  "format": "dxf",
  "min_score": 0.4
}
```
é™åˆ¶ï¼šæœ€å¤§ ID æ•°é‡ `BATCH_SIMILARITY_MAX_IDS` (é»˜è®¤ 200)ï¼Œè¶…è¿‡è¿”å› 422ï¼š
```json
{"code":"INPUT_VALIDATION_FAILED","stage":"batch_similarity","message":"Batch size exceeds limit","batch_size":350,"max_batch":200}
```
æŒ‡æ ‡ï¼š`vector_query_batch_latency_seconds{batch_size_range="small|medium|large"}`ï¼Œ`analysis_rejections_total{reason="batch_too_large"}`ï¼Œ`analysis_rejections_total{reason="batch_empty_results"}`ã€‚

### ğŸ”„ å‘é‡è¿ç§»æ‘˜è¦
`GET /api/v1/vectors/migrate/summary`
ç¤ºä¾‹ï¼š
```json
{
  "counts": {"migrated": 30, "dry_run": 5, "downgraded": 2, "error": 1, "not_found": 3, "skipped": 8},
  "total_migrations": 49,
  "history_size": 10,
  "statuses": ["dry_run","downgraded","error","migrated","not_found","skipped"]
}
```
æŒ‡æ ‡ï¼š`vector_migrate_total{status="migrated|dry_run|downgraded|error|not_found|skipped"}`ã€‚

### ğŸŒŠ Drift åŸºçº¿ç›‘æ§ä¸è‡ªåŠ¨åˆ·æ–°
ç«¯ç‚¹ï¼š`/api/v1/analyze/drift`ã€`/api/v1/analyze/drift/baseline/status`ã€`/api/v1/analyze/drift/reset`
è‡ªåŠ¨åˆ·æ–°ï¼šåŸºçº¿å¹´é¾„è¶…å‡º `DRIFT_BASELINE_MAX_AGE_SECONDS` ä¸”æ ·æœ¬æ•° â‰¥ `DRIFT_BASELINE_MIN_COUNT` æ—¶è½¯åˆ·æ–°å¹¶è®°å½• `drift_baseline_refresh_total{trigger="stale"}`ã€‚
å¯åŠ¨é¦–æ¬¡è®¿é—®æ ‡è®°ï¼š`drift_baseline_refresh_total{trigger="startup"}`ã€‚
æ‰‹åŠ¨é‡ç½®ï¼š`drift_baseline_refresh_total{trigger="manual"}`ã€‚

### ğŸ§ª æ–°å¢æŒ‡æ ‡ (Recent Metrics)
| åç§° | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| feature_extraction_latency_seconds{version} | Histogram | æŒ‰ç‰ˆæœ¬ç‰¹å¾æå–å»¶è¿Ÿ |
| vector_query_batch_latency_seconds{batch_size_range} | Histogram | æ‰¹é‡ç›¸ä¼¼åº¦å»¶è¿Ÿ |
| model_security_fail_total{reason} | Counter | æ¨¡å‹å®‰å…¨æ ¡éªŒå¤±è´¥åŸå›  |
| model_health_checks_total{status} | Counter | æ¨¡å‹å¥åº·ç«¯ç‚¹è®¿é—®ç»Ÿè®¡ |
| vector_store_reload_total{status} | Counter | å‘é‡åç«¯é‡è½½ç»“æœ |
| drift_baseline_refresh_total{type,trigger} | Counter | Drift åŸºçº¿åˆ·æ–°äº‹ä»¶ |
| vector_migrate_dimension_delta | Histogram | è¿ç§»ç»´åº¦å·® (æ–°ç»´åº¦-æ—§ç»´åº¦) åˆ†å¸ƒç›‘æ§ |
| similarity_degraded_total{event} | Counter | Faiss é™çº§ä¸æ¢å¤äº‹ä»¶ (degraded|restored) |

PromQL ç¤ºä¾‹ï¼š
```promql
histogram_quantile(0.95, sum by (le,version)(rate(feature_extraction_latency_seconds_bucket[5m])))
histogram_quantile(0.99, sum by (le)(rate(vector_query_batch_latency_seconds_bucket[5m])))
sum(rate(vector_migrate_total{status="migrated"}[10m])) / sum(rate(vector_migrate_total[10m]))
baseline_material_age_seconds > bool DRIFT_BASELINE_MAX_AGE_SECONDS
```

### ğŸ§· ç»“æ„åŒ– 410 åºŸå¼ƒç«¯ç‚¹é”™è¯¯
```json
{
  "code": "GONE",
  "stage": "routing",
  "message": "Endpoint moved. Please use GET /api/v1/vectors_stats/distribution",
  "deprecated_path": "/api/v1/analyze/vectors/distribution",
  "new_path": "/api/v1/vectors_stats/distribution",
  "method": "GET",
  "migration_date": "2024-11-24"
}
```

### ğŸ§¨ é”™è¯¯å“åº”ç»Ÿä¸€æ ¼å¼
å­—æ®µï¼š`code`, `stage`, `message` (+ä¸Šä¸‹æ–‡é”®)ã€‚å¸¸è§ stageï¼š`routing`/`batch_similarity`/`vector_migrate`/`feature_slots`/`model_reload`/`security`/`drift`ã€‚

### ğŸ›  æ–°å¢ç¯å¢ƒå˜é‡
| å˜é‡ | ç”¨é€” | é»˜è®¤ |
|------|------|------|
| FEATURE_VERSION | é»˜è®¤ç‰¹å¾ç‰ˆæœ¬ | v1 |
| BATCH_SIMILARITY_MAX_IDS | æ‰¹é‡ç›¸ä¼¼åº¦æœ€å¤§IDæ•° | 200 |
| MODEL_MAX_MB | æ¨¡å‹æ–‡ä»¶å¤§å°ä¸Šé™(MB) | 50 |
| ALLOWED_MODEL_HASHES | æ¨¡å‹å“ˆå¸Œç™½åå• | ç©º |
| MODEL_OPCODE_SCAN | æ˜¯å¦æ‰§è¡Œ opcode å®‰å…¨æ‰«æ | 1 |
| MODEL_OPCODE_STRICT | æ‰«æå¼‚å¸¸æ˜¯å¦é˜»æ–­ | 0 |
| DRIFT_BASELINE_MIN_COUNT | Drift åŸºçº¿æœ€å°æ ·æœ¬æ•° | 100 |
| DRIFT_BASELINE_MAX_AGE_SECONDS | Drift åŸºçº¿æœ€å¤§å¹´é¾„ | 86400 |
| DRIFT_BASELINE_AUTO_REFRESH | æ˜¯å¦è‡ªåŠ¨åˆ·æ–°è¿‡æœŸåŸºçº¿ | 1 |

### ğŸ” å®‰å…¨å»ºè®®
- ç”Ÿäº§ç¯å¢ƒé…ç½®å¹¶æ”¶æ•› `ALLOWED_MODEL_HASHES`ã€‚
- é«˜å®‰å…¨è¦æ±‚å¯ç”¨ `MODEL_OPCODE_STRICT=1`ã€‚
- ç›‘æ§ `model_security_fail_total` å¼‚å¸¸å¢é•¿ï¼ˆå¯èƒ½è¡¨ç¤ºä¾›åº”é“¾æˆ–æ–‡ä»¶æŠ•æ¯’ï¼‰ã€‚

### ğŸ“Œ Roadmap æ‘˜è¦
- v4 ç‰¹å¾çœŸå®åŒ–ï¼šç²¾ç»† surface_countã€ç†µè®¡ç®—ä¼˜åŒ–ã€‚
- è‡ªé€‚åº”ç¼“å­˜è°ƒä¼˜ç«¯ç‚¹ï¼šæ¨èå®¹é‡/TTLã€‚
- Opcode ç™½åå•æ¨¡å¼å¼ºåŒ–ã€‚
- æ‰¹é‡ç›¸ä¼¼åº¦å¹¶è¡ŒåŠ é€Ÿä¸ savings æŒ‡æ ‡ã€‚

---
  - `runtime.metrics_enabled`: Prometheus å¯¼å‡ºæ˜¯å¦å¯ç”¨
  - `runtime.python_version`: è¿è¡Œ Python ç‰ˆæœ¬
  - `runtime.vision_max_base64_bytes`: Vision Base64 è¾“å…¥å¤§å°ä¸Šé™ï¼ˆå­—èŠ‚ï¼‰
  - `runtime.error_rate_ema.ocr|vision`: OCR/Vision é”™è¯¯ç‡çš„æŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼ˆ0..1ï¼‰
  - `runtime.config.error_ema_alpha`: EMA å¹³æ»‘ç³»æ•°ï¼Œç¯å¢ƒå˜é‡ `ERROR_EMA_ALPHA` å¯é…ç½®

- å…³é”®æŒ‡æ ‡ï¼ˆéƒ¨åˆ†ï¼‰ï¼š
  - `vision_requests_total{provider,status}`ã€`vision_errors_total{provider,code}`
  - `vision_processing_duration_seconds{provider}`
  - `vision_input_rejected_total{reason}`ã€`vision_image_size_bytes`
  - `ocr_requests_total{provider,status}`ã€`ocr_errors_total{provider,code,stage}`
  - `ocr_input_rejected_total{reason}`ã€`ocr_image_size_bytes`
    - å¸¸è§ OCR `reason`ï¼š`invalid_mime`ã€`file_too_large`ã€`pdf_pages_exceed`ã€`pdf_forbidden_token`
  - `ocr_confidence_ema`ã€`ocr_confidence_fallback_threshold`

ç»Ÿä¸€é”™è¯¯æ¨¡å‹ï¼šæ‰€æœ‰é”™è¯¯ä»¥ HTTP 200 è¿”å› `{ success: false, code: ErrorCode, error: string }`ã€‚

ç¤ºä¾‹ï¼ˆè¾“å…¥è¿‡å¤§ï¼‰ï¼š
```bash
curl -s http://localhost:8000/api/v1/vision/analyze \
  -H 'Content-Type: application/json' \
  -d '{"image_base64": "<very_large>", "include_description": false}' | jq
```

### CI & å®‰å…¨å·¥ä½œæµ

```yaml
å…³é”®å·¥ä½œæµï¼š
- `.github/workflows/ci.yml` åˆ†ç¦» `lint-type` ä¸æµ‹è¯•çŸ©é˜µ (3.10/3.11)
- `.github/workflows/security-check.yml` æ¯å‘¨å®‰å…¨å®¡è®¡ï¼ˆåŸºäº `scripts/security_audit.py` é€€å‡ºç ï¼‰
- `.github/workflows/badge-review.yml` æ¯æœˆè‡ªåŠ¨é˜ˆå€¼åˆ†æä¸å»ºè®® Issue
 - æ–°å¢éé˜»æ–­ `lint-all-report`ï¼Œä¸Šä¼ å…¨ä»“ flake8 æŠ¥å‘Šå·¥ä»¶
```

---

## ğŸ“š APIæ–‡æ¡£

### ğŸ”„ æ¥å£è¿ç§»ä¸åºŸå¼ƒç­–ç•¥

ä¸ºæå‡ç³»ç»Ÿå¯ç»´æŠ¤æ€§ï¼Œéƒ¨åˆ†ç«¯ç‚¹å·²è¿ç§»åˆ°æ–°è·¯å¾„ã€‚æ—§ç«¯ç‚¹è¿”å› **HTTP 410 Gone** çŠ¶æ€ç ï¼Œå¹¶æä¾›ç»“æ„åŒ–è¿ç§»ä¿¡æ¯ã€‚

#### åºŸå¼ƒç«¯ç‚¹åˆ—è¡¨

| åºŸå¼ƒç«¯ç‚¹ (æ—§è·¯å¾„) | æ–°ç«¯ç‚¹è·¯å¾„ | HTTPæ–¹æ³• | è¿ç§»æ—¥æœŸ | çŠ¶æ€ç  |
|------------------|-----------|---------|---------|--------|
| `/api/v1/analyze/vectors/distribution` | `/api/v1/vectors_stats/distribution` | GET | 2024-11-24 | 410 |
| `/api/v1/analyze/vectors/delete` | `/api/v1/vectors` (DELETEæ–¹æ³•) | POST | 2024-11-24 | 410 |
| `/api/v1/analyze/vectors` | `/api/v1/vectors` | GET | 2024-11-24 | 410 |
| `/api/v1/analyze/vectors/stats` | `/api/v1/vectors_stats/summary` | GET | 2024-11-24 | 410 |
| `/api/v1/analyze/features/diff` | `/api/v1/features/diff` | GET | 2024-11-24 | 410 |
| `/api/v1/analyze/model/reload` | `/api/v1/model/reload` | POST | 2024-11-24 | 410 |
| `/api/v1/analyze/features/cache` | `/api/v1/maintenance/stats` | GET | 2024-11-24 | 410 |
| `/api/v1/analyze/faiss/health` | `/api/v1/health/faiss` | GET | 2024-11-24 | 410 |

#### é”™è¯¯å“åº”æ ¼å¼

åºŸå¼ƒç«¯ç‚¹è¿”å›ç»Ÿä¸€çš„ç»“æ„åŒ–é”™è¯¯ï¼š

```json
{
  "detail": {
    "code": "GONE",
    "message": "Endpoint moved. Please use GET /api/v1/vectors_stats/distribution",
    "stage": "routing",
    "deprecated_path": "/api/v1/analyze/vectors/distribution",
    "new_path": "/api/v1/vectors_stats/distribution",
    "method": "GET",
    "migration_date": "2024-11-24"
  }
}
```

**é”™è¯¯ç è¯´æ˜**ï¼š
- `GONE`ï¼šèµ„æºå·²æ°¸ä¹…ç§»é™¤ï¼ˆå¯¹åº” HTTP 410ï¼‰
- `severity`: INFO çº§åˆ«ï¼ˆéé”™è¯¯ï¼Œè€Œæ˜¯æç¤ºè¿ç§»ï¼‰

#### è¿ç§»æŒ‡å—

1. **ç«‹å³è¡ŒåŠ¨**ï¼šæ›´æ–°å®¢æˆ·ç«¯ä»£ç ä½¿ç”¨æ–°ç«¯ç‚¹è·¯å¾„
2. **åŒå†™éªŒè¯**ï¼šè¿ç§»åå¯æš‚æ—¶å¹¶è¡Œè°ƒç”¨æ–°æ—§ç«¯ç‚¹æ¯”å¯¹å“åº”ï¼ˆæ—§ç«¯ç‚¹ä»…è¿”å›410å…ƒæ•°æ®ï¼‰
3. **ç›‘æ§è¿ç§»**ï¼šä½¿ç”¨ PromQL ç›‘æ§ `rate(analysis_error_code_total{code="GONE"}[5m])` ä¸‹é™è¶‹åŠ¿ï¼Œåˆ¤æ–­è¿ç§»å®Œæˆåº¦ã€‚

### ğŸ§© æ¨¡å—ç»“æ„ä¸ç‰¹å¾ç‰ˆæœ¬è¿ç§»

ä¸»è¦APIæ¨¡å— (src/api/v1)ï¼š

| æ¨¡å— | åŠŸèƒ½ |
|------|------|
| analyze.py | ä¿ç•™åºŸå¼ƒç«¯ç‚¹çš„410ç»“æ„åŒ–æç¤º |
| vectors.py | å‘é‡ CRUD / æ›´æ–° / è¿ç§» / æ‰¹é‡ç›¸ä¼¼åº¦ |
| vectors_stats.py | å‘é‡ç»Ÿè®¡ä¸åˆ†å¸ƒæŸ¥è¯¢ |
| features.py | ç‰¹å¾å·®å¼‚æ¯”è¾ƒ / æ§½ä½æšä¸¾ `/features/slots` |
| drift.py | æ¼‚ç§»åŸºçº¿ä¸è‡ªåŠ¨åˆ·æ–°æ§åˆ¶ |
| model.py | æ¨¡å‹çƒ­åŠ è½½ä¸ç‰ˆæœ¬/å“ˆå¸ŒæŸ¥è¯¢ã€å®‰å…¨æ ¡éªŒ |
| maintenance.py | å­¤å„¿å‘é‡æ¸…ç† / ç¼“å­˜ç®¡ç† / ç³»ç»Ÿç»´æŠ¤ç»Ÿè®¡ |
| process.py | å·¥è‰ºè§„åˆ™å®¡è®¡ä¸ç‰ˆæœ¬æŒ‡æ ‡ |
| health.py | Faiss / feature cache å¥åº·çŠ¶æ€ |

ç‰¹å¾ç‰ˆæœ¬ (Feature Version) æ¼”è¿›ï¼š

| ç‰ˆæœ¬ | æ–°å¢æ§½ä½ | æè¿° |
|------|---------|------|
| v1 | åŸºç¡€7æ§½ä½ | å®ä½“è®¡æ•° + bboxå°ºå¯¸/ä½“ç§¯ + å›¾å±‚/å¤æ‚åº¦æ ‡å¿— |
| v2 | 5æ§½ä½ | å½’ä¸€åŒ–å®½é«˜æ·± + å®½é«˜æ¯” + å®½æ·±æ¯” |
| v3 | 11æ§½ä½ | å‡ ä½•å¢å¼º (solids/facets/æ¯”ç‡/å¹³å‡ä½“ç§¯) + Top5å®ä½“ç±»å‹é¢‘ç‡ |
| v4 | 2æ§½ä½ | surface_countï¼ˆçœŸå®å‡ ä½•é¢æ•°ä¼°è®¡ï¼‰+ shape_entropyï¼ˆæ‹‰æ™®æ‹‰æ–¯å¹³æ»‘å¹¶å½’ä¸€åŒ–è‡³[0,1]ï¼‰ |

è¿ç§»ç«¯ç‚¹ï¼š`POST /api/v1/vectors/migrate`

> v4 ç°å·²å®ç°çœŸå®ç‰¹å¾ï¼š`surface_count` ä¸ `shape_entropy`ï¼ˆæ‹‰æ™®æ‹‰æ–¯å¹³æ»‘å¹¶å½’ä¸€åŒ–ï¼‰ã€‚ä»å»ºè®®åœ¨å……åˆ†è¯„ä¼°åå†è®¾ä¸ºé»˜è®¤ï¼›è®¾ç½® `FEATURE_VERSION=v4` æˆ–è¿ç§»åˆ° `to_version="v4"` å°†è¿½åŠ è¿™ä¸¤ä¸ªæ§½ä½ã€‚

è¯·æ±‚ç¤ºä¾‹ï¼ˆå¹²è¿è¡Œ dry_runï¼‰ï¼š
```bash
curl -X POST /api/v1/vectors/migrate \
  -H 'Content-Type: application/json' \
  -H 'x-api-key: test' \
  -d '{"ids":["id1","id2"],"to_version":"v3","dry_run":true}'
```

å“åº”ç¤ºä¾‹ï¼š
```json
{
  "total": 2,
  "migrated": 0,
  "skipped": 1,
  "items": [
    {"id": "id1", "status": "dry_run", "from_version": "v1", "to_version": "v3", "dimension_before": 7, "dimension_after": 23},
    {"id": "id2", "status": "skipped", "from_version": "v3", "to_version": "v3"}
  ],
  "migration_id": "...",
  "started_at": "...",
  "finished_at": "...",
  "dry_run_total": 1
}
```

ç‰¹å¾ç»´åº¦å¯¹ç…§ï¼š

| ç‰ˆæœ¬ | æ€»ç»´åº¦ (geometric+semantic) |
|------|---------------------------|
| v1 | 7 |
| v2 | 12 |
| v3 | 23 |
| v4 | 24 |

é™çº§ä¸è¿ç§»çŠ¶æ€è¯´æ˜ï¼š
- `migrated`: ç‰ˆæœ¬æå‡æˆ–åŒå‘è°ƒæ•´
- `skipped`: å·²æ˜¯ç›®æ ‡ç‰ˆæœ¬
- `dry_run`: æ¨¡æ‹Ÿè¿ç§»ä¸å†™å…¥
- `downgraded`: ç›®æ ‡ç‰ˆæœ¬ä½äºæºç‰ˆæœ¬ï¼ˆä¿ç•™å‘åå…¼å®¹ï¼‰
- `error`: è½¬æ¢å¼‚å¸¸ï¼ˆé•¿åº¦ä¸åŒ¹é…ç­‰ï¼‰
- `not_found`: å‘é‡IDä¸å­˜åœ¨


å‡çº§ç­–ç•¥ï¼ˆæ— åŸå§‹æ–‡æ¡£æ—¶ `upgrade_vector` è¡Œä¸ºï¼‰ï¼š
- v1â†’v2: è¿½åŠ 5ä¸ªå½’ä¸€åŒ–ä¸æ¯”ç‡æ§½ä½ï¼ˆ0å¡«å……ï¼‰
- v1â†’v3: è¿½åŠ  v2 æ§½ä½ + 11 ä¸ªå¢å¼ºæ§½ä½ï¼ˆ0å¡«å……ï¼‰
- v2â†’v3: è¿½åŠ  11 ä¸ªå¢å¼ºæ§½ä½ï¼ˆ0å¡«å……ï¼‰
- v3â†’v2: æˆªæ–­ v3 æ‰©å±•æ§½ä½ï¼ˆå¯èƒ½ä¸¢å¤±ä¿¡æ¯ï¼‰

æŒ‡æ ‡ï¼š
- `vector_migrate_total{status="migrated|skipped|dry_run|error|not_found"}`
  - ç°å·²æ‰©å±•æ”¯æŒ `downgraded` çŠ¶æ€ï¼Œç”¨äºç‰ˆæœ¬é™çº§ï¼ˆä¾‹å¦‚ v3 -> v2 æˆ– v2 -> v1ï¼‰ã€‚
    ç›‘æ§ç¤ºä¾‹ï¼š`sum(rate(vector_migrate_total{status="downgraded"}[5m]))` è¯„ä¼°é™çº§é¢‘ç‡ã€‚
- å¹²è¿è¡Œæ¯”ç‡ï¼š`rate(vector_migrate_total{status="dry_run"}[5m]) / rate(vector_migrate_total[5m])`
- å†å²è®°å½•æ‰©å±•å­—æ®µ `counts`ï¼ˆè§å“åº”ç¤ºä¾‹ï¼‰æä¾›å„çŠ¶æ€ç²¾ç»†ç»Ÿè®¡ï¼š`migrated|skipped|dry_run|downgraded|error|not_found`

PromQL p95 æ‰¹é‡ç›¸ä¼¼åº¦å»¶è¿Ÿï¼š
```promql
histogram_quantile(0.95, sum by (le, batch_size_range)(rate(vector_query_batch_latency_seconds_bucket[5m])))
```

### æ¨¡å‹å¥åº·ç«¯ç‚¹

`GET /api/v1/health/model` æä¾›å½“å‰æ¨¡å‹åŠ è½½çŠ¶æ€ä¸å…ƒæ•°æ®ï¼ŒåŒ…æ‹¬å›æ»šçŠ¶æ€å’Œé”™è¯¯è¿½è¸ªã€‚

**å“åº”å­—æ®µè¯´æ˜:**

| å­—æ®µ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `status` | string | å¥åº·çŠ¶æ€: `ok` (æ­£å¸¸), `absent` (æœªåŠ è½½), `rollback` (å·²å›æ»š), `error` (é”™è¯¯) |
| `version` | string | æ¨¡å‹ç‰ˆæœ¬å· |
| `hash` | string | æ¨¡å‹æ–‡ä»¶ SHA256 å“ˆå¸Œå€¼ (å‰16ä½) |
| `path` | string | æ¨¡å‹æ–‡ä»¶è·¯å¾„ |
| `loaded` | boolean | æ˜¯å¦å·²åŠ è½½ |
| `loaded_at` | float | åŠ è½½æ—¶é—´æˆ³ (Unixæ—¶é—´) |
| `uptime_seconds` | float | æ¨¡å‹è¿è¡Œæ—¶é•¿ï¼ˆç§’ï¼‰ |
| `rollback_level` | int | å›æ»šçº§åˆ«: `0` (æ— å›æ»š), `1` (ä¸€çº§å›æ»š), `2` (äºŒçº§å›æ»š) |
| `rollback_reason` | string\|null | å›æ»šåŸå› æè¿° |
| `last_error` | string\|null | æœ€è¿‘ä¸€æ¬¡åŠ è½½é”™è¯¯ä¿¡æ¯ |
| `load_seq` | int | å•è°ƒé€’å¢çš„åŠ è½½åºåˆ—å·ï¼ˆç”¨äºåŒºåˆ†ä¸åŒåŠ è½½å®ä¾‹ï¼‰ |

**ç¤ºä¾‹å“åº” - æ­£å¸¸çŠ¶æ€:**
```json
{
  "status": "ok",
  "version": "v2.1.0",
  "hash": "abcd1234ef567890",
  "path": "models/classifier_v2.1.pkl",
  "loaded": true,
  "loaded_at": 1732464000.123,
  "uptime_seconds": 3600.5,
  "rollback_level": 0,
  "rollback_reason": null,
  "last_error": null,
  "load_seq": 5
}
```

**ç¤ºä¾‹å“åº” - å›æ»šçŠ¶æ€:**
```json
{
  "status": "rollback",
  "version": "v2.0.0",
  "hash": "def567890abc1234",
  "path": "models/classifier_v2.0.pkl",
  "loaded": true,
  "loaded_at": 1732464100.456,
  "uptime_seconds": 300.2,
  "rollback_level": 1,
  "rollback_reason": "Rolled back to previous model after reload failure",
  "last_error": "Security validation failed: disallowed pickle opcode REDUCE detected",
  "load_seq": 4
}
```

**ç¤ºä¾‹å“åº” - äºŒçº§å›æ»šçŠ¶æ€:**
```json
{
  "status": "rollback",
  "version": "v1.9.0",
  "hash": "ghi789012def3456",
  "path": "models/classifier_v1.9.pkl",
  "loaded": true,
  "loaded_at": 1732463800.789,
  "uptime_seconds": 600.8,
  "rollback_level": 2,
  "rollback_reason": "Rolled back to level 2 snapshot after consecutive failures",
  "last_error": "Model missing predict method",
  "load_seq": 3
}
```

**å›æ»šæœºåˆ¶:**
- ç³»ç»Ÿç»´æŠ¤3ä¸ªæ¨¡å‹å¿«ç…§ï¼šå½“å‰ã€å‰ä¸€ç‰ˆæœ¬(_PREV)ã€å‰ä¸¤ç‰ˆæœ¬(_PREV2)
- å½“æ¨¡å‹é‡è½½å¤±è´¥æ—¶ï¼Œè‡ªåŠ¨å›æ»šåˆ°å‰ä¸€å¯ç”¨ç‰ˆæœ¬
- è¿ç»­å¤±è´¥å¯å›æ»šåˆ°äºŒçº§å¿«ç…§ï¼ˆrollback_level=2ï¼‰
- å›æ»šå `status` å˜ä¸º `"rollback"`ï¼Œ`last_error` ä¿ç•™å¤±è´¥ä¿¡æ¯
- `load_seq` åœ¨å›æ»šæ—¶ä¿æŒä¸å˜ï¼ˆä¿ç•™æˆåŠŸåŠ è½½æ—¶çš„åºåˆ—å·ï¼‰

**æŒ‡æ ‡:** `model_health_checks_total{status="ok|absent|rollback|error"}`

### æ‰¹é‡ç›¸ä¼¼åº¦æŸ¥è¯¢é™åˆ¶

ç¯å¢ƒå˜é‡ `BATCH_SIMILARITY_MAX_IDS` æ§åˆ¶å•æ¬¡æ‰¹é‡æŸ¥è¯¢æœ€å¤§ ID æ•°ï¼ˆé»˜è®¤ 200ï¼‰ã€‚
è¶…è¿‡é™åˆ¶è¿”å› 422ï¼š
```json
{
  "code": "INPUT_VALIDATION_FAILED",
  "stage": "batch_similarity",
  "message": "Batch size exceeds limit",
  "batch_size": 350,
  "max_batch": 200
}
```
æ‹’ç»è®¡æ•°ï¼š`analysis_rejections_total{reason="batch_too_large"}`ã€‚

ç‰¹å¾æ§½ä½æšä¸¾ï¼š
```bash
curl /api/v1/features/slots?version=v3 -H 'x-api-key: test'
```
ç¤ºä¾‹å“åº”ï¼š
```json
{
  "version": "v3",
  "status": "ok",
  "slots": [
    {"name": "entity_count", "category": "geometric", "version": "v1"},
    {"name": "bbox_width", "category": "geometric", "version": "v1"},
    {"name": "norm_width", "category": "geometric", "version": "v2"},
    {"name": "solids_count", "category": "geometric", "version": "v3"}
  ]
}
```
2. **å…¼å®¹æœŸ**ï¼šåºŸå¼ƒç«¯ç‚¹å°†ä¿æŒ410å“åº”è‡³å°‘6ä¸ªæœˆ
3. **ç›‘æ§**ï¼šé€šè¿‡ Prometheus æŒ‡æ ‡ `http_410_responses_total` ç›‘æ§æ—§ç«¯ç‚¹ä½¿ç”¨æƒ…å†µ
4. **æµ‹è¯•è¦†ç›–**ï¼šæ‰€æœ‰åºŸå¼ƒç«¯ç‚¹å‡æœ‰å®Œæ•´çš„æµ‹è¯•è¦†ç›–ï¼ˆè§ `tests/unit/test_deprecated_endpoints_410.py`ï¼‰

---

### ğŸ“ˆ PromQL ç¤ºä¾‹ï¼ˆå¯ç›´æ¥ç”¨äº Grafanaï¼‰

- Vision è¾“å…¥æ‹’ç»å æ¯”ï¼ˆ5åˆ†é’Ÿçª—ï¼‰ï¼š
  - sum(rate(vision_input_rejected_total[5m])) / sum(rate(vision_requests_total[5m]))

- Vision å›¾åƒå¤§å° P99ï¼ˆ5åˆ†é’Ÿçª—ï¼‰ï¼š
  - histogram_quantile(0.99, rate(vision_image_size_bytes_bucket[5m]))

- OCR Provider Down é€Ÿç‡ï¼ˆæ¯æä¾›å•†ï¼‰ï¼š
  - sum by (provider) (rate(ocr_errors_total{code="provider_down"}[5m]))

- é”™è¯¯ç‡ EMAï¼š
  - vision_error_rate_ema
  - ocr_error_rate_ema

Grafana é¢æ¿ç¤ºä¾‹ï¼šè§ `docs/grafana/observability_dashboard.json`ï¼ˆå¯¼å…¥åˆ° Grafana å³å¯ï¼‰ã€‚

### ğŸ“Ÿ Runbooks & Alerts

- Prometheus å‘Šè­¦è§„åˆ™æ ·ä¾‹ï¼š`docs/ALERT_RULES.md`
- è¿è¡Œæ‰‹å†Œï¼ˆæ’éšœæŒ‡å—ï¼‰ï¼š
  - é”™è¯¯ç‡ EMA å‡é«˜ï¼š`docs/runbooks/ocr_vision_error_rate_ema.md`
  - è¾“å…¥æ‹’ç»æ¿€å¢ï¼š`docs/runbooks/input_rejections_spike.md`
  - Provider å®•æœºï¼š`docs/runbooks/provider_down.md`
  - ç†”æ–­å™¨æ‰“å¼€ï¼š`docs/runbooks/circuit_open.md`

### âš™ï¸ é…ç½®é€ŸæŸ¥è¡¨ï¼ˆ.envï¼‰

- `VISION_MAX_BASE64_BYTES`ï¼šVision Base64 è¾“å…¥å¤§å°ä¸Šé™ï¼ˆå­—èŠ‚ï¼Œé»˜è®¤ 1048576ï¼‰ã€‚
- `ERROR_EMA_ALPHA`ï¼šé”™è¯¯ç‡ EMA å¹³æ»‘å› å­ï¼ˆ0<alpha<=1ï¼Œé»˜è®¤ 0.2ï¼‰ã€‚
- `OCR_MAX_PDF_PAGES`ï¼šOCR PDF æœ€å¤§é¡µæ•°ï¼ˆé»˜è®¤ 20ï¼‰ã€‚
- `OCR_MAX_FILE_MB`ï¼šOCR ä¸Šä¼ æ–‡ä»¶å¤§å°ä¸Šé™ï¼ˆMBï¼Œé»˜è®¤ 50ï¼‰ã€‚

### åŸºç¡€ç«¯ç‚¹

æœåŠ¡å¯åŠ¨åï¼Œè®¿é—®ä»¥ä¸‹åœ°å€æŸ¥çœ‹äº¤äº’å¼APIæ–‡æ¡£ï¼š

- Swagger UI: `http://localhost:8000/docs`
- ReDoc: `http://localhost:8000/redoc`

### æ ¸å¿ƒAPI

#### 1. åˆ†æCADæ–‡ä»¶

```http
POST /api/v1/analyze
Content-Type: multipart/form-data

file: (binary)
options: {
  "extract_features": true,
  "classify_parts": true,
  "calculate_similarity": false
}
```

**å“åº”ç¤ºä¾‹**:
```json
{
  "id": "analysis_123456",
  "timestamp": "2025-11-12T10:30:00Z",
  "file_name": "demo.dxf",
  "file_format": "DXF",
  "results": {
    "features": {
      "geometric": [12, 100.0, 50.0, 5.0, 25000.0],
      "semantic": [3, 0],
      "dimension": 7
    },
    "classification": {
      "part_type": "moderate_component",
      "confidence": 0.6,
      "characteristics": ["entities:12", "layers:3", "volume_estimate:25000.00"]
    },
    "quality": {"score": 0.95, "issues": [], "suggestions": []},
    "process": {
      "recommended_process": "cnc_machining",
      "alternatives": ["casting"],
      "parameters": {"est_volume": 25000.0, "entity_count": 12, "complexity": "medium", "material": "steel"}
    },
    "statistics": {"entity_count": 12, "layer_count": 3, "complexity": "medium"}
  },
  "cad_document": {
    "format": "dxf",
    "entity_count": 12,
    "layers": {"LAYER1": 5, "LAYER2": 7},
    "bounding_box": {"min_x": 0.0, "min_y": 0.0, "min_z": 0.0, "max_x": 100.0, "max_y": 50.0, "max_z": 5.0},
    "complexity": "medium",
    "metadata": {"material": "steel"}
  }
}
```

#### 2. æ‰¹é‡ç›¸ä¼¼åº¦åˆ†æ

```http
POST /api/v1/similarity/batch
Content-Type: application/json

{
  "reference_id": "cad_001",
  "candidates": ["cad_002", "cad_003", "cad_004"],
  "threshold": 0.75
}
```

### Vision é”™è¯¯å“åº”è§„èŒƒ
æ‰€æœ‰ Vision åˆ†æè¯·æ±‚æ— è®ºæˆåŠŸæˆ–å¤±è´¥è¿”å› HTTP 200ï¼š
```json
{
  "success": false,
  "provider": "deepseek_stub",
  "processing_time_ms": 5.1,
  "error": "Image too large (1.20MB) via base64. Max 1.00MB.",
  "code": "INPUT_ERROR"
}
```
`code` å¯èƒ½å–å€¼ï¼š`INPUT_ERROR`ï¼ˆè¾“å…¥æ ¡éªŒå¤±è´¥ï¼‰ã€`INTERNAL_ERROR`ï¼ˆå†…éƒ¨å¼‚å¸¸ï¼‰ã€‚

### CAD åˆ†æé”™è¯¯å“åº”ç»“æ„ (ç»Ÿä¸€é”™è¯¯ç é›†æˆ)

é”™è¯¯æ—¶è¿”å›æ ‡å‡†ç»“æ„ï¼ˆHTTP çŠ¶æ€ç æŒ‡ç¤ºåˆ†ç±»ï¼‰ï¼š
```json
{
  "detail": {
    "code": "INPUT_SIZE_EXCEEDED",
    "source": "input",
    "severity": "info",
    "message": "File too large 15.2MB > 10MB"
  }
}
```

å¸¸è§é”™è¯¯ç ï¼š
- `INPUT_SIZE_EXCEEDED`: æ–‡ä»¶å¤§å°è¶…é™
- `UNSUPPORTED_FORMAT`: ä¸æ”¯æŒçš„æ ¼å¼
- `INPUT_ERROR`: ç©ºæ–‡ä»¶ / é€šç”¨è¾“å…¥é”™è¯¯
- `JSON_PARSE_ERROR`: é€‰é¡¹ JSON è§£æå¤±è´¥
- `BUSINESS_RULE_VIOLATION`: å®ä½“æ•°æˆ–ä¸šåŠ¡è§„åˆ™è¶…é™
- `DATA_NOT_FOUND`: å†å²åˆ†æç»“æœä¸å­˜åœ¨
- `INTERNAL_ERROR`: æœªæ•è·çš„å†…éƒ¨å¼‚å¸¸

å®Œæ•´æšä¸¾å‚è€ƒ `src/core/errors_extended.py`ã€‚

### ç»“æ„åŒ–é”™è¯¯å“åº”æ ¼å¼ (build_error)

æ‰€æœ‰åç«¯ API é”™è¯¯éµå¾ªç»Ÿä¸€çš„ç»“æ„åŒ–æ ¼å¼ï¼ˆé€šè¿‡ `build_error()` ç”Ÿæˆï¼‰ï¼ŒåµŒå¥—åœ¨ HTTPException çš„ `detail` å­—æ®µä¸­ï¼š

| å­—æ®µ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `code` | string | é”™è¯¯ä»£ç  (SCREAMING_SNAKE_CASEï¼Œå¦‚ `INTERNAL_ERROR`, `VALIDATION_FAILED`) |
| `stage` | string | é”™è¯¯å‘ç”Ÿé˜¶æ®µ (å¦‚ `backend_reload`, `model_validation`, `similarity`) |
| `message` | string | äººç±»å¯è¯»çš„é”™è¯¯æè¿° |
| `severity` | string | ä¸¥é‡ç¨‹åº¦: `error` (é”™è¯¯), `warning` (è­¦å‘Š), `info` (ä¿¡æ¯) |
| `context` | object | ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¯é€‰ï¼ŒåŒ…å«å…·ä½“é”™è¯¯ç»†èŠ‚å¦‚å»ºè®®ã€å‚æ•°ç­‰ï¼‰ |
| `suggestion` | string | å»ºè®®çš„ä¿®å¤æªæ–½ï¼ˆå¯é€‰ï¼Œé€šå¸¸åœ¨ context ä¸­ï¼‰ |

**ç¤ºä¾‹ 1 - æ¨¡å‹é‡è½½å¤±è´¥ (500 é”™è¯¯):**
```json
{
  "detail": {
    "code": "INTERNAL_ERROR",
    "stage": "backend_reload",
    "message": "Vector store backend reload failed",
    "severity": "error",
    "context": {
      "backend": "faiss",
      "suggestion": "Check backend configuration and logs"
    }
  }
}
```

**ç¤ºä¾‹ 2 - åç«¯æˆæƒå¤±è´¥ (403 é”™è¯¯):**
```json
{
  "detail": {
    "code": "FORBIDDEN",
    "stage": "backend_reload_auth",
    "message": "Admin token required for backend reload",
    "severity": "error",
    "context": {
      "required_header": "X-Admin-Token",
      "suggestion": "Provide valid admin token in X-Admin-Token header"
    }
  }
}
```

**ç¤ºä¾‹ 3 - æ¨¡å‹åŠ è½½å›æ»š (200 å“åº”ï¼Œä½†å«é”™è¯¯ä¿¡æ¯):**
```json
{
  "status": "rollback",
  "error": "Security validation failed: disallowed pickle opcode REDUCE detected",
  "previous_version": "v2.0.0",
  "previous_hash": "abc123def456"
}
```

æ­¤æ ¼å¼ç¡®ä¿æ‰€æœ‰é”™è¯¯å“åº”åŒ…å«è¶³å¤Ÿçš„è¯Šæ–­ä¿¡æ¯ï¼Œä¾¿äºå®¢æˆ·ç«¯å¤„ç†å’Œæ—¥å¿—åˆ†æã€‚

### ç›¸ä¼¼åº¦é”™è¯¯ç»“æ„ç¤ºä¾‹

`/api/v1/analyze/similarity` åœ¨é”™è¯¯ (å‘é‡ç¼ºå¤±ã€ç»´åº¦ä¸åŒ¹é…) æ—¶è¿”å›:
```json
{
  "reference_id": "abc",
  "target_id": "def",
  "score": 0.0,
  "method": "cosine",
  "dimension": 0,
  "status": "reference_not_found",
  "error": {
    "code": "DATA_NOT_FOUND",
    "source": "system",
    "severity": "error",
    "message": "Reference vector not found",
    "stage": "similarity"
  }
}
```

ç»´åº¦ä¸ä¸€è‡´ç¤ºä¾‹ (`dimension_mismatch`): `code` ä¸º `VALIDATION_FAILED`ã€‚

### OCR é”™è¯¯å“åº”è§„èŒƒ
OCR æå–ç«¯ç‚¹ç»Ÿä¸€ 200 è¿”å›ï¼š
```json
{
  "success": false,
  "provider": "auto",
  "confidence": null,
  "fallback_level": null,
  "processing_time_ms": 0,
  "dimensions": [],
  "symbols": [],
  "title_block": {},
  "error": "Unsupported MIME type image/txt",
  "code": "INPUT_ERROR"
}
```
å‰ç«¯åªéœ€ä¾æ® `success` ä¸ `code` åˆ¤æ–­é€»è¾‘ï¼Œä¸å†ä¾èµ– HTTP çŠ¶æ€ç ã€‚

### Unified Error Code Examples (curl)

#### Input Error Example
```bash
# Trigger INPUT_ERROR with invalid base64
curl -X POST http://localhost:8000/api/v1/vision/analyze \
  -H "Content-Type: application/json" \
  -d '{"image_base64": "invalid!!!", "include_description": true}' \
  | jq '.code'
# Output: "INPUT_ERROR"
```

#### Provider Timeout Example
```bash
# Simulate timeout (requires provider configuration)
curl -X POST http://localhost:8000/api/v1/ocr/extract \
  -F "file=@large_file.pdf" \
  -H "X-Timeout-MS: 100" \
  | jq '.code'
# Output: "PROVIDER_TIMEOUT"
```

#### Model Load Error Example
```bash
# Trigger MODEL_LOAD_ERROR (when model not available)
curl http://localhost:8000/health | jq '.services.ml'
# If "down", subsequent calls may return:
# "code": "MODEL_LOAD_ERROR"
```

#### Resource Exhausted Example
```bash
# Trigger RESOURCE_EXHAUSTED with very large image
curl -X POST http://localhost:8000/api/v1/vision/analyze \
  -H "Content-Type: application/json" \
  -d "{\"image_base64\": \"$(base64 -i 50mb_image.png)\"}" \
  | jq '.code'
# Output: "RESOURCE_EXHAUSTED"
```

### Strict Self-Check Mode

The self-check script now supports strict mode validation with environment variables:

```bash
# Basic self-check
python scripts/self_check.py

# Strict metrics validation
SELF_CHECK_STRICT_METRICS=1 \
SELF_CHECK_MIN_OCR_ERRORS=5 \
python scripts/self_check.py

# Remote endpoint check
SELF_CHECK_BASE_URL=http://production:8000 \
SELF_CHECK_REQUIRE_EMA=1 \
python scripts/self_check.py

# Full strict mode with counter increment
SELF_CHECK_STRICT_METRICS=1 \
SELF_CHECK_INCREMENT_COUNTERS=1 \
SELF_CHECK_MIN_OCR_ERRORS=10 \
python scripts/self_check.py
```

#### Environment Variables:
- `SELF_CHECK_BASE_URL`: Remote URL to check (default: local)
- `SELF_CHECK_STRICT_METRICS`: Enable strict contract validation
- `SELF_CHECK_MIN_OCR_ERRORS`: Minimum error counter threshold
- `SELF_CHECK_REQUIRE_EMA`: Require EMA values in /health
- `SELF_CHECK_INCREMENT_COUNTERS`: Make API calls to increment metrics

#### Exit Codes:

| Exit Code | Meaning | Description | CI Action |
|-----------|---------|-------------|-----------|
| `0` | Success | All checks passed | Continue pipeline |
| `2` | API Failure | Health endpoint unreachable or API errors | Fail pipeline, alert team |
| `3` | Health Check Failed | Service unhealthy or degraded | Block deployment |
| `5` | Metrics Contract Violation | Required metrics missing or malformed | Fail quality gate |
| `6` | Provider Mapping Gap | ErrorCode mapping incomplete | Warning, needs fix |

Example CI usage:
```bash
# In GitHub Actions
- name: Run Strict Self-Check
  run: |
    SELF_CHECK_STRICT_METRICS=1 python scripts/self_check.py
  continue-on-error: false

# In GitLab CI
self-check:
  script:
    - export SELF_CHECK_STRICT_METRICS=1
    - python scripts/self_check.py || exit_code=$?
    - if [ $exit_code -eq 5 ]; then echo "Metrics contract broken!"; exit 1; fi
```

#### 3. é›¶ä»¶åˆ†ç±»

```http
POST /api/v1/classify
Content-Type: multipart/form-data

file: (binary)
```

---

## ğŸ”§ å®¢æˆ·ç«¯SDK

### Pythonå®¢æˆ·ç«¯

```python
from cad_ml_client import CADMLClient

# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = CADMLClient(
    base_url="http://localhost:8000",
    api_key="your_api_key"
)

# åˆ†æCADæ–‡ä»¶
with open("drawing.dxf", "rb") as f:
    result = client.analyze(
        file=f,
        extract_features=True,
        classify_parts=True
    )

print(f"é›¶ä»¶ç±»å‹: {result.part_type}")
print(f"ç½®ä¿¡åº¦: {result.confidence}")
```

### JavaScriptå®¢æˆ·ç«¯

```javascript
const { CADMLClient } = require('cad-ml-client');

const client = new CADMLClient({
    baseURL: 'http://localhost:8000',
    apiKey: 'your_api_key'
});

// åˆ†ææ–‡ä»¶
const result = await client.analyze({
    file: fileBuffer,
    options: {
        extractFeatures: true,
        classifyParts: true
    }
});

console.log(`Part type: ${result.partType}`);
```

### Javaå®¢æˆ·ç«¯

```java
import com.cadml.client.CADMLClient;

CADMLClient client = new CADMLClient.Builder()
    .baseUrl("http://localhost:8000")
    .apiKey("your_api_key")
    .build();

AnalysisResult result = client.analyze(
    file,
    AnalysisOptions.builder()
        .extractFeatures(true)
        .classifyParts(true)
        .build()
);

System.out.println("Part type: " + result.getPartType());
```

---

## ğŸ”Œ é›†æˆæŒ‡å—

### ä¸DedupCADé›†æˆ

```python
# dedupcad/ml_integration.py
from cad_ml_client import CADMLClient

class MLEnhancedDedup:
    def __init__(self):
        self.ml_client = CADMLClient(
            base_url=os.getenv("CADML_URL", "http://cadml:8000")
        )

    async def compare_with_ml(self, file1, file2):
        # è·å–MLç‰¹å¾
        features1 = await self.ml_client.extract_features(file1)
        features2 = await self.ml_client.extract_features(file2)

        # è®¡ç®—ç›¸ä¼¼åº¦
        similarity = await self.ml_client.calculate_similarity(
            features1, features2
        )

        return similarity
```

### ä¸åˆ‡å‰²ç³»ç»Ÿé›†æˆ

```python
# cutting_system/process_optimizer.py
from cad_ml_client import CADMLClient

class ProcessOptimizer:
    def __init__(self):
        self.ml_client = CADMLClient()

    async def optimize_cutting_process(self, dxf_file):
        # è¯†åˆ«é›¶ä»¶ç±»å‹
        analysis = await self.ml_client.analyze(dxf_file)

        # æ ¹æ®é›¶ä»¶ç±»å‹ä¼˜åŒ–å·¥è‰º
        if analysis.part_type == "plate":
            return self.optimize_plate_cutting(analysis)
        elif analysis.part_type == "shaft":
            return self.optimize_shaft_cutting(analysis)
```

---

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡ & è‡ªé€‚åº”é™æµ

| æŒ‡æ ‡ | ç›®æ ‡å€¼ | å½“å‰å€¼ | çŠ¶æ€ |
|------|--------|--------|------|
| **å“åº”æ—¶é—´** | < 500ms | 320ms | âœ… |
| **ååé‡** | > 100 req/s | 150 req/s | âœ… |
| **å‡†ç¡®ç‡** | > 90% | 94.5% | âœ… |
| **å¯ç”¨æ€§** | > 99.9% | 99.95% | âœ… |
| **ç¼“å­˜å‘½ä¸­ç‡** | > 60% | 72% | âœ… |
| **è‡ªé€‚åº”é™çº§å“åº”æ—¶é—´å›é€€** | < +20% åŸºçº¿ | +12% | âœ… |

### è‡ªé€‚åº”é™æµæŒ‡æ ‡

æ ¸å¿ƒ Prometheus æŒ‡æ ‡ï¼š

```
adaptive_rate_limit_tokens_current{service,endpoint}
adaptive_rate_limit_base_rate{service,endpoint}
adaptive_rate_limit_adjustments_total{service,reason}
adaptive_rate_limit_state{service,state}  # 0=normal,1=degrading,2=recovery,3=clamped
adaptive_rate_limit_error_ema{service}
adaptive_rate_limit_latency_p95{service}
```

è§¦å‘æ¡ä»¶ï¼š
- é”™è¯¯ EMA > error_threshold â†’ é™çº§ (reason=error)
- P95 å»¶è¿Ÿ > baseline * multiplier â†’ é™çº§ (reason=latency)
- æ‹’ç»ç‡ > reject_rate_threshold â†’ é™çº§ (reason=reject)
- è¿ç»­å¤±è´¥æ•° >= max_failure_streak â†’ é™çº§ (reason=failures)
- æ¢å¤æ¡ä»¶æ»¡è¶³ï¼ˆä½é”™è¯¯ + æ­£å¸¸å»¶è¿Ÿ + æ— æ‹’ç»ï¼‰â†’ æ¸è¿›æ¢å¤ (reason=recover)
- æŠ–åŠ¨æ£€æµ‹çª—å£å†…æ–¹å‘é¢‘ç¹äº¤æ›¿ â†’ å†·å´ (è¿›å…¥ cooldown æŠ‘åˆ¶è°ƒæ•´)

ç¯å¢ƒå˜é‡ï¼š`ADAPTIVE_RATE_LIMIT_ENABLED=1` (é»˜è®¤å¼€å¯)ã€‚å…³é—­åä»ä¿æŒåŸºç¡€ä»¤ç‰Œæ¡¶è¡Œä¸ºä½†ä¸åšåŠ¨æ€è°ƒæ•´ã€‚

PromQL ç¤ºä¾‹ï¼š
```
increase(adaptive_rate_limit_adjustments_total[15m]) > 10
adaptive_rate_limit_state{state="clamped"} == 1
adaptive_rate_limit_error_ema > 0.05
```

å‘Šè­¦å»ºè®®ï¼š
- CLAMPED æŒç»­ >10mï¼šæ’æŸ¥ä¸Šæ¸¸æ•…éšœæˆ–èµ„æºç“¶é¢ˆã€‚
- å†·å´æœŸè§¦å‘é¢‘ç¹ï¼šè°ƒä¼˜ jitter_threshold æˆ–è°ƒæ•´æœ€å°æ ·æœ¬å‚æ•°ã€‚
- error_ema è¿ç»­ä¸Šå‡ä¸”æœªæ¢å¤ï¼šæ‰§è¡Œ provider å¥åº·è¯Šæ–­è„šæœ¬ã€‚

### æ€§èƒ½ä¼˜åŒ–

1. **ç¼“å­˜ç­–ç•¥**
   - Redisç¼“å­˜çƒ­ç‚¹æ•°æ®
   - ç‰¹å¾å‘é‡ç¼“å­˜24å°æ—¶
   - åˆ†ç±»ç»“æœç¼“å­˜7å¤©

2. **å¹¶å‘å¤„ç†**
   - å¼‚æ­¥APIå¤„ç†
   - æ‰¹é‡æ“ä½œæ”¯æŒ
   - å·¥ä½œé˜Ÿåˆ—å¹¶è¡Œå¤„ç†

3. **æ¨¡å‹ä¼˜åŒ–**
   - æ¨¡å‹é‡åŒ– (INT8)
   - ONNXè¿è¡Œæ—¶åŠ é€Ÿ
   - GPUæ¨ç† (å¯é€‰)

---

## ğŸ› ï¸ å¼€å‘æŒ‡å—

### é¡¹ç›®ç»“æ„

```
cad-ml-platform/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/              # APIç«¯ç‚¹
â”‚   â”‚   â”œâ”€â”€ v1/
â”‚   â”‚   â”‚   â”œâ”€â”€ analyze.py
â”‚   â”‚   â”‚   â”œâ”€â”€ similarity.py
â”‚   â”‚   â”‚   â””â”€â”€ classify.py
â”‚   â”‚   â””â”€â”€ middleware.py
â”‚   â”œâ”€â”€ core/             # æ ¸å¿ƒç®—æ³•
â”‚   â”‚   â”œâ”€â”€ feature_extractor.py
â”‚   â”‚   â”œâ”€â”€ classifier.py
â”‚   â”‚   â”œâ”€â”€ similarity_engine.py
â”‚   â”‚   â””â”€â”€ quality_checker.py
â”‚   â”œâ”€â”€ adapters/         # æ ¼å¼é€‚é…å™¨
â”‚   â”‚   â”œâ”€â”€ dxf_adapter.py
â”‚   â”‚   â”œâ”€â”€ step_adapter.py
â”‚   â”‚   â””â”€â”€ iges_adapter.py
â”‚   â”œâ”€â”€ models/           # MLæ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ part_classifier.pkl
â”‚   â”‚   â””â”€â”€ feature_model.h5
â”‚   â””â”€â”€ utils/            # å·¥å…·å‡½æ•°
â”œâ”€â”€ clients/              # å®¢æˆ·ç«¯SDK
â”‚   â”œâ”€â”€ python/
â”‚   â”œâ”€â”€ javascript/
â”‚   â””â”€â”€ java/
â”œâ”€â”€ tests/                # æµ‹è¯•å¥—ä»¶
â”‚   â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ integration/
â”‚   â””â”€â”€ e2e/
â”œâ”€â”€ docs/                 # æ–‡æ¡£
â”‚   â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ architecture/
â”‚   â””â”€â”€ deployment/
â”œâ”€â”€ config/               # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ config.yaml
â”‚   â””â”€â”€ logging.yaml
â”œâ”€â”€ scripts/              # è„šæœ¬å·¥å…·
â”‚   â”œâ”€â”€ train_model.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â””â”€â”€ benchmark.py
â”œâ”€â”€ deployments/          # éƒ¨ç½²é…ç½®
â”‚   â”œâ”€â”€ docker/
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ docker-compose.yml
â”‚   â””â”€â”€ kubernetes/
â”‚       â”œâ”€â”€ deployment.yaml
â”‚       â”œâ”€â”€ service.yaml
â”‚       â””â”€â”€ ingress.yaml
â””â”€â”€ knowledge_base/       # é¢†åŸŸçŸ¥è¯†
    â”œâ”€â”€ part_types.json
    â”œâ”€â”€ material_properties.json
    â””â”€â”€ process_rules.yaml
```

### æ·»åŠ æ–°åŠŸèƒ½

1. **æ–°å¢APIç«¯ç‚¹**
```python
# src/api/v1/new_endpoint.py
from fastapi import APIRouter, File, UploadFile
from src.core import new_analyzer

router = APIRouter()

@router.post("/new-analysis")
async def new_analysis(file: UploadFile = File(...)):
    result = await new_analyzer.analyze(file)
    return result
```

2. **æ–°å¢é€‚é…å™¨**
```python
# src/adapters/new_format_adapter.py
from src.adapters.base import BaseAdapter

class NewFormatAdapter(BaseAdapter):
    def convert(self, file_data: bytes) -> Dict:
        # å®ç°æ ¼å¼è½¬æ¢é€»è¾‘
        pass
```

### æµ‹è¯•

```bash
# è¿è¡Œå•å…ƒæµ‹è¯•
pytest tests/unit/

# è¿è¡Œé›†æˆæµ‹è¯•
pytest tests/integration/

# è¿è¡Œç«¯åˆ°ç«¯æµ‹è¯•
pytest tests/e2e/

# ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
pytest --cov=src --cov-report=html
```

---

## ğŸš¢ éƒ¨ç½²

### Dockeréƒ¨ç½²

```bash
# æ„å»ºé•œåƒ
docker build -t cad-ml-platform:latest .

# è¿è¡Œå®¹å™¨
docker run -d \
  -p 8000:8000 \
  -e REDIS_URL=redis://redis:6379 \
  --name cad-ml \
  cad-ml-platform:latest
```

### Docker Composeéƒ¨ç½²

```bash
# å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker-compose up -d

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f

# åœæ­¢æœåŠ¡
docker-compose down
```

### Kuberneteséƒ¨ç½²

```bash
# åˆ›å»ºå‘½åç©ºé—´
kubectl create namespace cad-ml

# åº”ç”¨é…ç½®
kubectl apply -f deployments/kubernetes/ -n cad-ml

# æ£€æŸ¥éƒ¨ç½²çŠ¶æ€
kubectl get pods -n cad-ml
kubectl get svc -n cad-ml
```

### ç”Ÿäº§ç¯å¢ƒé…ç½®

```yaml
# config/production.yaml
server:
  workers: 4
  host: 0.0.0.0
  port: 8000

redis:
  url: redis://redis.production:6379
  ttl: 86400

ml:
  model_path: /models
  batch_size: 32
  use_gpu: true

monitoring:
  prometheus_enabled: true
  metrics_port: 9090
```

---

## ğŸ“ˆ ç›‘æ§ä¸è¿ç»´

### Prometheusç›‘æ§

```yaml
# prometheus.yml
scrape_configs:
  - job_name: 'cad-ml-platform'
    static_configs:
      - targets: ['cad-ml:9090']
```

### å¥åº·æ£€æŸ¥

```bash
# å¥åº·æ£€æŸ¥ç«¯ç‚¹
curl http://localhost:8000/health

ç¤ºä¾‹å“åº”:
```json
{
  "status": "healthy",
  "services": {"api": "up", "ml": "up", "redis": "disabled"},
  "runtime": {
    "python_version": "3.11.2",
    "metrics_enabled": true,
    "vision_max_base64_bytes": 1048576
  }
}
```

Base64 å›¾åƒå¤§å°é™åˆ¶ï¼šè¶…è¿‡ 1MB æˆ–ç©ºå†…å®¹å°†è¢«æ‹’ç»ï¼Œå¹¶è®¡å…¥æŒ‡æ ‡ `vision_input_rejected_total{reason="base64_too_large"|"base64_empty"}`ã€‚

è§¦å‘è¶…é™ç¤ºä¾‹:
```bash
python - <<'PY'
import base64, requests
raw = b'x' * (1024 * 1200)  # >1MB
payload = {"image_base64": base64.b64encode(raw).decode(), "include_description": False, "include_ocr": False}
r = requests.post('http://localhost:8000/api/v1/vision/analyze', json=payload)
print(r.status_code, r.json())
PY
```

æˆåŠŸä¸æ‹’ç»è¯·æ±‚åçš„éƒ¨åˆ†æŒ‡æ ‡ç¤ºä¾‹ (Vision + OCR åŒç³»ç»Ÿ):
```
vision_requests_total{provider="deepseek_stub",status="success"} 1
vision_input_rejected_total{reason="base64_too_large"} 1
ocr_input_rejected_total{reason="validation_failed"} 1
ocr_errors_total{provider="auto",code="internal",stage="endpoint"} 1
vision_processing_duration_seconds_bucket{provider="deepseek_stub",le="0.1"} ...
```

æ–°å¢ OCR è¾“å…¥ä¸é”™è¯¯æŒ‡æ ‡è¯´æ˜:
- `ocr_input_rejected_total{reason}`: ä¸Šä¼ æ–‡ä»¶éªŒè¯å¤±è´¥ï¼ˆ`validation_failed|mime_unsupported|too_large|pdf_forbidden` ç­‰ï¼‰ã€‚
- `ocr_errors_total{provider,code,stage}`: è¿è¡Œæ—¶é”™è¯¯åˆ†é˜¶æ®µç»Ÿè®¡ï¼ˆ`code=internal|provider_down|rate_limit|circuit_open|input_error`ï¼‰ã€‚
- ç»Ÿä¸€é”™è¯¯å“åº”ï¼šHTTP 200 + JSON `{"success": false, "error": "...", "code": "INPUT_ERROR|INTERNAL_ERROR"}`ï¼Œä¾¿äºå‰ç«¯ä¸æ‰¹å¤„ç†æµæ°´çº¿ç®€åŒ–è§£æã€‚

# å°±ç»ªæ£€æŸ¥
curl http://localhost:8000/ready

# æŒ‡æ ‡ç«¯ç‚¹
curl http://localhost:8000/metrics
```

### æ—¥å¿—ç®¡ç†

```python
# æ—¥å¿—é…ç½®
logging:
  level: INFO
  format: json
  outputs:
    - console
    - file: /var/log/cad-ml/app.log
    - elasticsearch: http://elastic:9200
```

---

## ğŸ”’ å®‰å…¨æ€§

### APIè®¤è¯

```python
# ä½¿ç”¨APIå¯†é’¥
headers = {
    "X-API-Key": "your_api_key"
}

# ä½¿ç”¨JWTä»¤ç‰Œ
headers = {
    "Authorization": "Bearer your_jwt_token"
}
```

### é€Ÿç‡é™åˆ¶

```yaml
rate_limiting:
  enabled: true
  requests_per_minute: 100
  requests_per_hour: 5000
```

### æ•°æ®åŠ å¯†

- HTTPSä¼ è¾“åŠ å¯†
- æ•°æ®åº“å­—æ®µåŠ å¯†
- æ–‡ä»¶å­˜å‚¨åŠ å¯†

---

## ğŸ¤ è´¡çŒ®æŒ‡å—

### å¼€å‘æµç¨‹

1. Forké¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯Pull Request

### ä»£ç è§„èŒƒ

- éµå¾ªPEP 8 (Python)
- ä½¿ç”¨Blackæ ¼å¼åŒ–ä»£ç 
- ç¼–å†™å•å…ƒæµ‹è¯•
- æ›´æ–°æ–‡æ¡£

---

## ğŸ“ è®¸å¯è¯

æœ¬é¡¹ç›®ä¸ºç§æœ‰é¡¹ç›®ï¼Œç‰ˆæƒæ‰€æœ‰ Â© 2025 Your Company

---

## ğŸ“ è”ç³»æ”¯æŒ

- **æŠ€æœ¯æ”¯æŒ**: tech-support@yourcompany.com
- **å•†åŠ¡åˆä½œ**: business@yourcompany.com
- **Issueè¿½è¸ª**: [GitHub Issues](https://github.com/your-org/cad-ml-platform/issues)

---

## ğŸ”„ ç‰ˆæœ¬å†å²

### v1.0.0 (2025-11-12)
- åˆå§‹ç‰ˆæœ¬å‘å¸ƒ
- åŸºç¡€MLåˆ†æåŠŸèƒ½
- æ”¯æŒDXFæ ¼å¼
- Pythonå®¢æˆ·ç«¯SDK

### è·¯çº¿å›¾

- [ ] v1.1.0 - STEP/IGESæ ¼å¼æ”¯æŒ
- [ ] v1.2.0 - æ·±åº¦å­¦ä¹ æ¨¡å‹é›†æˆ
- [ ] v1.3.0 - å®æ—¶æµå¤„ç†
- [ ] v2.0.0 - åˆ†å¸ƒå¼å¤„ç†é›†ç¾¤

---

**æœ€åæ›´æ–°**: 2025å¹´11æœˆ12æ—¥
### æ–‡æ¡£å¯¼èˆª
- å…³é”®èƒ½åŠ›ä¸å®ç°åœ°å›¾: docs/KEY_HIGHLIGHTS.md
- CI å¤±è´¥è·¯ç”±ä¸å“åº”: docs/CI_FAILURE_ROUTING.md

### è·¯ç”±å‰ç¼€è§„èŒƒ
- å­è·¯ç”±ä»…åŒ…å«èµ„æºçº§è·¯å¾„ï¼ˆsrc/api/v1/*ï¼‰
- èšåˆè·¯ç”±ç»Ÿä¸€æŒ‚è½½è‡³ /api/v1ï¼Œé¿å…é‡å¤å‰ç¼€
- æœ‰æ•ˆè·¯å¾„ç¤ºä¾‹ï¼š
  - GET /api/v1/vision/health
  - POST /api/v1/vision/analyze
  - POST /api/v1/ocr/extract
  - POST /api/v1/vision/analyze (é”™è¯¯è·¯å¾„æµ‹è¯•: tests/test_ocr_errors.py)
# å¯é€‰ï¼šç¯å¢ƒå˜é‡è¦†ç›–
cp .env.example .env
# æ ¹æ®éœ€è¦ç¼–è¾‘ .envï¼ˆCORSã€ALLOWED_HOSTSã€REDIS ç­‰ï¼‰
#### 2.1 é¢„æäº¤é’©å­ï¼ˆå¯é€‰ä½†æ¨èï¼‰

```bash
pre-commit install
# è¿è¡Œå…¨é‡æ£€æŸ¥
pre-commit run --all-files --show-diff-on-failure
```

æç¤ºï¼š`tests/vision/test_vision_ocr_integration.py` å«é UTF-8 å†…å®¹ï¼Œå·²åœ¨ pre-commit ä¸ Makefile çš„æ ¼å¼åŒ–æ­¥éª¤ä¸­æ’é™¤ï¼Œä¸å½±å“æµ‹è¯•æ‰§è¡Œã€‚

### è´¨é‡é…ç½®æ–‡ä»¶
- Flake8: `.flake8` (max-line-length=100, å¿½ç•¥ E203/W503)
- Mypy: `mypy.ini` (ä¸¥æ ¼ç±»å‹, metrics æ¨¡å—å®½æ¾)
- æ–°å¢ Vision æŒ‡æ ‡: `vision_requests_total`, `vision_processing_duration_seconds`, `vision_errors_total`
```
#### OCR é”™è¯¯æŒ‡æ ‡è¯¦ç»†è¯´æ˜

| Metric | Labels | Description | Example |
|--------|--------|-------------|---------|
| `ocr_errors_total` | `provider, code, stage` | ç»Ÿè®¡OCRå„é˜¶æ®µé”™è¯¯æ¬¡æ•° | `ocr_errors_total{provider="paddle",code="rate_limit",stage="preprocess"} 3` |
| `ocr_input_rejected_total` | `reason` | è¾“å…¥éªŒè¯æ‹’ç» | `ocr_input_rejected_total{reason="validation_failed"} 1` |

Stages è¯´æ˜:
- `validate`: ä¸Šä¼ æ–‡ä»¶è¯»å–ä¸éªŒè¯ï¼ˆMIME/å¤§å°/PDFå®‰å…¨ï¼‰
- `preprocess`: é¢„å¤„ç†ä¸é€Ÿç‡é™åˆ¶
- `infer`: Provideræ¨ç†æˆ–å›é€€é€»è¾‘
- `parse`: ç»“æ„åŒ–è§£æé˜¶æ®µ
- `manager`: ç®¡ç†å™¨è·¯ç”±ä¸å›é€€åˆ¤å®š
- `endpoint`: æœ€å¤–å±‚ç«¯ç‚¹åŒ…è£…/æœªçŸ¥å¼‚å¸¸

å¸¸è§é”™è¯¯ä»£ç  (`code`): `internal`, `provider_down`, `rate_limit`, `circuit_open`, `input_error`ã€‚
#### è‡ªæ£€è„šæœ¬ (CI Smoke)

è¿è¡Œå¿«é€Ÿè‡ªæ£€ä»¥éªŒè¯å¥åº·ã€æ ¸å¿ƒæŒ‡æ ‡ä¸åŸºç¡€ç«¯ç‚¹ï¼š
```bash
python scripts/self_check.py || echo "Self-check failed"
```
å¯é…ç½®é¡¹ï¼š
- `SELF_CHECK_METRICS=0` å¯åœ¨ Prometheus æœªå¯ç”¨æˆ–æœªæŒ‚è½½ `/metrics` æ—¶è·³è¿‡æŒ‡æ ‡æ£€æŸ¥ï¼š
  ```bash
  SELF_CHECK_METRICS=0 python scripts/self_check.py
  ```
- `SELF_CHECK_ERROR=0` å¯è·³è¿‡æœ€å°é”™è¯¯è·¯å¾„å¥‘çº¦æ£€æŸ¥ï¼ˆé»˜è®¤å¼€å¯ï¼‰ã€‚
  ```bash
  SELF_CHECK_ERROR=0 python scripts/self_check.py
  ```
é€€å‡ºç å«ä¹‰ï¼š
- 0: æ‰€æœ‰æ£€æŸ¥é€šè¿‡
- 2: å…³é”®ç«¯ç‚¹ä¸å¯ç”¨æˆ–ä¸¥é‡é”™è¯¯
- 3: æŒ‡æ ‡ç¼ºå¤± (æ ¸å¿ƒè®¡æ•°å™¨æœªæš´éœ²)
- 4: é”™è¯¯å“åº”å¥‘çº¦å¼‚å¸¸
### Prometheuså‘Šè­¦è§„åˆ™ç¤ºä¾‹

å‚è§ `docs/ALERT_RULES.md` è·å– OCR/Vision é”™è¯¯çªå¢ã€Provider Downã€è¾“å…¥æ‹’ç»ä¸é€Ÿç‡è®°å½•è§„åˆ™ç¤ºä¾‹ã€‚
### ç›¸ä¼¼åº¦æ£€ç´¢ (Top-K)

å•ä¸ªå‘é‡ç›¸ä¼¼åº¦æŸ¥è¯¢:
```bash
curl -X POST http://localhost:8000/api/v1/analyze/similarity/topk \
  -H "X-API-Key: test" \
  -H "Content-Type: application/json" \
  -d '{"target_id": "<analysis_id>", "k": 5, "material_filter": "steel", "complexity_filter": "medium"}'
```

å“åº”ç¤ºä¾‹:
```json
{
  "target_id": "123e4567-e89b-12d3-a456-426614174000",
  "k": 5,
  "results": [
    {"id": "...", "score": 0.9923, "material": "steel", "complexity": "medium", "format": "dxf"}
  ]
}
```

**æ‰¹é‡ç›¸ä¼¼åº¦æŸ¥è¯¢** (æ–°å¢):
```bash
curl -X POST http://localhost:8000/api/v1/vectors/similarity/batch \
  -H "X-API-Key: test" \
  -H "Content-Type: application/json" \
  -d '{
    "ids": ["vec1", "vec2", "vec3"],
    "top_k": 5,
    "material": "steel",
    "min_score": 0.7
  }'
```

æ‰¹é‡æŸ¥è¯¢å“åº”:
```json
{
  "total": 3,
  "successful": 3,
  "failed": 0,
  "batch_id": "550e8400-e29b-41d4-a716-446655440000",
  "duration_ms": 12.34,
  "items": [
    {
      "id": "vec1",
      "status": "success",
      "similar": [
        {"id": "vec2", "score": 0.9512, "material": "steel", "complexity": "high", "format": "step", "dimension": 128}
      ]
    }
  ]
}
```

æ‰¹é‡æŸ¥è¯¢ç‰¹æ€§:
- æ”¯æŒæ‰¹é‡æŸ¥è¯¢å¤šä¸ªå‘é‡çš„ç›¸ä¼¼å‘é‡
- å¯é€‰è¿‡æ»¤: `material`, `complexity`, `format`
- æœ€å°ç›¸ä¼¼åº¦é˜ˆå€¼: `min_score` (0.0-1.0)
- è‡ªåŠ¨è®°å½• Prometheus æŒ‡æ ‡: `vector_query_batch_latency_seconds` (æŒ‰æ‰¹é‡å¤§å°åˆ†æ¡¶: small/medium/large)
- æ‰¹é‡ä¸Šé™: ç”±ç¯å¢ƒå˜é‡ `BATCH_SIMILARITY_MAX_IDS` æ§åˆ¶ (é»˜è®¤ 200)
- è¶…å‡ºä¸Šé™: è¿”å› 422 ç»“æ„åŒ–é”™è¯¯ (code=INPUT_VALIDATION_FAILED, stage=batch_similarity) å¹¶è®¡æ•° `analysis_rejections_total{reason="batch_too_large"}`
- è‹¥æ‰€æœ‰æˆåŠŸé¡¹çš„ç›¸ä¼¼ç»“æœåˆ—è¡¨ä¸ºç©º (è¿‡æ»¤æˆ–é˜ˆå€¼å¯¼è‡´) è®¡æ•° `analysis_rejections_total{reason="batch_empty_results"}` æ–¹ä¾¿è°ƒä¼˜é˜ˆå€¼

### å‘é‡ç®¡ç†

åˆ—å‡ºå·²æ³¨å†Œå‘é‡:
```bash
curl -H "X-API-Key: test" http://localhost:8000/api/v1/analyze/vectors | jq
```

åˆ é™¤å‘é‡:
```bash
curl -X POST http://localhost:8000/api/v1/analyze/vectors/delete \
  -H "X-API-Key: test" -H "Content-Type: application/json" \
  -d '{"id": "123e4567-e89b-12d3-a456-426614174000"}'
```

æ›´æ–°å‘é‡ (æ›¿æ¢æˆ–è¿½åŠ  + å…ƒæ•°æ®æ›´æ–°):
```bash
curl -X POST http://localhost:8000/api/v1/analyze/vectors/update \
  -H "X-API-Key: test" -H "Content-Type: application/json" \
  -d '{"id": "123e4567-e89b-12d3-a456-426614174000", "append": [0.12, 0.34], "material": "steel"}'
```

å‘é‡ç»Ÿè®¡:
```bash
curl -H "X-API-Key: test" http://localhost:8000/api/v1/analyze/vectors/stats | jq
```
ç¤ºä¾‹å“åº”:
```json
{
  "backend": "memory",
  "total": 42,
  "by_material": {"steel": 20, "aluminum": 12, "unknown": 10},
  "by_complexity": {"low": 30, "medium": 10, "high": 2},
  "by_format": {"dxf": 25, "step": 10, "stl": 7}
}
```

### å¤æ‚åº¦ä¸é™åˆ¶
é€šè¿‡ç¯å¢ƒå˜é‡æ§åˆ¶:
```bash
export ANALYSIS_MAX_FILE_MB=15          # æœ€å¤§æ–‡ä»¶å¤§å° (MB)
export ANALYSIS_MAX_ENTITIES=50000      # æœ€å¤§å®ä½“æ•°
export PROCESS_RULES_FILE=config/process_rules.yaml  # å·¥è‰ºè§„åˆ™æ–‡ä»¶è·¯å¾„
export ANALYSIS_PARSE_P95_TARGET_MS=250  # è§£æé˜¶æ®µ p95 ç›®æ ‡ (ç”¨äºå†…éƒ¨é¢„ç®—)
export ANALYSIS_VECTOR_DIM_CHECK=1       # å¼€å¯å‘é‡ç»´åº¦ä¸€è‡´æ€§æ£€æŸ¥ (æœªæ¥æ‰©å±•)
export CLASSIFICATION_RULE_VERSION=v1    # åˆ†ç±»è§„åˆ™ç‰ˆæœ¬æ ‡è®° (è§‚æµ‹å˜æ›´å½±å“)
export VECTOR_STORE_BACKEND=memory       # å‘é‡å­˜å‚¨åç«¯ memory|redis
export VECTOR_TTL_SECONDS=0              # å‘é‡TTL(ç§’) 0è¡¨ç¤ºç¦ç”¨
export VECTOR_PRUNE_INTERVAL_SECONDS=30  # åå°æ¸…ç†é—´éš”(ç§’)
export PROCESS_RULE_VERSION=v1           # å·¥è‰ºè§„åˆ™ç‰ˆæœ¬ (Prometheusè®¡æ•° + å“åº”æš´éœ²)
export ENABLE_PROCESS_AUDIT_ENDPOINT=1   # å¼€å¯ /api/v1/analyze/process/rules/audit å®¡è®¡ç«¯ç‚¹ (é»˜è®¤å¼€å¯)
export ANALYSIS_MAX_FILE_MB=15           # æœ€å¤§æ–‡ä»¶å¤§å° (MB)
export ANALYSIS_MAX_ENTITIES=50000       # æœ€å¤§å®ä½“æ•°
export ANALYSIS_PARSE_P95_TARGET_MS=250  # è§£æé˜¶æ®µ p95 ç›®æ ‡ (ç”¨äºé¢„ç®—æ¯”ç‡è®¡ç®—)
export CLASSIFICATION_RULE_VERSION=v1    # åˆ†ç±»è§„åˆ™ç‰ˆæœ¬ (Prometheus + å“åº”è¯†åˆ«)
export VECTOR_STORE_BACKEND=memory       # å‘é‡å­˜å‚¨åç«¯ memory|redis
export PROCESS_RULES_FILE=config/process_rules.yaml  # å·¥è‰ºè§„åˆ™æ–‡ä»¶è·¯å¾„
export VECTOR_TTL_SECONDS=0              # å‘é‡ TTL (ç§’)
export PROCESS_RULE_VERSION=v1           # å·¥è‰ºè§„åˆ™ç‰ˆæœ¬
export ANALYSIS_VECTOR_DIM_CHECK=1       # å¼€å¯å‘é‡ç»´åº¦ä¸€è‡´æ€§æ£€æŸ¥
export PROMETHEUS_MULTIPROC_DIR=/tmp     # å¯é€‰: å¤šè¿›ç¨‹æŒ‡æ ‡å¯¼å‡ºç›®å½•
export FEATURE_FLAG_SIMILARITY=1         # æœªæ¥æ‰©å±•: ç›¸ä¼¼åº¦åŠŸèƒ½å¼€å…³
export FEATURE_FLAG_OCR=0                # æœªæ¥æ‰©å±•: OCR åŠŸèƒ½å¼€å…³
export FEATURE_VERSION=v1               # ç‰¹å¾ç‰ˆæœ¬ v1|v2 (v2 å¯ç”¨å½’ä¸€åŒ–ä¸é¢å¤–å‡ ä½•æ¯”ç‡)
```

è¶…é™æ—¶è¿”å› 422 å¹¶åœ¨æŒ‡æ ‡ `analysis_rejections_total{reason="entity_count_exceeded"}` ä¸­å¢åŠ ã€‚

æ–°å¢å»¶è¿ŸæŒ‡æ ‡:
```
classification_latency_seconds            # åˆ†ç±»é˜¶æ®µ wall clock å»¶è¿Ÿç›´æ–¹å›¾
process_recommend_latency_seconds         # å·¥è‰ºæ¨èé˜¶æ®µ wall clock å»¶è¿Ÿç›´æ–¹å›¾
vector_store_material_total{material="steel"}  # å‘é‡æŒ‰ææ–™åˆ†å¸ƒè®¡æ•°
vector_dimension_rejections_total{reason="dimension_mismatch_*"} # å‘é‡ç»´åº¦æ‹’ç»æ¬¡æ•°
analysis_parallel_enabled                 # å¹¶è¡Œæ‰§è¡Œ classify/quality/process æ—¶ä¸º1, å¦åˆ™0
analysis_cache_hits_total / analysis_cache_miss_total  # åˆ†æç¼“å­˜å‘½ä¸­ä¸æœªå‘½ä¸­æ¬¡æ•°
features: { feature_version: v1 }       # å“åº”ç‰¹å¾ç‰ˆæœ¬æ ‡è®°
```

å½•åˆ¶è§„åˆ™æ–°å¢:
```
cad_ml:classification_p95_5m
cad_ml:process_recommend_p95_5m
```

### å·¥è‰ºè§„åˆ™çƒ­åŠ è½½
è§„åˆ™æ–‡ä»¶è·¯å¾„å¯é€šè¿‡ `PROCESS_RULES_FILE` ç¯å¢ƒå˜é‡æŒ‡å®šã€‚é»˜è®¤ç¤ºä¾‹: `config/process_rules.yaml`ã€‚
ç»“æ„ç¤ºä¾‹:
```yaml
steel:
  low:
    - max_volume: 10000
      primary: cnc_machining
      alternatives: [sheet_metal]
```

å®¡è®¡ç«¯ç‚¹:
```bash
# å®Œæ•´è¿”å› (åŒ…å«åŸå§‹è§„åˆ™ç»“æ„)
curl -H "X-API-Key: test" "http://localhost:8000/api/v1/analyze/process/rules/audit" | jq

# ç²¾ç®€è¿”å› (ä¸åŒ…å« raw è§„åˆ™ä½“)
curl -H "X-API-Key: test" "http://localhost:8000/api/v1/analyze/process/rules/audit?raw=0" | jq
```
ä¿®æ”¹åæ–‡ä»¶ mtime å˜åŒ–ä¼šè§¦å‘ä¸‹ä¸€æ¬¡è¯·æ±‚è‡ªåŠ¨é‡è½½ã€‚

### ğŸ“Ÿ Runbooks & Alerts
å¸¸è§å‘Šè­¦å¤„ç½®:
- HighErrorRate: æ£€æŸ¥æœ€è¿‘å‘å¸ƒä¸å…¥å£æµé‡æ¿€å¢ (æŸ¥çœ‹ `cad_ml:api_error_rate_5m` ä¸ `cad_ml:api_request_rate_5m`)ï¼Œæ»šåŠ¨é‡å¯æœ‰æ— å¤±è´¥ï¼›è‹¥å¤§é‡ 5xx æ¥è‡ªå•ä¸€è·¯å¾„ï¼Œæ‰§è¡Œå±€éƒ¨ç†”æ–­ã€‚
- LowOCRSuccessRate: å¯¹åº” Provider é€šé“è´¨é‡ä¸‹é™ï¼Œé™çº§åˆ°å¤‡ç”¨ Provider (`ocr_provider=deepseek_hf` æˆ– `paddle`)ï¼›æ¯”å¯¹ `ocr_processing_duration_seconds_*` æ˜¯å¦è¶…æ—¶å¯¼è‡´å¤±è´¥ã€‚
- HighResourceUsage: ç™»å½•èŠ‚ç‚¹æŸ¥çœ‹ `top` / `iostat`; è‹¥ CPU é«˜ä¸” parse é˜¶æ®µè€—æ—¶ä¸Šå‡ï¼Œè€ƒè™‘ä¸´æ—¶æ‰©å®¹æˆ–æå‡ `ANALYSIS_PARSE_P95_TARGET_MS` åè°ƒæ•´é¢„ç®—ã€‚
- ParseLatencyBudget(æœªæ¥): å…³æ³¨ `analysis_parse_latency_budget_ratio` >1.0 æŒç»­çª—å£ï¼Œå¯èƒ½æ˜¯å¤§æ–‡ä»¶æˆ– adapter å›é€€è·¯å¾„æ€§èƒ½é—®é¢˜ã€‚

Runbook é“¾æ¥ç”± Prometheus alert `runbook` æ³¨è§£æŒ‡å‘æ­¤èŠ‚ã€‚

### ç‰¹å¾ç‰ˆæœ¬ (Feature Versioning)
å½“å‰æ”¯æŒ:
- v1: åŸºç¡€å‡ ä½• (å®ä½“æ•°, bboxå®½é«˜æ·±, ä½“ç§¯) + è¯­ä¹‰ (å±‚æ•°, é«˜å¤æ‚åº¦æ ‡è®°)
- v2: åœ¨ v1 åŸºç¡€ä¸Šè¿½åŠ å½’ä¸€åŒ–å®½/é«˜/æ·±ä¸å®½é«˜ã€å®½æ·±æ¯”ç‡ (éœ€ `FEATURE_VERSION=v2`)
- v3: åœ¨ v2 åŸºç¡€ä¸Šè¿½åŠ  STEP/IGES å‡ ä½•å¢å¼º (solids, facets, å¹³å‡ä½“ç§¯/å®ä½“å æ¯”) + å‰5å®ä½“ç±»å‹é¢‘ç‡å‘é‡ (å›ºå®š5æ§½ä½); é€‚é… `FEATURE_VERSION=v3`

ç»´åº¦å‡çº§å»ºè®®æµç¨‹:
1. æš‚æ—¶å…³é—­ç»´åº¦æ£€æŸ¥ (`ANALYSIS_VECTOR_DIM_CHECK=0`)
2. é‡æ–°æ³¨å†Œæˆ–æ‰¹é‡é‡å»ºæ—§å‘é‡ä¸ºæ–°ç‰ˆæœ¬
3. å¼€å¯ç»´åº¦æ£€æŸ¥å¹¶å›ºå®šæ–°ç‰ˆæœ¬ (ç‰ˆæœ¬å›æ»šåªéœ€åˆ‡å› v1 å¹¶ä¿æŒæ£€æŸ¥å¼€å¯)

åç»­è§„åˆ’: STEP å‡ ä½•ç»†åŒ– (edges/surfaces/solids)ã€å±‚åç§°é¢‘ç‡å‘é‡ã€OCR æ–‡æœ¬åµŒå…¥æ‰©å±•åˆ° v3/v4ã€‚
v3 å·²åˆæ­¥åŒ…å« solids/facets ä¸å®ä½“ç±»å‹é¢‘ç‡ (Top-5 æ­£è§„åŒ–)ï¼Œæœªæ¥ v4 è®¡åˆ’åŠ å…¥è¾¹/é¢æ•°é‡ã€B-Rep æ‹“æ‰‘ç‰¹å¾ã€OCRæ–‡æœ¬åµŒå…¥ã€‚
å‘é‡å…ƒæ•°æ®å·²å­˜å‚¨ï¼š`geometric_dim` / `semantic_dim` / `total_dim` / `feature_version`ï¼Œç”¨äºè¿ç§»ä¸ä¸€è‡´æ€§æ ¡éªŒï¼›åˆ†å¸ƒæ¥å£ `/api/v1/analyze/vectors/distribution` æä¾› `average_dimension` ä¸ç‰ˆæœ¬é¢‘ç‡ `versions`ã€‚
ä¸¥æ ¼æ ¼å¼ä¸çŸ©é˜µæ ¡éªŒ: `FORMAT_STRICT_MODE=1` + `FORMAT_VALIDATION_MATRIX=config/format_validation_matrix.yaml` æ”¯æŒåŠ¨æ€ token/å°ºå¯¸è§„åˆ™ä¸é¡¹ç›®è±å… (`exempt_projects`)ã€‚
Faiss æŒä¹…åŒ–: `FAISS_EXPORT_INTERVAL_SECONDS` å®šæœŸå¯¼å‡ºåˆ° `FAISS_INDEX_PATH` (é»˜è®¤ `data/faiss_index.bin`)ï¼ŒæŒ‡æ ‡ `faiss_export_total{status}` / `faiss_export_duration_seconds`ã€‚
ML åˆ†ç±»æŒ‡æ ‡: `classification_model_load_total`, `classification_model_inference_seconds`, `classification_prediction_distribution{label,version}`ã€‚

æ–°å¢æŒ‡æ ‡ä¸å¢å¼º:
- `analysis_cache_hits_total` / `analysis_cache_miss_total`ï¼šç¼“å­˜å‘½ä¸­ç‡ç›‘æ§ (å‘Šè­¦ CacheHitRateLow <30%)
  - å½•åˆ¶è§„åˆ™: `cad_ml:analysis_cache_hit_ratio_30m` / `cad_ml:analysis_cache_hit_ratio_6h` æä¾›ä¸­çŸ­æœŸè¶‹åŠ¿å¯¹æ¯”
- `feature_cache_hits_last_hour` / `feature_cache_miss_last_hour`ï¼šç‰¹å¾ç¼“å­˜è¿‘1å°æ—¶æ»‘çª—å‘½ä¸­ä¸æœªå‘½ä¸­äº‹ä»¶è®¡æ•° (å‘Šè­¦ FeatureCacheHitRateLowSlidingHour <30%)
- `material_drift_ratio`ï¼šä¸»å¯¼ææ–™å æ¯”æ¼‚ç§»ç›‘æ§ (>0.85 è§¦å‘å‘Šè­¦ MaterialDistributionDrift)
- `signature_validation_fail_total{format}`ï¼šæ–‡ä»¶ç­¾åä¸å£°æ˜æ ¼å¼ä¸åŒ¹é…çš„æ¬¡æ•°
- `format_validation_fail_total{format,reason}`ï¼šä¸¥æ ¼æ¨¡å¼ä¸‹æ·±åº¦æ ¼å¼éªŒè¯å¤±è´¥æ¬¡æ•°
- `strict_mode_enabled`ï¼šä¸¥æ ¼æ ¼å¼æ ¡éªŒæ¨¡å¼å¼€å…³çŠ¶æ€ (Gauge)
 - `faiss_auto_rebuild_total{status}`ï¼šFaiss å»¶è¿Ÿåˆ é™¤è¾¾åˆ°é˜ˆå€¼è‡ªåŠ¨é‡å»ºç»“æœç»Ÿè®¡ (success|error)

ç­¾åæ ¡éªŒ (Signature Validation):
- é’ˆå¯¹ STEP / STL / IGES åšè½»é‡é¦–éƒ¨æ ¡éªŒï¼Œå¤±è´¥è¿”å› 415 ä¸å‘Šè­¦æŒ‡æ ‡é€’å¢ï¼Œå¹¶åœ¨é”™è¯¯ä½“ä¸­åŒ…å« `signature_prefix` (å‰32å­—èŠ‚åå…­è¿›åˆ¶) ä¸ `expected_signature`ã€‚

Feature Slots (feature_slots):
- åˆ†æç»“æœ `results.features.feature_slots` æä¾›ç‰¹å¾æ§½ä½å®šä¹‰ï¼Œå« `name/category/version`ï¼Œé¿å…å®¢æˆ·ç«¯ç¡¬ç¼–ç ç´¢å¼•ã€‚
ç¤ºä¾‹: `[{"name":"entity_count","category":"geometric","version":"v1"}, {"name":"norm_width","category":"geometric","version":"v2"}]`

å‘é‡è¿ç§»æ‰¹æ¬¡:
- è¿ç§»å“åº”åŒ…å« `migration_id`, `started_at`, `finished_at`, `dry_run_total`ã€‚
- çŠ¶æ€ç«¯ç‚¹ `/api/v1/vectors/migrate/status` è¿”å›æœ€è¿‘æ‰¹æ¬¡ä¸ `history` (æœ€å¤š10æ¡)ï¼Œä¾¿äºå®¡è®¡è¿ç§»æ´»åŠ¨ã€‚

Faiss è‡ªåŠ¨å¯¼å…¥ä¸é‡å»º:
- å¯åŠ¨å°è¯•ä» `FAISS_INDEX_PATH` å¯¼å…¥ (æ—¥å¿—æ˜¾ç¤ºç»´åº¦ä¸å¤§å°)ã€‚
- è¾¾åˆ° `FAISS_MAX_PENDING_DELETE` è§¦å‘è‡ªåŠ¨é‡å»ºå¹¶è®°å½•æŒ‡æ ‡ `faiss_auto_rebuild_total{status}`ã€‚
- æ–°å¢é€€é¿æŒ‡æ ‡ `faiss_rebuild_backoff_seconds`ï¼Œå¤±è´¥æŒ‡æ•°é€€é¿ (åˆå§‹ `FAISS_REBUILD_BACKOFF_INITIAL`ï¼Œæœ€å¤§ `FAISS_REBUILD_BACKOFF_MAX`)ã€‚
- é…ç½®ä¿æŒå®½æ¾ä»¥é¿å…æ—©æœŸè¯¯æŠ¥ï¼›å¯åœ¨å®‰å…¨åŠ å›ºé˜¶æ®µæ”¶ç´§åŒ¹é…é€»è¾‘

æ·±åº¦æ ¼å¼æ ¡éªŒ (Deep Format Validation / Strict Mode):
- è®¾ç½® `FORMAT_STRICT_MODE=1` å¯ç”¨ä¸¥æ ¼æ ¡éªŒï¼›å¤±è´¥ä½¿ç”¨æ‰©å±•é”™è¯¯ç  `INPUT_FORMAT_INVALID` + 415ã€‚
- å¤±è´¥åŸå› ç¤ºä¾‹: `missing_step_header`, `missing_step_HEADER_section`, `stl_too_small`, `iges_section_markers_missing`, `dxf_section_missing`ã€‚
- è¿è¡Œæ‰‹å†Œ: `docs/runbooks/format_validation_fail.md`ã€‚

TTL è¡Œä¸ºè¯´æ˜:
- å‘é‡ TTL (`VECTOR_TTL_SECONDS`) è¿‡æœŸç”±åå°å¾ªç¯ä¸æŸ¥è¯¢æ—¶ prune åŒè·¯å¾„å¤„ç†ï¼Œå¯èƒ½äº§ç”Ÿé‡å¤åˆ é™¤ (å¹‚ç­‰å®‰å…¨)
- ç«æ€æ¡ä»¶ä¸ä¼šå¯¼è‡´é”™è¯¯ï¼Œä»…å¯èƒ½å¤šæ¬¡å°è¯•åˆ é™¤ç›¸åŒ key
- ç›‘æ§ `vector_store_material_total` ä¸ `material_drift_ratio` ç»„åˆè¯„ä¼°æ•°æ®æ–°é²œåº¦ä¸åˆ†å¸ƒå‡è¡¡

æ¼‚ç§»å¤„ç½® Runbook: `docs/runbooks/material_distribution_drift.md`

### å‘é‡åç«¯è·¯çº¿ (ANN Roadmap)
åè®® `VectorStoreProtocol` æ”¯æŒå¯æ’æ‹”åç«¯:
- InMemoryVectorStore: å†…å­˜ + å¯é€‰ Redis è½åœ°
- FaissVectorStore (å ä½): æœªå®‰è£… faiss æ—¶æŸ¥è¯¢ä¸ºç©ºï¼Œå®‰è£…åæ–¹æ³•æŠ› `NotImplementedError` ç­‰å¾…åç»­å®ç°
  - å·²å®ç°åŸºç¡€ IndexFlatIP å¢åŠ  / æŸ¥è¯¢ï¼Œæ”¯æŒå½’ä¸€åŒ–ä½™å¼¦è¿‘ä¼¼ã€å»¶è¿Ÿåˆ é™¤ + æ‰‹åŠ¨é‡å»ºæ¥å£ `/api/v1/analyze/vectors/faiss/rebuild`
  - å»¶è¿Ÿåˆ é™¤ï¼š`/vectors/delete` åœ¨ Faiss åç«¯ä»…æ ‡è®°å¾…åˆ é™¤é›†åˆï¼Œé‡å»ºæ—¶ä¸€æ¬¡æ€§é‡æ–°æ„å»ºç´¢å¼•
  - æŒ‡æ ‡ï¼š`faiss_index_size`ã€`faiss_index_age_seconds`ã€`faiss_rebuild_total{status}`ã€`faiss_rebuild_duration_seconds`ã€`vector_query_latency_seconds{backend}`
  - è€åŒ–ç›‘æ§ï¼š`faiss_index_age_seconds` è¶…è¿‡é˜ˆå€¼(å¦‚ 3600s) è§¦å‘ç´¢å¼•åˆ·æ–°æˆ–é‡å»ºå‘Šè­¦
  - ç¯å¢ƒï¼š`VECTOR_STORE_BACKEND=faiss`ã€`FEATURE_COSINE_NORMALIZE=1`

æœªæ¥: æä¾› `VECTOR_STORE_BACKEND=faiss` çœŸæ­£å¯ç”¨ ANNï¼›å¢åŠ ç›¸ä¼¼åº¦ Top-K è¿‡æ»¤æ¡ä»¶ä¸æ‰¹é‡æŸ¥è¯¢æ€§èƒ½ä¼˜åŒ–ã€‚
#### ç‰¹å¾å·®å¼‚å¯¹æ¯” (Features Diff Endpoint)
ä½¿ç”¨ `/api/v1/features/diff?id_a=<id1>&id_b=<id2>` è¿”å›é€æ§½ä½å·®å¼‚: `[{index,name,category,version,a,b,delta,percent_change,normalized_delta}, ...]`ã€‚
æ–°å¢å­—æ®µè¯´æ˜:
- `percent_change`: `(b - a) / (|a| + 1e-9)`
- `normalized_delta`: `|b - a| / max(|a|, |b|, 1e-9)` èŒƒå›´ [0,1]
æŒ‡æ ‡: `features_diff_requests_total{status}`ã€`feature_slot_delta_magnitude`ã€‚
ç¤ºä¾‹å“åº”:
```
{
  "id_a": "A123", "id_b": "B456", "dimension": 12, "status": "ok",
  "diffs": [
     {"index":0, "name":"entity_count", "a":10, "b":12, "delta":2, "percent_change":0.2, "normalized_delta":0.1667},
     {"index":1, "name":"bbox_width", "a":100.0, "b":95.0, "delta":-5.0, "percent_change":-0.05, "normalized_delta":0.05}
  ]
}
```
ç”¨äºç›¸ä¼¼æ€§æ£€ç´¢åå®šä½å·®å¼‚æ¥æºä¸å¹…åº¦ã€‚

#### æ¨¡å‹çƒ­é‡è½½ (Model Hot Reload)
ç«¯ç‚¹: `POST /api/v1/analyze/model/reload`
è¯·æ±‚ç¤ºä¾‹:
```
{
  "path": "models/new_classifier.pkl",
  "expected_version": "v2",
  "force": false
}
```
å“åº”ç¤ºä¾‹ (æˆåŠŸ):
```
{
  "status": "success",
  "model_version": "v2",
  "hash": "a1b2c3d4e5f6a7b8"
}
```
å¤±è´¥ (`not_found`): è¿”å›æ‰©å±•é”™è¯¯ä½“ã€‚
æŒ‡æ ‡: `model_reload_total{status,version}`ã€‚

#### æ¼‚ç§»ç›‘æ§ (Drift Monitoring)
ç«¯ç‚¹: `GET /api/v1/analyze/drift`
å­—æ®µ:
- `material_drift_score` / `prediction_drift_score`: PSI è¿‘ä¼¼åˆ†å¸ƒæ¼‚ç§»åˆ†æ•° (0-1)ã€‚
- `baseline_min_count`: å»ºç«‹åŸºçº¿éœ€è¦çš„æœ€å°æ ·æœ¬æ•° (env `DRIFT_BASELINE_MIN_COUNT`, é»˜è®¤100)ã€‚
- `status`: `baseline_pending` æˆ– `ok`ã€‚
æŒ‡æ ‡: `material_distribution_drift_score`ã€`classification_prediction_drift_score` (Histogram)ï¼Œ`baseline_material_age_seconds`ã€`baseline_prediction_age_seconds` (Gauge)ï¼Œ`drift_baseline_created_total{type}` (Counter)ã€‚
å»ºè®®å‘Šè­¦: 15m ç§»åŠ¨å¹³å‡ >0.3 è¿ç»­ä¸‰å‘¨æœŸã€‚
Runbook: `docs/runbooks/drift_monitoring.md` (éœ€åç»­è¡¥å……)ã€‚

#### è§£æé˜¶æ®µè¶…æ—¶ä¿æŠ¤ (Parse Timeout)
ç¯å¢ƒå˜é‡: `PARSE_TIMEOUT_SECONDS` (é»˜è®¤10)ã€‚
è¶…æ—¶è¿”å› 504 + æ‰©å±•é”™è¯¯ç  `TIMEOUT`ï¼Œè®¡æ•°: `parse_timeout_total` ä¸ `analysis_errors_total{stage="parse",code="timeout"}`ã€‚

#### å‘é‡å­¤å„¿æ‰«æ (Orphan Vector Scan)
åå°ä»»åŠ¡å‘¨æœŸ (`VECTOR_ORPHAN_SCAN_INTERVAL_SECONDS`, é»˜è®¤300s) æ£€æµ‹æ— å¯¹åº” `analysis_result:{id}` ç¼“å­˜çš„å‘é‡ã€‚
æŒ‡æ ‡: `vector_orphan_total` (æŒ‰æ‰¹æ¬¡å¢é‡) ä¸ `vector_orphan_scan_last_seconds` (è·ç¦»æœ€è¿‘æ‰«æç§’æ•°)ã€‚
ç”¨äºå‘ç°ç¼“å­˜æ¸…ç†æˆ–è¿ç§»å¼‚å¸¸å¯¼è‡´çš„å¼•ç”¨å¤±é…ã€‚å‘ç°å­¤å„¿æ¯”ä¾‹è¿‡é«˜å¯è§¦å‘è‡ªåŠ¨æ¸…ç†ç­–ç•¥ã€‚

### æ¨¡å‹çƒ­é‡è½½å›æ»šä¸é™åˆ¶ (æ–°å¢)
ç¯å¢ƒå˜é‡: `MODEL_MAX_MB` (é»˜è®¤ 50MB)ã€‚æ¨¡å‹é‡è½½è¿‡ç¨‹å°†æ ¡éªŒæ–‡ä»¶å¤§å°ä¸ `predict` æ–¹æ³•å­˜åœ¨æ€§ï¼Œå¤±è´¥è‡ªåŠ¨å›æ»šæ—§æ¨¡å‹ã€‚
é‡è½½ç«¯ç‚¹: `POST /api/v1/analyze/model/reload`
æ–°å¢çŠ¶æ€:
- `size_exceeded`: æ–‡ä»¶å¤§å°è¶…é™ã€‚
- `rollback`: åŠ è½½å¤±è´¥å·²æ¢å¤æ—§æ¨¡å‹ã€‚
æŒ‡æ ‡æ‰©å±•: `model_reload_total{status="size_exceeded"|"rollback"}`ã€‚

### ç‰¹å¾å‘é‡ç¼“å­˜ (Feature Cache)
ç¯å¢ƒå˜é‡:
- `FEATURE_CACHE_CAPACITY` (é»˜è®¤ 256)
- `FEATURE_CACHE_TTL_SECONDS` (é»˜è®¤ 0 = ä¸è¿‡æœŸ)
ç¼“å­˜å‘½ä¸­è·³è¿‡ç‰¹å¾æå–ï¼›å“åº” `features.cache_hit=true`ã€‚
æŒ‡æ ‡: `feature_cache_hits_total`ã€`feature_cache_miss_total`ã€`feature_cache_evictions_total`ã€`feature_cache_size`ã€‚
å‘½ä¸­ç‡è®°å½•è§„åˆ™ç¤ºä¾‹:
```
record: feature_cache_hit_ratio
expr: sum(rate(feature_cache_hits_total[5m])) / (sum(rate(feature_cache_hits_total[5m])) + sum(rate(feature_cache_miss_total[5m])))
```

### å­¤å„¿å‘é‡æ¸…ç†ç«¯ç‚¹ (Orphan Cleanup)
ç«¯ç‚¹: `DELETE /api/v1/analyze/vectors/orphans?threshold=<n>&force=<bool>&dry_run=<bool>`
å½“å­¤å„¿æ•°é‡ >= threshold æˆ–ä½¿ç”¨ `force=true` æ—¶æ‰§è¡Œæ¸…ç†ï¼›`dry_run=true` ä»…ç»Ÿè®¡ä¸åˆ é™¤ã€‚
è¿”å›: `{"status":"cleaned|skipped|dry_run","cleaned":<æ•°é‡>,"total_orphans_detected":<æ€»æ•°>}`ã€‚
æŒ‡æ ‡: `vector_cold_pruned_total{reason="orphan_cleanup"}`ã€‚
### Faiss å¥åº·æ£€æŸ¥ä¸é™çº§æ¨¡å¼

æ–°å¢ç«¯ç‚¹ `GET /api/v1/health/faiss/health` è¿”å› Faiss ç´¢å¼•çŠ¶æ€å’Œé™çº§ä¿¡æ¯:

**æ­£å¸¸çŠ¶æ€ç¤ºä¾‹:**
```json
{
  "available": true,
  "index_size": 120,
  "dim": 12,
  "age_seconds": 3600,
  "pending_delete": 3,
  "max_pending_delete": 100,
  "normalize": true,
  "status": "ok",
  "degraded": false,
  "degraded_reason": null,
  "degraded_duration_seconds": null,
  "degradation_history_count": 0,
  "degradation_history": null
}
```

**é™çº§çŠ¶æ€ç¤ºä¾‹ (Faiss ä¸å¯ç”¨ï¼Œé™çº§åˆ°å†…å­˜):**
```json
{
  "available": false,
  "index_size": null,
  "dim": null,
  "age_seconds": null,
  "pending_delete": null,
  "max_pending_delete": null,
  "normalize": null,
  "status": "degraded",
  "degraded": true,
  "degraded_reason": "Faiss library unavailable",
  "degraded_duration_seconds": 3600.5,
  "degradation_history_count": 2,
  "degradation_history": [
    {
      "timestamp": 1732460400.123,
      "reason": "Faiss library unavailable",
      "backend_requested": "faiss",
      "backend_actual": "memory"
    },
    {
      "timestamp": 1732464000.456,
      "reason": "Faiss initialization failed: ModuleNotFoundError",
      "backend_requested": "faiss",
      "backend_actual": "memory",
      "error": "ModuleNotFoundError: No module named 'faiss'"
    }
  ]
}
```

**é™çº§æ¨¡å¼è¯´æ˜:**
- å½“ `VECTOR_STORE_BACKEND=faiss` ä½† Faiss åº“ä¸å¯ç”¨æˆ–åˆå§‹åŒ–å¤±è´¥æ—¶ï¼Œç³»ç»Ÿè‡ªåŠ¨é™çº§åˆ°å†…å­˜å‘é‡å­˜å‚¨
- `degraded=true` æ ‡å¿—è¡¨ç¤ºå½“å‰å¤„äºé™çº§æ¨¡å¼
- `degraded_reason` è¯´æ˜é™çº§åŸå› ï¼ˆåº“ä¸å¯ç”¨ / åˆå§‹åŒ–å¤±è´¥ï¼‰
- `degraded_duration_seconds` æ˜¾ç¤ºé™çº§æŒç»­æ—¶é—´
- `degradation_history` è®°å½•æœ€è¿‘10æ¬¡é™çº§äº‹ä»¶ï¼ŒåŒ…å«æ—¶é—´æˆ³ã€åŸå› ã€è¯·æ±‚/å®é™…åç«¯ã€é”™è¯¯ä¿¡æ¯
- `status` ä¼˜å…ˆçº§: `degraded` > `unavailable` > `ok`

ç”¨äºè¿ç»´æŸ¥çœ‹ç´¢å¼•å‘é‡è§„æ¨¡ã€ç»´åº¦ã€è·ç¦»ä¸Šæ¬¡å¯¼å…¥/å¯¼å‡ºæ—¶é—´ã€å¾…åˆ é™¤å‘é‡æ•°é‡é˜ˆå€¼æƒ…å†µä»¥åŠé™çº§çŠ¶æ€ç›‘æ§ã€‚

### Feature Cache ç»Ÿè®¡

ç«¯ç‚¹ `GET /api/v1/features/cache` è¿”å›ç¼“å­˜å¤§å°ã€å‘½ä¸­ç‡ã€TTL ç­‰ä¿¡æ¯ï¼Œè¾…åŠ©è°ƒä¼˜ `FEATURE_CACHE_CAPACITY` ä¸ `FEATURE_CACHE_TTL_SECONDS`ã€‚
### æ¼‚ç§»åŸºçº¿çŠ¶æ€ / è¿‡æœŸ

æ–°å¢ç«¯ç‚¹ `GET /api/v1/drift/baseline/status` è¿”å›åŸºçº¿å¹´é¾„ã€åˆ›å»ºæ—¶é—´ä»¥åŠæ˜¯å¦è¿‡æœŸ (`stale=true/false`)ã€‚å½“è¾¾åˆ° `DRIFT_BASELINE_MAX_AGE_SECONDS` é…ç½®é˜ˆå€¼ä¼šè§¦å‘å‘Šè­¦ `DriftBaselineStale`ï¼Œå‚è€ƒè¿è¡Œæ‰‹å†Œ `docs/runbooks/drift_baseline_stale.md`ã€‚

### æ¨¡å‹å®‰å…¨æ¨¡å¼ä¸ Opcode å®¡è®¡

- ç¯å¢ƒå˜é‡ `MODEL_OPCODE_MODE` æ§åˆ¶æ¨¡å‹é‡è½½çš„å®‰å…¨æ‰«ææ¨¡å¼ï¼š
  - `blacklist`ï¼ˆé»˜è®¤ï¼‰ï¼šé˜»æ­¢å·²çŸ¥å±é™© opcodeï¼ˆå¦‚ GLOBAL/STACK_GLOBAL/REDUCEï¼‰ã€‚
  - `audit`ï¼šä»…è®°å½•è§‚æµ‹åˆ°çš„ opcodeï¼Œä¸é˜»æ­¢ï¼›ç”¨äºç”Ÿäº§å®¡è®¡æœŸã€‚
  - `whitelist`ï¼šåªå…è®¸ç™½åå• opcodeï¼›ä»»ä½•æœªçŸ¥ opcode å°†è¢«é˜»æ­¢ã€‚

- å®¡è®¡æŸ¥è¯¢ç«¯ç‚¹ï¼š`GET /api/v1/model/opcode-audit`ï¼ˆéœ€è¦ `X-API-Key` ä¸ `X-Admin-Token`ï¼‰

  ç¤ºä¾‹å“åº”ï¼š

  {
    "opcodes": ["GLOBAL", "BINUNICODE", "TUPLE"],
    "counts": {"GLOBAL": 3, "BINUNICODE": 12, "TUPLE": 12},
    "sample_count": 15
  }

- ç›¸å…³æŒ‡æ ‡ï¼š
  - `model_opcode_audit_total{opcode}`ï¼šè§‚æµ‹åˆ°çš„ opcode è®¡æ•°ï¼ˆå®¡è®¡/ç™½åå•/é»‘åå•æ¨¡å¼å‡é‡‡é›†ï¼‰ã€‚
  - `model_opcode_whitelist_violations_total{opcode}`ï¼šç™½åå•æ‹’ç»æ¬¡æ•°ã€‚

### Faiss è‡ªåŠ¨æ¢å¤ä¸é™çº§æŒ‡æ ‡

- ç«¯ç‚¹ï¼š
  - `GET /api/v1/health/faiss/health`ï¼šåŒ…å« `degraded`ã€`degraded_reason`ã€`degraded_duration_seconds`ã€`degradation_history`ã€‚
  - `POST /api/v1/faiss/recover`ï¼šæ‰‹åŠ¨è§¦å‘æ¢å¤å°è¯•ï¼ˆéµå¾ªé€€é¿ï¼‰ã€‚

- æŒ‡æ ‡ï¼š
  - `similarity_degraded_total{event="degraded|restored"}`ï¼šé™çº§/æ¢å¤äº‹ä»¶è®¡æ•°ã€‚
  - `faiss_recovery_attempts_total{result="success|skipped|error"}`ï¼šè‡ªåŠ¨/æ‰‹åŠ¨æ¢å¤å°è¯•ç»“æœã€‚
  - `faiss_degraded_duration_seconds`ï¼šå½“å‰é™çº§æŒç»­æ—¶é—´ï¼ˆå¥åº·æ—¶ä¸º 0ï¼‰ã€‚

- å»ºè®® Prometheus è§„åˆ™ï¼ˆç¤ºä¾‹ï¼‰ï¼š

  - alert: VectorStoreDegraded
    expr: faiss_degraded_duration_seconds > 300
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Vector store degraded for > 5min"

  - alert: OpcodeWhitelistViolations
    expr: increase(model_opcode_whitelist_violations_total[10m]) > 0
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "Model reload whitelist violations detected"

### Feature Cache è¿è¡Œæ—¶è°ƒä¼˜ä¸é¢„çƒ­

- ç»Ÿè®¡ç«¯ç‚¹: `GET /api/v1/features/cache` è¿”å›ç¼“å­˜å¤§å°ã€å®¹é‡ã€TTLã€å‘½ä¸­/æœªå‘½ä¸­/é©±é€ç­‰æŒ‡æ ‡ä»¥åŠå‘½ä¸­ç‡ã€‚
- è°ƒä¼˜å»ºè®®: `GET /api/v1/features/cache/tuning` æä¾›å®¹é‡ä¸TTLå»ºè®®å’ŒåŸå› ã€‚
- åº”ç”¨æ–°é…ç½®: `POST /api/v1/features/cache/apply` éœ€è¦ `X-Admin-Token`ï¼Œæ”¯æŒ 5 åˆ†é’Ÿå›æ»šçª—å£ï¼Œè¿”å›å¿«ç…§ä¿¡æ¯ï¼š

  ç¤ºä¾‹å“åº”:

  {
    "status": "applied",
    "applied": {"capacity": 1024, "ttl_seconds": 3600, "evicted": 0},
    "snapshot": {
      "previous_capacity": 256,
      "previous_ttl": 0,
      "applied_at": "2025-11-25T10:30:45.123Z",
      "can_rollback_until": "2025-11-25T10:35:45.123Z"
    }
  }

- å›æ»šæ—§é…ç½®: `POST /api/v1/features/cache/rollback` éœ€è¦ `X-Admin-Token`ï¼Œåœ¨çª—å£å†…æ¢å¤ä¹‹å‰çš„å®¹é‡/TTLã€‚
- é¢„çƒ­ç¼“å­˜: `POST /api/v1/features/cache/prewarm?strategy=auto&limit=50` éœ€è¦ `X-Admin-Token`ï¼Œä»¥ LRU è§¦ç¢°æ–¹å¼é¢„çƒ­ï¼Œè¿”å›è§¦ç¢°æ¡ç›®æ•°é‡ã€‚

å®‰å…¨: ä»¥ä¸Šä¸‰ä¸ªå†™ç«¯ç‚¹å‡è¦æ±‚åŒé‡è®¤è¯ï¼ˆ`X-API-Key` + `X-Admin-Token`ï¼‰ã€‚
#### åç«¯é‡è½½

å¼ºåˆ¶é‡æ–°é€‰æ‹©å‘é‡å­˜å‚¨åç«¯ï¼ˆä¾‹å¦‚åˆ‡æ¢ä¸º Faiss åéœ€è¦çƒ­é‡è½½ï¼‰:
```bash
curl -X POST http://localhost:8000/api/v1/maintenance/vectors/backend/reload -H "X-API-Key: test"
```
å“åº”:
```json
{"status":"ok","backend":"memory"}
```
æŒ‡æ ‡: `vector_store_reload_total{status="success|error"}`

---

## ğŸ”¥ å‹åŠ›æµ‹è¯•è„šæœ¬ (Stress Test Scripts)

ä½äº `scripts/` ç›®å½•çš„å‹åŠ›æµ‹è¯•è„šæœ¬ç”¨äºéªŒè¯ç³»ç»Ÿåœ¨é«˜å¹¶å‘å’Œæ•…éšœåœºæ™¯ä¸‹çš„ç¨³å®šæ€§ã€‚

### stress_concurrency_reload.py

å¹¶å‘æ¨¡å‹é‡è½½å‹åŠ›æµ‹è¯•ï¼ŒéªŒè¯ `_MODEL_LOCK` æœ‰æ•ˆæ€§å’Œ `load_seq` å•è°ƒé€’å¢ã€‚

```bash
# åŸºæœ¬ç”¨æ³•
python scripts/stress_concurrency_reload.py --threads 10 --iterations 10

# ç¯å¢ƒå˜é‡é…ç½®
export STRESS_API_URL=http://localhost:8000
export STRESS_API_KEY=your-api-key
export STRESS_ADMIN_TOKEN=your-admin-token

# ä¸¥æ ¼æ¨¡å¼ï¼ˆä»»ä½•å¼‚å¸¸å³å¤±è´¥ï¼‰
python scripts/stress_concurrency_reload.py --strict
```

è¾“å‡ºç¤ºä¾‹ï¼š
```
STRESS TEST RESULTS
Total time: 15.2s | Throughput: 6.6 req/s
Load sequence monotonicity: monotonic (1 -> 100)
VERDICT: PASS - No concurrency issues detected
```

### stress_memory_gc_check.py

å†…å­˜æ³„æ¼æ£€æµ‹è„šæœ¬ï¼Œç›‘æ§ RSS å†…å­˜å¢é•¿å’Œ GC å›æ”¶æ•ˆç‡ã€‚

```bash
# åŸºæœ¬ç”¨æ³•
python scripts/stress_memory_gc_check.py --iterations 50 --allocation-mb 10

# ç¯å¢ƒå˜é‡é…ç½®
export STRESS_API_URL=http://localhost:8000
export STRESS_API_KEY=your-api-key
```

### stress_degradation_flapping.py

é™çº§çŠ¶æ€ç¿»è½¬è§‚æµ‹è„šæœ¬ï¼Œç›‘æ§ Faiss å¯ç”¨æ€§åˆ‡æ¢æ—¶çš„æŒ‡æ ‡ä¸€è‡´æ€§ã€‚

> **æ•°æ®æºè¯´æ˜**: è„šæœ¬ä¼˜å…ˆä½¿ç”¨å¥åº·ç«¯ç‚¹ (`/api/v1/health/vectors`) çš„ `degradation_history_count` å­—æ®µï¼ˆæƒå¨æ¥æºï¼Œé™åˆ¶ â‰¤10ï¼‰ï¼ŒPrometheus `/metrics` ç”¨äºè·å– `similarity_degraded_total` è®¡æ•°å™¨å’Œ `faiss_degraded_duration_seconds` æ—¶é•¿æŒ‡æ ‡ã€‚

```bash
# åŸºæœ¬ç”¨æ³•
python scripts/stress_degradation_flapping.py --cycles 20 --interval 1.0

# ç¯å¢ƒå˜é‡é…ç½®
export STRESS_API_URL=http://localhost:8000
export STRESS_API_KEY=your-api-key

# è‡ªå®šä¹‰å‚æ•°
python scripts/stress_degradation_flapping.py --url http://staging:8000 --cycles 50 --interval 0.5
```

**éªŒè¯å†…å®¹ï¼š**
- `similarity_degraded_total{event="degraded|restored"}` è®¡æ•°å™¨é€’å¢
- `faiss_degraded_duration_seconds` æŒ‡æ ‡è¡Œä¸º
- é™çº§å†å² (`degradation_history_count`) é™åˆ¶åœ¨ â‰¤10 æ¡
- å¥åº·ç«¯ç‚¹ (`/api/v1/health/vectors`) ä¸€è‡´æ€§

è¾“å‡ºç¤ºä¾‹ï¼š
```
FLAPPING TEST RESULTS
Total cycles: 20 | Successful: 20 | Errors: 0
Degraded events observed: 0 -> 5
Restored events observed: 0 -> 4
Max history count observed: 9
VERDICT: PASS - Degradation metrics consistent
```

### é›†æˆæµ‹è¯•

é…å¥—çš„é›†æˆæµ‹è¯•ä½äº `tests/integration/test_stress_stability.py`ï¼ŒåŒ…å«ï¼š
- `TestConcurrentReload`: å¹¶å‘é‡è½½é”æœ‰æ•ˆæ€§ã€load_seq å•è°ƒæ€§ã€æ­»é”æ£€æµ‹
- `TestMemoryStability`: GC å›æ”¶ã€æ¨¡å‹é‡è½½å†…å­˜ç¨³å®šæ€§
- `TestDegradationState`: é™çº§çŠ¶æ€å˜é‡ã€å†å²é™åˆ¶ã€get_degraded_mode_info
- `TestFeatureExtractionStress`: å¹¶å‘ç‰¹å¾æå–çº¿ç¨‹å®‰å…¨
- `TestCacheStress`: ç¼“å­˜å¹¶å‘è®¿é—®ã€é©±é€ç­–ç•¥

è¿è¡Œé›†æˆæµ‹è¯•ï¼š
```bash
pytest tests/integration/test_stress_stability.py -v
```
