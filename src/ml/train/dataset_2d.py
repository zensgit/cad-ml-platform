"""
DXF Dataset Loader (2D).

Loads synthetic DXF data and labels for GNN training.
Converts raw entities (Lines, Circles) into a Graph structure.
"""

import csv
import json
import logging
import os
from typing import Any, Dict, List, Tuple

import ezdxf
import torch
from torch.utils.data import Dataset

logger = logging.getLogger(__name__)

# Feature dimensions (Contract)
# Node: [is_line, is_circle, length/radius, center_x, center_y, dir_x, dir_y,
#        border_hint, title_block_hint] -> 9 dim
DXF_NODE_DIM = 9


class DXFDataset(Dataset):
    """
    PyTorch Dataset for 2D DXF Drawings.
    Reads labels.json generated by the synthetic generator.
    """

    def __init__(self, root_dir: str, transform=None, node_dim: int = DXF_NODE_DIM):
        """
        Args:
            root_dir (str): Directory containing .dxf files and labels.json.
        """
        self.root_dir = root_dir
        self.transform = transform
        self.node_dim = node_dim
        self.samples = []

        label_path = os.path.join(root_dir, "labels.json")
        if os.path.exists(label_path):
            with open(label_path, "r") as f:
                self.samples = json.load(f)
        elif self.root_dir not in {".", ""}:
            logger.warning(f"Labels not found at {label_path}. Dataset empty.")

    def __len__(self) -> int:
        return len(self.samples)

    def __getitem__(self, idx: int) -> Tuple[Dict[str, Any], torch.Tensor]:
        item = self.samples[idx]
        file_name = item["file"]
        file_path = os.path.join(self.root_dir, file_name)
        
        # Target: For this simple task, let's predict the number of holes (features count)
        # or classify if it has a specific feature.
        # Let's try: Count of Holes (Regression) or Has Slot (Classification)
        # Here: Classify "Has Slot" (0 or 1)
        features = item.get("features", [])
        has_slot = any(f["type"] == "slot" for f in features)
        label = torch.tensor([1.0 if has_slot else 0.0], dtype=torch.float)

        try:
            doc = ezdxf.readfile(file_path)
            msp = doc.modelspace()
            
            # Build Graph
            x, edge_index = self._dxf_to_graph(msp, self.node_dim)
            
            return {
                "x": x, 
                "edge_index": edge_index,
                "file_name": file_name
            }, label.long().squeeze()

        except Exception as e:
            logger.error(f"Error parsing {file_name}: {e}")
            # Return empty graph on error
            return {
                "x": torch.zeros(0, DXF_NODE_DIM), 
                "edge_index": torch.zeros(2, 0, dtype=torch.long)
            }, label.long().squeeze()

    def _dxf_to_graph(self, msp, node_dim: int | None = None) -> Tuple[torch.Tensor, torch.Tensor]:
        """Convert DXF entities to Node Features and Adjacency."""
        nodes = []
        # Build adjacency by shared endpoints (approx) to keep topology meaningful.
        
        entities = list(msp)
        # Filter supported entities
        valid_entities = [e for e in entities if e.dxftype() in ["LINE", "CIRCLE", "LWPOLYLINE"]]
        
        # Limit graph size for stability
        max_nodes = 50
        valid_entities = valid_entities[:max_nodes]

        keypoints: List[List[Tuple[float, float]]] = []
        all_points: List[Tuple[float, float]] = []

        node_meta: List[Dict[str, Any]] = []

        for e in valid_entities:
            feat = [0.0] * 7
            dtype = e.dxftype()
            pts: List[Tuple[float, float]] = []
            length = 0.0
            mid_x = 0.0
            mid_y = 0.0
            
            if dtype == "LINE":
                feat[0] = 1.0
                start = e.dxf.start
                end = e.dxf.end
                length = start.distance(end)
                feat[2] = length / 100.0  # Normalize
                # Center
                mid = (start + end) / 2
                mid_x = mid.x
                mid_y = mid.y
                feat[3] = mid_x / 200.0
                feat[4] = mid_y / 200.0
                # Direction
                if length > 1e-9:
                    d = (end - start).normalize()
                    feat[5] = d.x
                    feat[6] = d.y
                pts = [(float(start.x), float(start.y)), (float(end.x), float(end.y))]
                
            elif dtype == "CIRCLE":
                feat[1] = 1.0
                r = e.dxf.radius
                length = r * 2.0
                mid_x = float(e.dxf.center.x)
                mid_y = float(e.dxf.center.y)
                feat[2] = r / 50.0
                feat[3] = mid_x / 200.0
                feat[4] = mid_y / 200.0
                pts = [(float(e.dxf.center.x), float(e.dxf.center.y))]
                
            elif dtype == "LWPOLYLINE":
                # Treat polyline as a single complex node for now
                feat[0] = 0.5  # kind of a line?
                feat[1] = 0.5
                pts = [(float(p[0]), float(p[1])) for p in e.get_points()]
                if pts:
                    mid_x = pts[0][0]
                    mid_y = pts[0][1]
                    feat[3] = mid_x / 200.0
                    feat[4] = mid_y / 200.0
                    for a, b in zip(pts[:-1], pts[1:]):
                        dx = b[0] - a[0]
                        dy = b[1] - a[1]
                        length += (dx * dx + dy * dy) ** 0.5

            nodes.append(feat)
            keypoints.append(pts)
            all_points.extend(pts)
            node_meta.append(
                {
                    "dtype": dtype,
                    "length": float(length),
                    "mid": (float(mid_x), float(mid_y)),
                }
            )

        if not nodes:
            return torch.zeros(0, DXF_NODE_DIM), torch.zeros(2, 0, dtype=torch.long)

        node_dim = node_dim or DXF_NODE_DIM
        extra_dims = max(0, node_dim - 7)
        if extra_dims:
            xs = [p[0] for p in all_points] if all_points else [0.0]
            ys = [p[1] for p in all_points] if all_points else [0.0]
            min_x, max_x = min(xs), max(xs)
            min_y, max_y = min(ys), max(ys)
            width = max(max_x - min_x, 1.0)
            height = max(max_y - min_y, 1.0)
            max_dim = max(width, height, 1.0)
            tol = max_dim * 0.02
            for feat, meta, pts in zip(nodes, node_meta, keypoints):
                border_hint = 0.0
                title_hint = 0.0
                if meta["dtype"] in {"LINE", "LWPOLYLINE"}:
                    if meta["length"] >= 0.8 * max_dim and pts:
                        for px, py in pts:
                            if (
                                abs(px - min_x) <= tol
                                or abs(px - max_x) <= tol
                                or abs(py - min_y) <= tol
                                or abs(py - max_y) <= tol
                            ):
                                border_hint = 1.0
                                break
                    mx, my = meta["mid"]
                    if (
                        meta["length"] <= 0.5 * max_dim
                        and mx >= min_x + 0.6 * width
                        and my <= min_y + 0.4 * height
                    ):
                        title_hint = 1.0
                extras = [border_hint, title_hint]
                if extra_dims > 2:
                    extras.extend([0.0] * (extra_dims - 2))
                feat.extend(extras[:extra_dims])

        x = torch.tensor(nodes, dtype=torch.float)
        
        num_nodes = len(nodes)
        if num_nodes <= 1:
            return x, torch.zeros(2, 0, dtype=torch.long)

        eps = 1e-3
        if all_points:
            xs = [p[0] for p in all_points]
            ys = [p[1] for p in all_points]
            dx = max(xs) - min(xs)
            dy = max(ys) - min(ys)
            scale = max(dx, dy, 1.0)
            eps = max(eps, scale * 1e-3)

        edges: List[Tuple[int, int]] = []
        for i in range(num_nodes):
            for j in range(i + 1, num_nodes):
                connected = False
                for p1 in keypoints[i]:
                    for p2 in keypoints[j]:
                        dx = p1[0] - p2[0]
                        dy = p1[1] - p2[1]
                        if (dx * dx + dy * dy) <= eps * eps:
                            connected = True
                            break
                    if connected:
                        break
                if connected:
                    edges.append((i, j))
                    edges.append((j, i))

        if not edges:
            # Fallback to fully connected if no adjacency detected.
            row = torch.arange(num_nodes).repeat_interleave(num_nodes)
            col = torch.arange(num_nodes).repeat(num_nodes)
            mask = row != col
            edge_index = torch.stack([row[mask], col[mask]], dim=0)
            return x, edge_index

        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()

        return x, edge_index


class DXFManifestDataset(Dataset):
    """DXF dataset backed by a manifest CSV (weak labels from filenames)."""

    def __init__(
        self,
        manifest_csv: str,
        dxf_dir: str,
        label_map: Dict[str, int] | None = None,
        node_dim: int = DXF_NODE_DIM,
    ):
        self.manifest_csv = manifest_csv
        self.dxf_dir = dxf_dir
        self.samples: List[Dict[str, Any]] = []
        self.label_map = label_map or {}
        self.node_dim = node_dim

        with open(manifest_csv, "r", encoding="utf-8") as handle:
            reader = csv.DictReader(handle)
            for row in reader:
                if not row:
                    continue
                label = (row.get("label_cn") or "").strip()
                file_name = (row.get("file_name") or "").strip()
                if not label or not file_name:
                    continue
                if label not in self.label_map:
                    self.label_map[label] = len(self.label_map)
                self.samples.append(
                    {
                        "file_name": file_name,
                        "label": label,
                        "label_id": self.label_map[label],
                    }
                )

    def __len__(self) -> int:
        return len(self.samples)

    def __getitem__(self, idx: int) -> Tuple[Dict[str, Any], torch.Tensor]:
        item = self.samples[idx]
        file_name = item["file_name"]
        stem = os.path.splitext(file_name)[0]
        file_path = os.path.join(self.dxf_dir, f"{stem}.dxf")
        label = torch.tensor(item["label_id"], dtype=torch.long)

        try:
            doc = ezdxf.readfile(file_path)
            msp = doc.modelspace()
            x, edge_index = self._dxf_to_graph(msp, self.node_dim)
            return {"x": x, "edge_index": edge_index, "file_name": file_name}, label
        except Exception as e:
            logger.error(f"Error parsing {file_name}: {e}")
            return {
                "x": torch.zeros(0, DXF_NODE_DIM),
                "edge_index": torch.zeros(2, 0, dtype=torch.long),
                "file_name": file_name,
            }, label

    def get_label_map(self) -> Dict[str, int]:
        return dict(self.label_map)

    def _dxf_to_graph(self, msp, node_dim: int | None = None) -> Tuple[torch.Tensor, torch.Tensor]:
        # Reuse graph builder from DXFDataset
        return DXFDataset._dxf_to_graph(self, msp, node_dim=node_dim)
