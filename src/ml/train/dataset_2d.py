"""
DXF Dataset Loader (2D).

Loads synthetic DXF data and labels for GNN training.
Converts raw entities (Lines, Circles) into a Graph structure.
"""

import csv
import hashlib
import json
import logging
import math
import os
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple, Union

import ezdxf
import torch
from torch.utils.data import Dataset

logger = logging.getLogger(__name__)

# Feature dimensions (Contract)
DXF_NODE_FEATURES_LEGACY = (
    "is_line",
    "is_circle",
    "length_norm",
    "center_x_norm",
    "center_y_norm",
    "dir_x",
    "dir_y",
    "border_hint",
    "title_block_hint",
)

DXF_NODE_FEATURES = (
    "is_line",
    "is_circle",
    "is_arc",
    "is_polyline",
    "is_text",
    "is_dimension",
    "is_insert",
    "length_norm",
    "radius_norm",
    "center_x_norm",
    "center_y_norm",
    "dir_x",
    "dir_y",
    "layer_norm",
    "color_norm",
    "text_density",
    "border_hint",
    "title_block_hint",
    "is_closed",
)

DXF_NODE_DIM = len(DXF_NODE_FEATURES)
DXF_EDGE_FEATURES = (
    "dx_norm",
    "dy_norm",
    "dist_norm",
    "dir_dot",
    "layer_diff",
    "color_diff",
    "same_type",
)
DXF_EDGE_DIM = len(DXF_EDGE_FEATURES)


class DXFDataset(Dataset):
    """
    PyTorch Dataset for 2D DXF Drawings.
    Reads labels.json generated by the synthetic generator.
    """

    def __init__(
        self,
        root_dir: str,
        transform=None,
        node_dim: int = DXF_NODE_DIM,
        return_edge_attr: bool = False,
    ):
        """
        Args:
            root_dir (str): Directory containing .dxf files and labels.json.
        """
        self.root_dir = root_dir
        self.transform = transform
        self.node_dim = node_dim
        self.return_edge_attr = return_edge_attr
        self.samples = []

        label_path = os.path.join(root_dir, "labels.json")
        if os.path.exists(label_path):
            with open(label_path, "r") as f:
                self.samples = json.load(f)
        elif self.root_dir not in {".", ""}:
            logger.warning(f"Labels not found at {label_path}. Dataset empty.")

    def __len__(self) -> int:
        return len(self.samples)

    def __getitem__(self, idx: int) -> Tuple[Dict[str, Any], torch.Tensor]:
        item = self.samples[idx]
        file_name = item["file"]
        file_path = os.path.join(self.root_dir, file_name)

        # Target: For this simple task, let's predict the number of holes (features count)
        # or classify if it has a specific feature.
        # Let's try: Count of Holes (Regression) or Has Slot (Classification)
        # Here: Classify "Has Slot" (0 or 1)
        features = item.get("features", [])
        has_slot = any(f["type"] == "slot" for f in features)
        label = torch.tensor([1.0 if has_slot else 0.0], dtype=torch.float)

        try:
            doc = ezdxf.readfile(file_path)
            msp = doc.modelspace()

            # Build Graph
            if self.return_edge_attr:
                x, edge_index, edge_attr = self._dxf_to_graph(
                    msp, self.node_dim, return_edge_attr=True
                )
                return {
                    "x": x,
                    "edge_index": edge_index,
                    "edge_attr": edge_attr,
                    "file_name": file_name,
                }, label.long().squeeze()

            x, edge_index = self._dxf_to_graph(msp, self.node_dim)
            return {
                "x": x,
                "edge_index": edge_index,
                "file_name": file_name,
            }, label.long().squeeze()

        except Exception as e:
            logger.error(f"Error parsing {file_name}: {e}")
            # Return empty graph on error
            empty_graph = {
                "x": torch.zeros(0, self.node_dim),
                "edge_index": torch.zeros(2, 0, dtype=torch.long),
            }
            if self.return_edge_attr:
                empty_graph["edge_attr"] = torch.zeros(0, DXF_EDGE_DIM)
            return empty_graph, label.long().squeeze()

    def _dxf_to_graph(
        self, msp, node_dim: Optional[int] = None, return_edge_attr: bool = False
    ) -> Union[
        Tuple[torch.Tensor, torch.Tensor],
        Tuple[torch.Tensor, torch.Tensor, torch.Tensor],
    ]:
        """Convert DXF entities to Node Features and Adjacency."""
        node_dim = node_dim or DXF_NODE_DIM
        legacy_mode = node_dim <= len(DXF_NODE_FEATURES_LEGACY)
        enhanced_keypoints = (
            os.getenv("DXF_ENHANCED_KEYPOINTS", "false").strip().lower()
            in {"1", "true", "yes", "on"}
        )

        entities = list(msp)
        valid_types = {
            "LINE",
            "CIRCLE",
            "ARC",
            "LWPOLYLINE",
            "TEXT",
            "MTEXT",
            "DIMENSION",
            "INSERT",
        }
        valid_entities = [e for e in entities if e.dxftype() in valid_types]

        if valid_entities:
            try:
                from src.ml.importance_sampler import get_importance_sampler

                sampler = get_importance_sampler()
                sampled = sampler.sample(valid_entities)
                valid_entities = sampled.sampled_entities
            except Exception as exc:
                logger.warning(
                    "Importance sampling failed, using raw entities: %s", exc
                )

        if not valid_entities:
            empty_x = torch.zeros(0, node_dim)
            empty_edge = torch.zeros(2, 0, dtype=torch.long)
            if return_edge_attr:
                return empty_x, empty_edge, torch.zeros(0, DXF_EDGE_DIM)
            return empty_x, empty_edge

        doc = getattr(msp, "doc", None)
        layer_names: List[str] = []
        if doc is not None:
            try:
                layer_names = list(doc.layers.names())
            except Exception:
                try:
                    layer_names = [
                        layer.dxf.name for layer in doc.layers  # type: ignore[attr-defined]
                    ]
                except Exception:
                    layer_names = []
        layer_index = {name: idx for idx, name in enumerate(layer_names)}
        layer_count = max(1, len(layer_index))

        node_meta: List[Dict[str, Any]] = []
        all_points: List[Tuple[float, float]] = []
        text_lengths: List[float] = []

        for e in valid_entities:
            dtype = e.dxftype()
            pts: List[Tuple[float, float]] = []
            length = 0.0
            radius = 0.0
            center_x = 0.0
            center_y = 0.0
            dir_x = 0.0
            dir_y = 0.0
            text_len = 0.0
            is_closed = 0.0

            if dtype == "LINE":
                start = e.dxf.start
                end = e.dxf.end
                length = float(start.distance(end))
                mid = (start + end) / 2
                center_x = float(mid.x)
                center_y = float(mid.y)
                if length > 1e-9:
                    d = (end - start).normalize()
                    dir_x = float(d.x)
                    dir_y = float(d.y)
                pts = [(float(start.x), float(start.y)), (float(end.x), float(end.y))]
            elif dtype == "CIRCLE":
                center = e.dxf.center
                radius = float(e.dxf.radius)
                length = radius * 2.0
                center_x = float(center.x)
                center_y = float(center.y)
                pts = [(center_x, center_y)]
                if enhanced_keypoints and radius > 0:
                    # Cardinal points help circles connect to surrounding geometry.
                    pts.extend(
                        [
                            (center_x + radius, center_y),
                            (center_x - radius, center_y),
                            (center_x, center_y + radius),
                            (center_x, center_y - radius),
                        ]
                    )
            elif dtype == "ARC":
                center = e.dxf.center
                radius = float(e.dxf.radius)
                center_x = float(center.x)
                center_y = float(center.y)
                start_angle = math.radians(float(e.dxf.start_angle))
                end_angle = math.radians(float(e.dxf.end_angle))
                delta = end_angle - start_angle
                if delta < 0:
                    delta += 2 * math.pi
                length = abs(radius * delta)
                sx = center_x + radius * math.cos(start_angle)
                sy = center_y + radius * math.sin(start_angle)
                ex = center_x + radius * math.cos(end_angle)
                ey = center_y + radius * math.sin(end_angle)
                pts = [(sx, sy), (ex, ey)]
                if enhanced_keypoints and radius > 0 and delta > 1e-9:
                    mid_angle = start_angle + delta * 0.5
                    mx = center_x + radius * math.cos(mid_angle)
                    my = center_y + radius * math.sin(mid_angle)
                    pts.append((mx, my))
                dx = ex - sx
                dy = ey - sy
                norm = math.hypot(dx, dy)
                if norm > 1e-9:
                    dir_x = dx / norm
                    dir_y = dy / norm
            elif dtype == "LWPOLYLINE":
                pts = [(float(p[0]), float(p[1])) for p in e.get_points()]
                is_closed = 1.0 if getattr(e, "closed", False) else 0.0
                if pts:
                    center_x = sum(p[0] for p in pts) / len(pts)
                    center_y = sum(p[1] for p in pts) / len(pts)
                    for a, b in zip(pts[:-1], pts[1:]):
                        dx = b[0] - a[0]
                        dy = b[1] - a[1]
                        length += math.hypot(dx, dy)
                    if is_closed and len(pts) > 1:
                        dx = pts[0][0] - pts[-1][0]
                        dy = pts[0][1] - pts[-1][1]
                        length += math.hypot(dx, dy)
            elif dtype in {"TEXT", "MTEXT"}:
                if dtype == "TEXT":
                    raw_text = str(getattr(e.dxf, "text", "") or "")
                else:
                    raw_text = str(getattr(e, "plain_text", lambda: "")() or "")
                    if not raw_text:
                        raw_text = str(getattr(e, "text", "") or "")
                text_len = float(len(raw_text.strip()))
                insert = getattr(e.dxf, "insert", None) or getattr(
                    e.dxf, "location", None
                )
                if insert is not None:
                    center_x = float(insert.x)
                    center_y = float(insert.y)
                height = float(getattr(e.dxf, "height", 1.0) or 1.0)
                length = text_len * height
                pts = [(center_x, center_y)]
            elif dtype == "DIMENSION":
                raw_text = str(getattr(e.dxf, "text", "") or "")
                text_len = float(len(raw_text.strip()))
                measurement = float(getattr(e.dxf, "measurement", 0.0) or 0.0)
                length = measurement if measurement > 0 else text_len
                point = (
                    getattr(e.dxf, "text_midpoint", None)
                    or getattr(e.dxf, "defpoint", None)
                    or getattr(e.dxf, "insert", None)
                )
                if point is not None:
                    center_x = float(point.x)
                    center_y = float(point.y)
                pts = [(center_x, center_y)]
            elif dtype == "INSERT":
                insert = getattr(e.dxf, "insert", None)
                if insert is not None:
                    center_x = float(insert.x)
                    center_y = float(insert.y)
                xscale = float(getattr(e.dxf, "xscale", 1.0) or 1.0)
                yscale = float(getattr(e.dxf, "yscale", 1.0) or 1.0)
                length = max(abs(xscale), abs(yscale))
                pts = [(center_x, center_y)]

            if not pts:
                pts = [(center_x, center_y)]

            layer_name = str(getattr(e.dxf, "layer", "") or "")
            layer_idx = layer_index.get(layer_name, 0)
            layer_norm = layer_idx / max(1, layer_count - 1)

            color_value = float(getattr(e.dxf, "color", 256) or 256)
            if color_value in {0.0, 256.0} and doc is not None and layer_name:
                try:
                    layer_color = float(doc.layers.get(layer_name).dxf.color)
                    if layer_color:
                        color_value = layer_color
                except Exception:
                    pass
            color_norm = max(0.0, min(color_value, 256.0)) / 256.0

            node_meta.append(
                {
                    "dtype": dtype,
                    "length": float(length),
                    "radius": float(radius),
                    "center": (float(center_x), float(center_y)),
                    "direction": (float(dir_x), float(dir_y)),
                    "pts": pts,
                    "layer_norm": float(layer_norm),
                    "color_norm": float(color_norm),
                    "text_len": float(text_len),
                    "is_closed": float(is_closed),
                }
            )
            all_points.extend(pts)
            text_lengths.append(float(text_len))

        max_text_len = max(text_lengths) if text_lengths else 0.0

        xs = [p[0] for p in all_points] if all_points else [0.0]
        ys = [p[1] for p in all_points] if all_points else [0.0]
        min_x, max_x = min(xs), max(xs)
        min_y, max_y = min(ys), max(ys)
        width = max(max_x - min_x, 1.0)
        height = max(max_y - min_y, 1.0)
        max_dim = max(width, height, 1.0)
        tol = max_dim * 0.02

        nodes: List[List[float]] = []
        keypoints: List[List[Tuple[float, float]]] = []

        for meta in node_meta:
            dtype = meta["dtype"]
            length = meta["length"]
            radius = meta["radius"]
            center_x, center_y = meta["center"]
            dir_x, dir_y = meta["direction"]
            pts = meta["pts"]
            layer_norm = meta["layer_norm"]
            color_norm = meta["color_norm"]
            text_len = meta["text_len"]
            is_closed = meta["is_closed"]

            border_hint = 0.0
            title_hint = 0.0
            if dtype in {"LINE", "LWPOLYLINE"}:
                if length >= 0.8 * max_dim and pts:
                    for px, py in pts:
                        if (
                            abs(px - min_x) <= tol
                            or abs(px - max_x) <= tol
                            or abs(py - min_y) <= tol
                            or abs(py - max_y) <= tol
                        ):
                            border_hint = 1.0
                            break
                if (
                    length <= 0.5 * max_dim
                    and center_x >= min_x + 0.6 * width
                    and center_y <= min_y + 0.4 * height
                ):
                    title_hint = 1.0

            if legacy_mode:
                is_line = 1.0 if dtype == "LINE" else 0.0
                is_circle = 1.0 if dtype == "CIRCLE" else 0.0
                if dtype == "LWPOLYLINE":
                    is_line = 0.5
                    is_circle = 0.5
                if dtype == "ARC":
                    is_circle = 1.0
                if dtype in {"CIRCLE", "ARC"}:
                    length_norm = radius / 50.0 if radius > 0 else 0.0
                else:
                    length_norm = length / 100.0 if length > 0 else 0.0
                feat = [
                    is_line,
                    is_circle,
                    length_norm,
                    center_x / 200.0,
                    center_y / 200.0,
                    dir_x,
                    dir_y,
                    border_hint,
                    title_hint,
                ]
            else:
                text_density = text_len / max_text_len if max_text_len > 0 else 0.0
                feat = [
                    1.0 if dtype == "LINE" else 0.0,
                    1.0 if dtype == "CIRCLE" else 0.0,
                    1.0 if dtype == "ARC" else 0.0,
                    1.0 if dtype == "LWPOLYLINE" else 0.0,
                    1.0 if dtype in {"TEXT", "MTEXT"} else 0.0,
                    1.0 if dtype == "DIMENSION" else 0.0,
                    1.0 if dtype == "INSERT" else 0.0,
                    length / max_dim if max_dim > 0 else 0.0,
                    radius / max_dim if max_dim > 0 else 0.0,
                    (center_x - min_x) / max_dim if max_dim > 0 else 0.0,
                    (center_y - min_y) / max_dim if max_dim > 0 else 0.0,
                    dir_x,
                    dir_y,
                    layer_norm,
                    color_norm,
                    text_density,
                    border_hint,
                    title_hint,
                    is_closed,
                ]

            if node_dim > len(feat):
                feat.extend([0.0] * (node_dim - len(feat)))
            else:
                feat = feat[:node_dim]

            nodes.append(feat)
            keypoints.append(pts)

        x = torch.tensor(nodes, dtype=torch.float)

        num_nodes = len(nodes)
        if num_nodes <= 1:
            empty_edge = torch.zeros(2, 0, dtype=torch.long)
            if return_edge_attr:
                return x, empty_edge, torch.zeros(0, DXF_EDGE_DIM)
            return x, empty_edge

        eps = max(1e-3, max_dim * 1e-3)

        def _edge_feature(i: int, j: int) -> List[float]:
            meta_i = node_meta[i]
            meta_j = node_meta[j]
            cx_i, cy_i = meta_i["center"]
            cx_j, cy_j = meta_j["center"]
            dx = (cx_j - cx_i) / max_dim if max_dim > 0 else 0.0
            dy = (cy_j - cy_i) / max_dim if max_dim > 0 else 0.0
            dist = math.sqrt(dx * dx + dy * dy)
            dir_i = meta_i["direction"]
            dir_j = meta_j["direction"]
            dir_dot = dir_i[0] * dir_j[0] + dir_i[1] * dir_j[1]
            layer_diff = abs(meta_i["layer_norm"] - meta_j["layer_norm"])
            color_diff = abs(meta_i["color_norm"] - meta_j["color_norm"])
            same_type = 1.0 if meta_i["dtype"] == meta_j["dtype"] else 0.0
            return [dx, dy, dist, dir_dot, layer_diff, color_diff, same_type]

        edges: List[Tuple[int, int]] = []
        edge_features: List[List[float]] = []
        for i in range(num_nodes):
            for j in range(i + 1, num_nodes):
                connected = False
                for p1 in keypoints[i]:
                    for p2 in keypoints[j]:
                        dx = p1[0] - p2[0]
                        dy = p1[1] - p2[1]
                        if (dx * dx + dy * dy) <= eps * eps:
                            connected = True
                            break
                    if connected:
                        break
                if connected:
                    edges.append((i, j))
                    edges.append((j, i))
                    if return_edge_attr:
                        edge_features.append(_edge_feature(i, j))
                        edge_features.append(_edge_feature(j, i))

        # Optional edge augmentation: add kNN edges on entity centers even when the
        # epsilon-adjacency graph is non-empty. This helps avoid "island" nodes in
        # sparse graphs and provides more consistent neighborhood structure for
        # message passing models.
        augment_raw = os.getenv("DXF_EDGE_AUGMENT_KNN_K", "").strip()
        try:
            augment_k = int(augment_raw) if augment_raw else 0
        except Exception:
            augment_k = 0
        augment_strategy = (
            os.getenv("DXF_EDGE_AUGMENT_STRATEGY", "union_all").strip().lower()
        )
        if augment_strategy not in {"union_all", "isolates_only"}:
            augment_strategy = "union_all"

        if augment_k > 0 and edges:
            k = max(1, min(int(augment_k), num_nodes - 1))
            edge_set: set[Tuple[int, int]] = set(edges)

            augment_nodes: List[int]
            if augment_strategy == "isolates_only":
                # Treat the epsilon-adjacency edges as undirected because we add
                # edges in both directions above. A node is "isolated" if it has
                # zero outgoing edges in the current directed list.
                degrees = [0] * num_nodes
                for src, _dst in edges:
                    degrees[src] += 1
                augment_nodes = [idx for idx, deg in enumerate(degrees) if deg == 0]
            else:
                augment_nodes = list(range(num_nodes))

            for i in augment_nodes:
                cx_i, cy_i = node_meta[i]["center"]
                dists: List[Tuple[float, int]] = []
                for j in range(num_nodes):
                    if i == j:
                        continue
                    cx_j, cy_j = node_meta[j]["center"]
                    dx = cx_j - cx_i
                    dy = cy_j - cy_i
                    dists.append((dx * dx + dy * dy, j))
                dists.sort(key=lambda t: t[0])
                for _dist2, j in dists[:k]:
                    if (i, j) not in edge_set:
                        edge_set.add((i, j))
                        edges.append((i, j))
                        if return_edge_attr:
                            edge_features.append(_edge_feature(i, j))
                    if (j, i) not in edge_set:
                        edge_set.add((j, i))
                        edges.append((j, i))
                        if return_edge_attr:
                            edge_features.append(_edge_feature(j, i))

        if not edges:
            fallback = (
                os.getenv("DXF_EMPTY_EDGE_FALLBACK", "fully_connected").strip().lower()
            )
            if fallback in {"knn", "k_nn", "nearest"}:
                k_raw = os.getenv("DXF_EMPTY_EDGE_K", "8").strip()
                try:
                    k = int(k_raw)
                except Exception:
                    k = 8
                k = max(1, min(k, num_nodes - 1))

                edge_set: set[Tuple[int, int]] = set()
                edges_knn: List[Tuple[int, int]] = []
                edge_features_knn: List[List[float]] = []

                # kNN on entity centers (in normalized space via _edge_feature()).
                for i in range(num_nodes):
                    cx_i, cy_i = node_meta[i]["center"]
                    dists: List[Tuple[float, int]] = []
                    for j in range(num_nodes):
                        if i == j:
                            continue
                        cx_j, cy_j = node_meta[j]["center"]
                        dx = cx_j - cx_i
                        dy = cy_j - cy_i
                        dists.append((dx * dx + dy * dy, j))
                    dists.sort(key=lambda t: t[0])
                    for _dist2, j in dists[:k]:
                        if (i, j) not in edge_set:
                            edge_set.add((i, j))
                            edges_knn.append((i, j))
                            if return_edge_attr:
                                edge_features_knn.append(_edge_feature(i, j))
                        if (j, i) not in edge_set:
                            edge_set.add((j, i))
                            edges_knn.append((j, i))
                            if return_edge_attr:
                                edge_features_knn.append(_edge_feature(j, i))

                edge_index = torch.tensor(edges_knn, dtype=torch.long).t().contiguous()
                if return_edge_attr:
                    edge_attr = torch.tensor(edge_features_knn, dtype=torch.float)
                    return x, edge_index, edge_attr
                return x, edge_index

            row = torch.arange(num_nodes).repeat_interleave(num_nodes)
            col = torch.arange(num_nodes).repeat(num_nodes)
            mask = row != col
            edge_index = torch.stack([row[mask], col[mask]], dim=0)
            if return_edge_attr:
                for i in range(num_nodes):
                    for j in range(num_nodes):
                        if i == j:
                            continue
                        edge_features.append(_edge_feature(i, j))
                edge_attr = torch.tensor(edge_features, dtype=torch.float)
                return x, edge_index, edge_attr
            return x, edge_index

        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()
        if return_edge_attr:
            edge_attr = torch.tensor(edge_features, dtype=torch.float)
            return x, edge_index, edge_attr
        return x, edge_index


class DXFManifestDataset(Dataset):
    """DXF dataset backed by a manifest CSV (weak labels from filenames)."""

    def __init__(
        self,
        manifest_csv: str,
        dxf_dir: str,
        label_map: Optional[Dict[str, int]] = None,
        node_dim: int = DXF_NODE_DIM,
        return_edge_attr: bool = False,
    ):
        self.manifest_csv = manifest_csv
        self.dxf_dir = dxf_dir
        self.samples: List[Dict[str, Any]] = []
        self.label_map = label_map or {}
        self.node_dim = node_dim
        self.return_edge_attr = return_edge_attr
        cache_mode = os.getenv("DXF_MANIFEST_DATASET_CACHE", "").strip().lower()
        self._cache_memory_enabled = cache_mode in {
            "1",
            "true",
            "yes",
            "on",
            "memory",
            "both",
            "memory+disk",
            "disk+memory",
        }
        self._cache_disk_enabled = cache_mode in {
            "disk",
            "both",
            "memory+disk",
            "disk+memory",
        }
        self._cache_max_items = int(
            os.getenv("DXF_MANIFEST_DATASET_CACHE_MAX_ITEMS", "0").strip() or 0
        )
        # Cache graph tensors only. Labels depend on the manifest label_map and
        # must never be cached across different manifests.
        self._graph_cache: Dict[str, Dict[str, Any]] = {}
        self._cache_order: List[str] = []
        self._cache_stats = {"hits": 0, "misses": 0}
        self._disk_cache_stats = {"hits": 0, "misses": 0, "writes": 0, "errors": 0}

        self._disk_cache_dir: Optional[Path] = None
        if self._cache_disk_enabled:
            raw_dir = os.getenv("DXF_MANIFEST_DATASET_CACHE_DIR", "").strip()
            self._disk_cache_dir = (
                Path(raw_dir).expanduser()
                if raw_dir
                else Path("/tmp/dxf_manifest_dataset_graph_cache")
            )
            try:
                self._disk_cache_dir.mkdir(parents=True, exist_ok=True)
            except Exception as exc:
                logger.warning(
                    "Failed to init disk graph cache dir %s: %s",
                    self._disk_cache_dir,
                    exc,
                )
                self._disk_cache_dir = None
                self._cache_disk_enabled = False

        with open(manifest_csv, "r", encoding="utf-8") as handle:
            reader = csv.DictReader(handle)
            for row in reader:
                if not row:
                    continue
                label = (row.get("label_cn") or "").strip()
                file_name = (row.get("file_name") or "").strip()
                relative_path = (row.get("relative_path") or "").strip()
                if not label or not file_name:
                    continue
                if label not in self.label_map:
                    self.label_map[label] = len(self.label_map)
                self.samples.append(
                    {
                        "file_name": file_name,
                        "relative_path": relative_path or file_name,
                        "label": label,
                        "label_id": self.label_map[label],
                    }
                )

    def _graph_cache_key(self, file_path: Path) -> str:
        """Generate a stable cache key for a DXF graph sample."""
        try:
            mtime = file_path.stat().st_mtime
        except OSError:
            mtime = 0.0

        key_tokens = [
            str(file_path.resolve()),
            str(mtime),
            str(self.node_dim),
            "edge_attr=1" if self.return_edge_attr else "edge_attr=0",
            os.getenv("DXF_MAX_NODES", ""),
            os.getenv("DXF_SAMPLING_STRATEGY", ""),
            os.getenv("DXF_SAMPLING_SEED", ""),
            os.getenv("DXF_TEXT_PRIORITY_RATIO", ""),
            os.getenv("DXF_FRAME_PRIORITY_RATIO", ""),
            os.getenv("DXF_LONG_LINE_RATIO", ""),
            os.getenv("DXF_EDGE_AUGMENT_KNN_K", ""),
            os.getenv("DXF_EDGE_AUGMENT_STRATEGY", ""),
            os.getenv("DXF_EMPTY_EDGE_FALLBACK", ""),
            os.getenv("DXF_EMPTY_EDGE_K", ""),
            os.getenv("DXF_ENHANCED_KEYPOINTS", ""),
            os.getenv("DXF_STRIP_TEXT_ENTITIES", ""),
        ]
        raw = ":".join(key_tokens)
        try:
            digest = hashlib.md5(raw.encode("utf-8"), usedforsecurity=False).hexdigest()
        except TypeError:  # pragma: no cover
            digest = hashlib.md5(raw.encode("utf-8")).hexdigest()
        return digest[:16]

    def _cache_get(self, cache_key: str) -> Optional[Dict[str, Any]]:
        if not self._cache_memory_enabled:
            return None
        value = self._graph_cache.get(cache_key)
        if value is None:
            self._cache_stats["misses"] += 1
            return None
        self._cache_stats["hits"] += 1
        if cache_key in self._cache_order:
            self._cache_order.remove(cache_key)
        self._cache_order.append(cache_key)
        return value

    def _cache_put(self, cache_key: str, graph: Dict[str, Any]) -> None:
        if not self._cache_memory_enabled:
            return
        while (
            self._cache_max_items > 0
            and len(self._cache_order) >= self._cache_max_items
        ):
            old_key = self._cache_order.pop(0)
            self._graph_cache.pop(old_key, None)
        self._graph_cache[cache_key] = graph
        if cache_key in self._cache_order:
            self._cache_order.remove(cache_key)
        self._cache_order.append(cache_key)

    def _disk_cache_path(self, cache_key: str) -> Optional[Path]:
        if not self._cache_disk_enabled or self._disk_cache_dir is None:
            return None
        return self._disk_cache_dir / f"{cache_key}.pt"

    def _disk_cache_get(self, cache_key: str) -> Optional[Dict[str, Any]]:
        cache_path = self._disk_cache_path(cache_key)
        if cache_path is None or not cache_path.exists():
            self._disk_cache_stats["misses"] += 1
            return None
        try:
            payload = torch.load(str(cache_path), map_location="cpu")
            if not isinstance(payload, dict):
                raise TypeError("invalid_cache_payload")
            graph = payload.get("graph")
            # Older cache versions stored labels as well; ignore them since
            # labels depend on the manifest and cannot be reused safely.
            if not isinstance(graph, dict):
                raise TypeError("invalid_cache_types")
        except Exception as exc:
            self._disk_cache_stats["errors"] += 1
            logger.warning("Failed to read disk graph cache %s: %s", cache_path, exc)
            return None

        self._disk_cache_stats["hits"] += 1
        if self._cache_memory_enabled:
            self._cache_put(cache_key, graph)
        return graph

    def _disk_cache_put(self, cache_key: str, graph: Dict[str, Any]) -> None:
        cache_path = self._disk_cache_path(cache_key)
        if cache_path is None:
            return
        tmp_path = cache_path.with_suffix(f".{os.getpid()}.tmp")
        try:
            torch.save({"graph": graph}, str(tmp_path))
            os.replace(str(tmp_path), str(cache_path))
            self._disk_cache_stats["writes"] += 1
        except Exception as exc:
            self._disk_cache_stats["errors"] += 1
            logger.warning("Failed to write disk graph cache %s: %s", cache_path, exc)
            try:
                if tmp_path.exists():
                    tmp_path.unlink()
            except Exception:
                pass

    def get_cache_stats(self) -> Dict[str, Any]:
        total = int(self._cache_stats["hits"]) + int(self._cache_stats["misses"])
        hit_rate = float(self._cache_stats["hits"]) / float(total) if total else 0.0
        return {
            "memory_enabled": bool(self._cache_memory_enabled),
            "hits": int(self._cache_stats["hits"]),
            "misses": int(self._cache_stats["misses"]),
            "hit_rate": hit_rate,
            "size": len(self._graph_cache),
            "max_items": int(self._cache_max_items),
            "disk_enabled": bool(self._cache_disk_enabled),
            "disk_dir": str(self._disk_cache_dir) if self._disk_cache_dir else "",
            "disk_hits": int(self._disk_cache_stats["hits"]),
            "disk_misses": int(self._disk_cache_stats["misses"]),
            "disk_writes": int(self._disk_cache_stats["writes"]),
            "disk_errors": int(self._disk_cache_stats["errors"]),
        }

    def __len__(self) -> int:
        return len(self.samples)

    def __getitem__(self, idx: int) -> Tuple[Dict[str, Any], torch.Tensor]:
        item = self.samples[idx]
        file_name = item["file_name"]
        rel_path = str(item.get("relative_path") or file_name).strip() or file_name

        base_dir = Path(self.dxf_dir)
        candidates: List[Path] = []

        rel_candidate = Path(rel_path)
        candidates.append(
            rel_candidate if rel_candidate.is_absolute() else base_dir / rel_path
        )

        # Backward compatible fallbacks for older manifests.
        if file_name and file_name != rel_path:
            candidates.append(base_dir / file_name)

        stem = os.path.splitext(Path(file_name).name)[0]
        if stem:
            candidates.append(base_dir / f"{stem}.dxf")
            candidates.append(base_dir / f"{stem}.DXF")

        file_path = next((p for p in candidates if p.exists()), candidates[0])
        label = torch.tensor(item["label_id"], dtype=torch.long)

        cache_key = self._graph_cache_key(file_path)
        cached_graph = self._cache_get(cache_key)
        if cached_graph is not None:
            graph = dict(cached_graph)
            graph["file_name"] = file_name
            graph["relative_path"] = rel_path
            graph["file_path"] = str(file_path)
            return graph, label
        if self._cache_disk_enabled:
            cached_graph = self._disk_cache_get(cache_key)
            if cached_graph is not None:
                graph = dict(cached_graph)
                graph["file_name"] = file_name
                graph["relative_path"] = rel_path
                graph["file_path"] = str(file_path)
                return graph, label

        try:
            strip_text = os.getenv(
                "DXF_STRIP_TEXT_ENTITIES", "false"
            ).strip().lower() in {"1", "true", "yes", "on"}
            if strip_text:
                from src.utils.dxf_io import (
                    read_dxf_document_from_bytes,
                    strip_dxf_text_entities_from_bytes,
                )

                raw_bytes = file_path.read_bytes()
                stripped = strip_dxf_text_entities_from_bytes(
                    raw_bytes, strip_blocks=True
                )
                doc = read_dxf_document_from_bytes(stripped)
                msp = doc.modelspace()
            else:
                doc = ezdxf.readfile(str(file_path))
                msp = doc.modelspace()
            if self.return_edge_attr:
                x, edge_index, edge_attr = self._dxf_to_graph(
                    msp, self.node_dim, return_edge_attr=True
                )
                graph = {
                    "x": x,
                    "edge_index": edge_index,
                    "edge_attr": edge_attr,
                    "file_name": file_name,
                    "relative_path": rel_path,
                    "file_path": str(file_path),
                }
                self._cache_put(cache_key, graph)
                self._disk_cache_put(cache_key, graph)
                return graph, label
            x, edge_index = self._dxf_to_graph(msp, self.node_dim)
            graph = {
                "x": x,
                "edge_index": edge_index,
                "file_name": file_name,
                "relative_path": rel_path,
                "file_path": str(file_path),
            }
            self._cache_put(cache_key, graph)
            self._disk_cache_put(cache_key, graph)
            return graph, label
        except Exception as e:
            logger.error("Error parsing %s (%s): %s", file_name, file_path, e)
            empty_graph = {
                "x": torch.zeros(0, self.node_dim),
                "edge_index": torch.zeros(2, 0, dtype=torch.long),
                "file_name": file_name,
                "relative_path": rel_path,
                "file_path": str(file_path),
            }
            if self.return_edge_attr:
                empty_graph["edge_attr"] = torch.zeros(0, DXF_EDGE_DIM)
            self._cache_put(cache_key, empty_graph)
            self._disk_cache_put(cache_key, empty_graph)
            return empty_graph, label

    def get_label_map(self) -> Dict[str, int]:
        return dict(self.label_map)

    def _dxf_to_graph(
        self, msp, node_dim: Optional[int] = None, return_edge_attr: bool = False
    ) -> Union[
        Tuple[torch.Tensor, torch.Tensor],
        Tuple[torch.Tensor, torch.Tensor, torch.Tensor],
    ]:
        # Reuse graph builder from DXFDataset
        return DXFDataset._dxf_to_graph(
            self, msp, node_dim=node_dim, return_edge_attr=return_edge_attr
        )
