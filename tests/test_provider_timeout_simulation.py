#!/usr/bin/env python3
"""
Provider Timeout Simulation Tests
Provider è¶…æ—¶æ¨¡æ‹Ÿæµ‹è¯• - æµ‹è¯•ç³»ç»Ÿåœ¨å„ç§è¶…æ—¶åœºæ™¯ä¸‹çš„è¡Œä¸º

æµ‹è¯•åœºæ™¯ï¼š
1. å•ä¸ª Provider è¶…æ—¶
2. çº§è”è¶…æ—¶ï¼ˆå¤šä¸ª Provider è¿ç»­è¶…æ—¶ï¼‰
3. éƒ¨åˆ†è¶…æ—¶ï¼ˆæŸäº›è¯·æ±‚è¶…æ—¶ï¼‰
4. æ…¢å“åº”ï¼ˆæ¥è¿‘è¶…æ—¶ä½†æœªè¶…æ—¶ï¼‰
5. é—´æ­‡æ€§è¶…æ—¶
6. è¶…æ—¶æ¢å¤æµ‹è¯•
"""

import asyncio
import random
import statistics
import time
from dataclasses import dataclass
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional
from unittest.mock import AsyncMock, Mock, patch

import pytest


@dataclass
class TimeoutScenario:
    """è¶…æ—¶åœºæ™¯é…ç½®"""

    name: str
    providers: List[str]
    timeout_pattern: str  # fixed, random, increasing, burst
    timeout_duration: float
    recovery_time: float
    failure_rate: float  # 0.0 åˆ° 1.0
    description: str


class ProviderTimeoutSimulator:
    """Provider è¶…æ—¶æ¨¡æ‹Ÿå™¨"""

    def __init__(self):
        self.scenarios = self._define_scenarios()
        self.metrics = {
            "total_requests": 0,
            "timeouts": 0,
            "recoveries": 0,
            "response_times": [],
            "cascade_failures": 0,
        }

    def _define_scenarios(self) -> List[TimeoutScenario]:
        """å®šä¹‰æµ‹è¯•åœºæ™¯"""
        # NOTE: ä½¿ç”¨è¾ƒçŸ­çš„è¶…æ—¶æ—¶é—´ï¼ˆ0.01-0.1ç§’ï¼‰ä»¥åŠ å¿«æµ‹è¯•è¿è¡Œé€Ÿåº¦
        # ä¿æŒç›¸åŒçš„æµ‹è¯•é€»è¾‘å’Œæ¯”ä¾‹å…³ç³»
        return [
            TimeoutScenario(
                name="single_provider_timeout",
                providers=["deepseek"],
                timeout_pattern="fixed",
                timeout_duration=0.05,  # åŸ30.0ï¼Œç¼©çŸ­ä¸º50ms
                recovery_time=0.1,  # åŸ60.0ï¼Œç¼©çŸ­ä¸º100ms
                failure_rate=1.0,
                description="å•ä¸ª Provider å®Œå…¨è¶…æ—¶",
            ),
            TimeoutScenario(
                name="cascading_timeout",
                providers=["deepseek", "assemblyai", "glm4v"],
                timeout_pattern="increasing",
                timeout_duration=0.02,  # åŸ10.0ï¼Œç¼©çŸ­ä¸º20ms
                recovery_time=0.2,  # åŸ120.0ï¼Œç¼©çŸ­ä¸º200ms
                failure_rate=1.0,
                description="å¤šä¸ª Provider çº§è”è¶…æ—¶",
            ),
            TimeoutScenario(
                name="partial_timeout",
                providers=["deepseek"],
                timeout_pattern="random",
                timeout_duration=0.03,  # åŸ15.0ï¼Œç¼©çŸ­ä¸º30ms
                recovery_time=0.05,  # åŸ30.0ï¼Œç¼©çŸ­ä¸º50ms
                failure_rate=0.3,
                description="30% çš„è¯·æ±‚è¶…æ—¶",
            ),
            TimeoutScenario(
                name="slow_response",
                providers=["assemblyai"],
                timeout_pattern="fixed",
                timeout_duration=0.05,  # åŸ25.0ï¼Œç¼©çŸ­ä¸º50ms
                recovery_time=0.0,
                failure_rate=0.0,
                description="æ…¢å“åº”ä½†ä¸è¶…æ—¶",
            ),
            TimeoutScenario(
                name="intermittent_timeout",
                providers=["glm4v"],
                timeout_pattern="burst",
                timeout_duration=0.06,  # åŸ35.0ï¼Œç¼©çŸ­ä¸º60ms
                recovery_time=0.08,  # åŸ45.0ï¼Œç¼©çŸ­ä¸º80ms
                failure_rate=0.5,
                description="é—´æ­‡æ€§è¶…æ—¶çªå‘",
            ),
            TimeoutScenario(
                name="gradual_degradation",
                providers=["deepseek", "assemblyai"],
                timeout_pattern="increasing",
                timeout_duration=0.01,  # åŸ5.0ï¼Œç¼©çŸ­ä¸º10ms
                recovery_time=0.15,  # åŸ90.0ï¼Œç¼©çŸ­ä¸º150ms
                failure_rate=0.7,
                description="é€æ¸æ¶åŒ–çš„è¶…æ—¶æƒ…å†µ",
            ),
        ]

    async def simulate_provider_call(
        self, provider: str, scenario: TimeoutScenario, request_num: int
    ) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿ Provider è°ƒç”¨"""
        start_time = time.time()
        self.metrics["total_requests"] += 1

        try:
            # åˆ¤æ–­æ˜¯å¦åº”è¯¥è¶…æ—¶
            should_timeout = self._should_timeout(scenario, request_num)

            if should_timeout:
                # è®¡ç®—è¶…æ—¶æŒç»­æ—¶é—´
                timeout_duration = self._calculate_timeout_duration(scenario, request_num)

                # æ¨¡æ‹Ÿè¶…æ—¶
                await asyncio.sleep(timeout_duration)
                self.metrics["timeouts"] += 1

                raise asyncio.TimeoutError(f"Provider {provider} timeout after {timeout_duration}s")

            else:
                # æ­£å¸¸å“åº”ï¼ˆå¯èƒ½æ…¢ï¼‰
                if scenario.timeout_pattern == "fixed" and scenario.failure_rate == 0:
                    # æ…¢å“åº”åœºæ™¯
                    response_time = scenario.timeout_duration
                else:
                    # æ­£å¸¸å“åº”æ—¶é—´ï¼ˆç¼©çŸ­ä¸º0.001-0.01ç§’ä»¥åŠ å¿«æµ‹è¯•ï¼‰
                    response_time = random.uniform(0.001, 0.01)

                await asyncio.sleep(response_time)

                elapsed = time.time() - start_time
                self.metrics["response_times"].append(elapsed)

                return {
                    "provider": provider,
                    "status": "success",
                    "response_time": elapsed,
                    "request_num": request_num,
                }

        except asyncio.TimeoutError as e:
            elapsed = time.time() - start_time
            return {
                "provider": provider,
                "status": "timeout",
                "error": str(e),
                "response_time": elapsed,
                "request_num": request_num,
            }

    def _should_timeout(self, scenario: TimeoutScenario, request_num: int) -> bool:
        """åˆ¤æ–­è¯·æ±‚æ˜¯å¦åº”è¯¥è¶…æ—¶"""
        if scenario.failure_rate >= 1.0:
            return True
        elif scenario.failure_rate <= 0.0:
            return False

        if scenario.timeout_pattern == "burst":
            # çªå‘æ¨¡å¼ï¼šæ¯ 10 ä¸ªè¯·æ±‚ä¸­æœ‰ä¸€æ³¢è¶…æ—¶
            if request_num % 10 < 3:
                return random.random() < scenario.failure_rate * 2
            return False

        return random.random() < scenario.failure_rate

    def _calculate_timeout_duration(self, scenario: TimeoutScenario, request_num: int) -> float:
        """è®¡ç®—è¶…æ—¶æŒç»­æ—¶é—´"""
        base_duration = scenario.timeout_duration

        if scenario.timeout_pattern == "fixed":
            return base_duration

        elif scenario.timeout_pattern == "random":
            return random.uniform(base_duration * 0.5, base_duration * 1.5)

        elif scenario.timeout_pattern == "increasing":
            # é€æ¸å¢åŠ çš„è¶…æ—¶æ—¶é—´
            return base_duration * (1 + request_num * 0.1)

        elif scenario.timeout_pattern == "burst":
            # çªå‘æ¨¡å¼ä¸‹çš„è¶…æ—¶æ›´é•¿
            return base_duration * 1.5

        return base_duration

    def analyze_metrics(self) -> Dict[str, Any]:
        """åˆ†ææµ‹è¯•æŒ‡æ ‡"""
        if not self.metrics["response_times"]:
            avg_response = 0
            p95_response = 0
            p99_response = 0
        else:
            avg_response = statistics.mean(self.metrics["response_times"])
            p95_response = (
                statistics.quantiles(self.metrics["response_times"], n=20)[18]
                if len(self.metrics["response_times"]) > 1
                else avg_response
            )
            p99_response = (
                statistics.quantiles(self.metrics["response_times"], n=100)[98]
                if len(self.metrics["response_times"]) > 1
                else avg_response
            )

        timeout_rate = (
            self.metrics["timeouts"] / self.metrics["total_requests"]
            if self.metrics["total_requests"] > 0
            else 0
        )

        return {
            "total_requests": self.metrics["total_requests"],
            "timeouts": self.metrics["timeouts"],
            "timeout_rate": timeout_rate,
            "avg_response_time": avg_response,
            "p95_response_time": p95_response,
            "p99_response_time": p99_response,
            "cascade_failures": self.metrics["cascade_failures"],
            "recoveries": self.metrics["recoveries"],
        }


# ============================================================================
# Test Cases
# ============================================================================


@pytest.fixture
def simulator():
    """åˆ›å»ºæ¨¡æ‹Ÿå™¨å®ä¾‹"""
    return ProviderTimeoutSimulator()


@pytest.fixture
def mock_resilience_layer():
    """æ¨¡æ‹Ÿ resilience layer"""
    with patch("src.core.resilience.circuit_breaker.CircuitBreaker") as mock_cb, patch(
        "src.core.resilience.retry_policy.RetryPolicy"
    ) as mock_retry:
        mock_cb_instance = Mock()
        mock_retry_instance = Mock()

        mock_cb.return_value = mock_cb_instance
        mock_retry.return_value = mock_retry_instance

        yield {"circuit_breaker": mock_cb_instance, "retry_policy": mock_retry_instance}


@pytest.mark.asyncio
async def test_single_provider_timeout(simulator):
    """æµ‹è¯•å•ä¸ª Provider å®Œå…¨è¶…æ—¶"""
    scenario = simulator.scenarios[0]  # single_provider_timeout

    results = []
    for i in range(10):
        result = await simulator.simulate_provider_call(
            provider=scenario.providers[0], scenario=scenario, request_num=i
        )
        results.append(result)

    # éªŒè¯æ‰€æœ‰è¯·æ±‚éƒ½è¶…æ—¶
    assert all(r["status"] == "timeout" for r in results)

    metrics = simulator.analyze_metrics()
    assert metrics["timeout_rate"] == 1.0
    assert metrics["timeouts"] == 10


@pytest.mark.asyncio
async def test_cascading_timeout(simulator):
    """æµ‹è¯•çº§è”è¶…æ—¶åœºæ™¯"""
    scenario = simulator.scenarios[1]  # cascading_timeout

    # æ¨¡æ‹Ÿä¸» Provider å’Œå¤‡ç”¨ Provider éƒ½è¶…æ—¶
    cascade_detected = False

    for provider in scenario.providers:
        result = await simulator.simulate_provider_call(
            provider=provider, scenario=scenario, request_num=0
        )

        if result["status"] == "timeout":
            if provider != scenario.providers[0]:
                # å¤‡ç”¨ Provider ä¹Ÿè¶…æ—¶ï¼Œçº§è”å¤±è´¥
                simulator.metrics["cascade_failures"] += 1
                cascade_detected = True

    assert cascade_detected, "Should detect cascade failure"


@pytest.mark.asyncio
async def test_partial_timeout(simulator):
    """æµ‹è¯•éƒ¨åˆ†è¯·æ±‚è¶…æ—¶"""
    scenario = simulator.scenarios[2]  # partial_timeout

    results = []
    for i in range(100):  # è¿è¡Œè¶³å¤Ÿå¤šçš„è¯·æ±‚ä»¥è·å¾—ç»Ÿè®¡æ„ä¹‰
        result = await simulator.simulate_provider_call(
            provider=scenario.providers[0], scenario=scenario, request_num=i
        )
        results.append(result)

    timeout_count = sum(1 for r in results if r["status"] == "timeout")
    timeout_rate = timeout_count / len(results)

    # éªŒè¯è¶…æ—¶ç‡æ¥è¿‘é…ç½®å€¼ï¼ˆå…è®¸ 15% åå·®ï¼Œå› éšæœºæ€§é¿å…è¾¹ç•Œæ¡ä»¶ï¼‰
    assert abs(timeout_rate - scenario.failure_rate) <= 0.15


@pytest.mark.asyncio
async def test_slow_response_detection(simulator):
    """æµ‹è¯•æ…¢å“åº”æ£€æµ‹"""
    scenario = simulator.scenarios[3]  # slow_response

    results = []
    for i in range(5):
        result = await simulator.simulate_provider_call(
            provider=scenario.providers[0], scenario=scenario, request_num=i
        )
        results.append(result)

    # éªŒè¯æ²¡æœ‰è¶…æ—¶ä½†å“åº”å¾ˆæ…¢ï¼ˆç›¸å¯¹äºæ­£å¸¸å“åº”æ—¶é—´ï¼‰
    assert all(r["status"] == "success" for r in results)
    # æ…¢å“åº”æ—¶é—´åº”è¯¥æ¥è¿‘é…ç½®çš„è¶…æ—¶æ—¶é—´ï¼ˆ0.05ç§’ï¼‰
    assert all(r["response_time"] >= scenario.timeout_duration * 0.9 for r in results)

    metrics = simulator.analyze_metrics()
    assert metrics["p95_response_time"] >= scenario.timeout_duration * 0.9


@pytest.mark.asyncio
async def test_intermittent_timeout(simulator):
    """æµ‹è¯•é—´æ­‡æ€§è¶…æ—¶"""
    scenario = simulator.scenarios[4]  # intermittent_timeout

    burst_results = []
    normal_results = []

    for i in range(30):
        result = await simulator.simulate_provider_call(
            provider=scenario.providers[0], scenario=scenario, request_num=i
        )

        # æ ¹æ®çªå‘æ¨¡å¼åˆ†ç»„ç»“æœ
        if i % 10 < 3:
            burst_results.append(result)
        else:
            normal_results.append(result)

    # éªŒè¯çªå‘æœŸé—´æœ‰æ›´é«˜çš„è¶…æ—¶ç‡
    burst_timeout_rate = (
        sum(1 for r in burst_results if r["status"] == "timeout") / len(burst_results)
        if burst_results
        else 0
    )

    normal_timeout_rate = (
        sum(1 for r in normal_results if r["status"] == "timeout") / len(normal_results)
        if normal_results
        else 0
    )

    assert burst_timeout_rate > normal_timeout_rate


@pytest.mark.asyncio
async def test_timeout_recovery(simulator):
    """æµ‹è¯•è¶…æ—¶æ¢å¤æœºåˆ¶"""
    scenario = TimeoutScenario(
        name="recovery_test",
        providers=["test_provider"],
        timeout_pattern="fixed",
        timeout_duration=0.02,  # åŸ10.0ï¼Œç¼©çŸ­ä¸º20ms
        recovery_time=0.01,  # åŸ5.0ï¼Œç¼©çŸ­ä¸º10ms
        failure_rate=1.0,
        description="æµ‹è¯•æ¢å¤æœºåˆ¶",
    )

    # ç¬¬ä¸€é˜¶æ®µï¼šè¶…æ—¶
    timeout_results = []
    for i in range(5):
        result = await simulator.simulate_provider_call(
            provider=scenario.providers[0], scenario=scenario, request_num=i
        )
        timeout_results.append(result)

    # æ¨¡æ‹Ÿæ¢å¤æ—¶é—´
    await asyncio.sleep(scenario.recovery_time)
    simulator.metrics["recoveries"] += 1

    # ä¿®æ”¹åœºæ™¯ä¸ºæ­£å¸¸
    scenario.failure_rate = 0.0

    # ç¬¬äºŒé˜¶æ®µï¼šæ¢å¤åçš„æ­£å¸¸è¯·æ±‚
    recovery_results = []
    for i in range(5, 10):
        result = await simulator.simulate_provider_call(
            provider=scenario.providers[0], scenario=scenario, request_num=i
        )
        recovery_results.append(result)

    # éªŒè¯æ¢å¤
    assert all(r["status"] == "timeout" for r in timeout_results)
    assert all(r["status"] == "success" for r in recovery_results)
    assert simulator.metrics["recoveries"] > 0


@pytest.mark.asyncio
async def test_gradual_degradation(simulator):
    """æµ‹è¯•é€æ¸æ¶åŒ–çš„è¶…æ—¶æƒ…å†µ"""
    scenario = simulator.scenarios[5]  # gradual_degradation

    response_times = []
    timeout_positions = []

    for i in range(20):
        result = await simulator.simulate_provider_call(
            provider=scenario.providers[0], scenario=scenario, request_num=i
        )

        if result["status"] == "timeout":
            timeout_positions.append(i)
            # è¶…æ—¶çš„å“åº”æ—¶é—´ä¼šæ›´é•¿
            response_times.append(result["response_time"])
        else:
            response_times.append(result["response_time"])

    # éªŒè¯åæœŸçš„è¶…æ—¶æ›´é¢‘ç¹ï¼ˆå¦‚æœpatternæ˜¯increasingï¼‰
    if scenario.timeout_pattern == "increasing" and len(timeout_positions) > 1:
        # ååŠéƒ¨åˆ†åº”è¯¥æœ‰æ›´å¤šè¶…æ—¶
        mid_point = len(timeout_positions) // 2
        early_timeouts = sum(1 for p in timeout_positions if p < 10)
        late_timeouts = sum(1 for p in timeout_positions if p >= 10)

        # è¿™ä¸ªæ–­è¨€å¯èƒ½ä¸æ€»æ˜¯é€šè¿‡ï¼ˆç”±äºéšæœºæ€§ï¼‰ï¼Œä½†è¶‹åŠ¿åº”è¯¥å­˜åœ¨
        if late_timeouts > 0 and early_timeouts > 0:
            print(f"Early timeouts: {early_timeouts}, Late timeouts: {late_timeouts}")


@pytest.mark.asyncio
async def test_circuit_breaker_integration(simulator, mock_resilience_layer):
    """æµ‹è¯•ä¸ Circuit Breaker çš„é›†æˆ"""
    scenario = simulator.scenarios[0]  # single_provider_timeout

    # æ¨¡æ‹Ÿå¤šæ¬¡å¤±è´¥è§¦å‘ circuit breaker
    failures = 0
    circuit_opened = False

    for i in range(10):
        result = await simulator.simulate_provider_call(
            provider=scenario.providers[0], scenario=scenario, request_num=i
        )

        if result["status"] == "timeout":
            failures += 1

            # æ¨¡æ‹Ÿ circuit breaker é€»è¾‘
            if failures >= 5 and not circuit_opened:
                mock_resilience_layer["circuit_breaker"].open()
                circuit_opened = True
                break

    assert circuit_opened, "Circuit breaker should open after multiple timeouts"


@pytest.mark.asyncio
async def test_retry_policy_with_timeout(simulator, mock_resilience_layer):
    """æµ‹è¯•é‡è¯•ç­–ç•¥ä¸è¶…æ—¶çš„äº¤äº’"""
    scenario = TimeoutScenario(
        name="retry_test",
        providers=["test_provider"],
        timeout_pattern="random",
        timeout_duration=0.01,  # åŸ5.0ï¼Œç¼©çŸ­ä¸º10ms
        recovery_time=0.002,  # åŸ1.0ï¼Œç¼©çŸ­ä¸º2ms
        failure_rate=0.5,
        description="æµ‹è¯•é‡è¯•æœºåˆ¶",
    )

    max_retries = 3
    successful = False
    attempts = 0

    for retry in range(max_retries):
        attempts += 1
        result = await simulator.simulate_provider_call(
            provider=scenario.providers[0], scenario=scenario, request_num=retry
        )

        if result["status"] == "success":
            successful = True
            break

        # æ¨¡æ‹ŸæŒ‡æ•°é€€é¿ï¼ˆç¼©çŸ­æ—¶é—´ï¼‰
        await asyncio.sleep(0.001 * (2**retry))

    # ç»Ÿè®¡é‡è¯•æ•ˆæœ
    print(f"Retry attempts: {attempts}, Successful: {successful}")


@pytest.mark.asyncio
async def test_multi_provider_fallback(simulator):
    """æµ‹è¯•å¤š Provider æ•…éšœè½¬ç§»"""
    providers = ["deepseek", "assemblyai", "glm4v"]
    fallback_chain = []

    for idx, provider in enumerate(providers):
        # ä¸ºæ¯ä¸ª provider åˆ›å»ºä¸åŒçš„è¶…æ—¶æ¦‚ç‡
        scenario = TimeoutScenario(
            name=f"fallback_test_{provider}",
            providers=[provider],
            timeout_pattern="random",
            timeout_duration=0.02,  # åŸ10.0ï¼Œç¼©çŸ­ä¸º20ms
            recovery_time=0.01,  # åŸ5.0ï¼Œç¼©çŸ­ä¸º10ms
            failure_rate=0.7 - idx * 0.2,  # é€’å‡çš„å¤±è´¥ç‡
            description=f"Fallback test for {provider}",
        )

        result = await simulator.simulate_provider_call(
            provider=provider, scenario=scenario, request_num=0
        )

        fallback_chain.append({"provider": provider, "result": result, "order": idx + 1})

        if result["status"] == "success":
            break

    # åˆ†ææ•…éšœè½¬ç§»é“¾
    successful_provider = next(
        (f["provider"] for f in fallback_chain if f["result"]["status"] == "success"), None
    )

    print(f"Fallback chain: {[f['provider'] for f in fallback_chain]}")
    print(f"Successful provider: {successful_provider}")


def test_timeout_metrics_calculation(simulator):
    """æµ‹è¯•è¶…æ—¶æŒ‡æ ‡è®¡ç®—"""
    # æ¨¡æ‹Ÿä¸€äº›æ•°æ®
    simulator.metrics = {
        "total_requests": 100,
        "timeouts": 25,
        "recoveries": 3,
        "response_times": [1.5, 2.3, 3.1, 4.5, 5.2, 8.9, 12.3, 15.6, 22.1, 28.5],
        "cascade_failures": 5,
    }

    analysis = simulator.analyze_metrics()

    assert analysis["timeout_rate"] == 0.25
    assert analysis["total_requests"] == 100
    assert analysis["timeouts"] == 25
    assert analysis["cascade_failures"] == 5
    assert analysis["avg_response_time"] > 0
    assert analysis["p95_response_time"] >= analysis["avg_response_time"]
    assert analysis["p99_response_time"] >= analysis["p95_response_time"]


# ============================================================================
# Performance and Stress Tests
# ============================================================================


@pytest.mark.asyncio
@pytest.mark.performance
async def test_high_load_timeout_behavior(simulator):
    """æµ‹è¯•é«˜è´Ÿè½½ä¸‹çš„è¶…æ—¶è¡Œä¸º"""
    scenario = TimeoutScenario(
        name="high_load_test",
        providers=["test_provider"],
        timeout_pattern="random",
        timeout_duration=0.01,  # åŸ5.0ï¼Œç¼©çŸ­ä¸º10ms
        recovery_time=0.002,  # åŸ1.0ï¼Œç¼©çŸ­ä¸º2ms
        failure_rate=0.2,
        description="é«˜è´Ÿè½½æµ‹è¯•",
    )

    # å¹¶å‘è¯·æ±‚
    concurrent_requests = 50
    tasks = []

    for i in range(concurrent_requests):
        task = simulator.simulate_provider_call(
            provider=scenario.providers[0], scenario=scenario, request_num=i
        )
        tasks.append(task)

    # æ‰§è¡Œæ‰€æœ‰å¹¶å‘è¯·æ±‚
    results = await asyncio.gather(*tasks, return_exceptions=True)

    # åˆ†æç»“æœ
    timeout_count = sum(1 for r in results if isinstance(r, dict) and r.get("status") == "timeout")
    success_count = sum(1 for r in results if isinstance(r, dict) and r.get("status") == "success")

    print(f"High load test results:")
    print(f"  Total: {concurrent_requests}")
    print(f"  Timeouts: {timeout_count}")
    print(f"  Success: {success_count}")

    # éªŒè¯ç³»ç»Ÿæ²¡æœ‰å´©æºƒ
    assert timeout_count + success_count == concurrent_requests


@pytest.mark.asyncio
async def test_timeout_scenario_report(simulator):
    """ç”Ÿæˆè¶…æ—¶åœºæ™¯æµ‹è¯•æŠ¥å‘Š"""
    report = {"test_time": datetime.now().isoformat(), "scenarios": []}

    for scenario in simulator.scenarios:
        # é‡ç½®æŒ‡æ ‡
        simulator.metrics = {
            "total_requests": 0,
            "timeouts": 0,
            "recoveries": 0,
            "response_times": [],
            "cascade_failures": 0,
        }

        # è¿è¡Œåœºæ™¯æµ‹è¯•
        for i in range(10):
            await simulator.simulate_provider_call(
                provider=scenario.providers[0], scenario=scenario, request_num=i
            )

        # æ”¶é›†æŒ‡æ ‡
        metrics = simulator.analyze_metrics()
        report["scenarios"].append(
            {"name": scenario.name, "description": scenario.description, "metrics": metrics}
        )

    # æ‰“å°æŠ¥å‘Š
    print("\n" + "=" * 60)
    print("Provider Timeout Simulation Report")
    print("=" * 60)

    for scenario_report in report["scenarios"]:
        print(f"\nğŸ“Š Scenario: {scenario_report['name']}")
        print(f"   Description: {scenario_report['description']}")
        print(f"   Results:")
        for key, value in scenario_report["metrics"].items():
            if isinstance(value, float):
                print(f"     - {key}: {value:.2f}")
            else:
                print(f"     - {key}: {value}")

    print("\n" + "=" * 60)
